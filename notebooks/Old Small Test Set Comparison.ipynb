{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Test Set #\n",
    "## Goal ##\n",
    "The goal of this test set is to perform proof of concept testing on a small number of proteins with a wide range of sizes and available homologs, orthologs, and paralogs. By doing so it should be possible to test the best parameterization for this tool as well as identifying the strengths and weaknesses of the tool using various measurments as end points.\n",
    "## Warning ##\n",
    "Before attempting to use this notebook make sure that your .env file has been properly setup to reflect the correct locations of command line tools and the location of files and directories needed for execution.\n",
    "### Initial Import###\n",
    "This first cell performs the necessary imports required to begin this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "try:\n",
    "    dotenv_path = find_dotenv(raise_error_if_not_found=True)\n",
    "except IOError:\n",
    "    dotenv_path = find_dotenv(raise_error_if_not_found=True, usecwd=True)\n",
    "load_dotenv(dotenv_path)\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ.get('PROJECT_PATH'), 'src'))\n",
    "sys.path.append(os.path.join(os.environ.get('PROJECT_PATH'), 'src', 'SupportingClasses'))\n",
    "input_dir = os.environ.get('INPUT_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set Construction ##\n",
    "The first task required to test the data set is to download the required data and construct any necessary input files for all down stream analyses.\n",
    "In this case that means:\n",
    "* Downloading PDB files for the proteins in our small test set.\n",
    "* Extracting a query sequence from each PDB file.\n",
    "* Searching for paralogs, homologs, and orthologs in a custom BLAST database built by filtering the Uniref90 database.\n",
    "* Filtering the hits from the BLAST search to meet minimum and maximum length requirements, as well as minimum and maximum identity requirements.\n",
    "* Building alignments using CLUSTALW in both the fasta and msf formats since some of the tools which will be used for comparison need different formats.\n",
    "* Filtering the alignment for maximum identity similarity between seqeunces.\n",
    "* Re-aligning the filtered sequences using CLUSTALW.\n",
    "This is all handeled by the DataSetGenerator class found in the src/SupportingClasses folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.00367888609568278 min\n",
      "Removing gaps took 1.6005833943684897e-05 min\n",
      "Removing gaps took 0.005647377173105875 min\n",
      "Removing gaps took 9.645620981852213e-05 min\n",
      "Removing gaps took 0.00839095115661621 min\n",
      "Removing gaps took 0.00040719906489054364 min\n",
      "Removing gaps took 0.024015319347381592 min\n",
      "Removing gaps took 0.0028417825698852537 min\n",
      "Removing gaps took 6.891489028930664e-05 min\n",
      "Removing gaps took 0.008348623911539713 min\n",
      "Removing gaps took 0.009320274988810221 min\n",
      "Removing gaps took 0.03673636118570964 min\n",
      "Removing gaps took 0.03094174067179362 min\n",
      "Removing gaps took 0.010829782485961914 min\n",
      "Removing gaps took 0.031043771902720133 min\n",
      "Removing gaps took 0.033912158012390135 min\n",
      "Removing gaps took 0.04118153254191081 min\n",
      "Removing gaps took 0.01693795124689738 min\n",
      "Removing gaps took 0.05430312951405843 min\n",
      "Removing gaps took 0.06564549207687378 min\n",
      "Removing gaps took 0.06950506766637167 min\n",
      "Removing gaps took 0.00010329087575276693 min\n",
      "Removing gaps took 0.06190025806427002 min\n",
      "   Protein_ID Accession BLAST_Hits Filtered_BLAST  Filtered_Alignment  Length  \\\n",
      "8       3q05A      None       None           None                  27     234   \n",
      "21      2b59A      None       None           None                  28     166   \n",
      "3       7hvpA      None       None           None                  31      97   \n",
      "1       1c17A      None       None           None                  49      79   \n",
      "5       206lA      None       None           None                  70     162   \n",
      "7       1bolA      None       None           None                 162     222   \n",
      "13      2z0eA      None       None           None                 329     315   \n",
      "9       1axbA      None       None           None                 344     263   \n",
      "4       135lA      None       None           None                 424     129   \n",
      "10      2rh1A      None       None           None                 427     282   \n",
      "17      4lliA      None       None           None                 460     377   \n",
      "15      1a26A      None       None           None                 520     351   \n",
      "16      1c0kA      None       None           None                 601     363   \n",
      "20      2zxeA      None       None           None                 623     992   \n",
      "14      1jwlA      None       None           None                 760     329   \n",
      "11      1hckA      None       None           None                 778     294   \n",
      "22      1h1vA      None       None           None                 785     368   \n",
      "0       2ysdA      None       None           None                 861      57   \n",
      "19      2iopA      None       None           None                 871     618   \n",
      "12      3b6vA      None       None           None                 876     306   \n",
      "18      4ycuA      None       None           None                 878     505   \n",
      "6       2werA      None       None           None                 881     214   \n",
      "2       3tnuA      None       None           None                 945      90   \n",
      "\n",
      "    Total_Size  \n",
      "8         6318  \n",
      "21        4648  \n",
      "3         3007  \n",
      "1         3871  \n",
      "5        11340  \n",
      "7        35964  \n",
      "13      103635  \n",
      "9        90472  \n",
      "4        54696  \n",
      "10      120414  \n",
      "17      173420  \n",
      "15      182520  \n",
      "16      218163  \n",
      "20      618016  \n",
      "14      250040  \n",
      "11      228732  \n",
      "22      288880  \n",
      "0        49077  \n",
      "19      538278  \n",
      "12      268056  \n",
      "18      443390  \n",
      "6       188534  \n",
      "2        85050  \n",
      "It took 0.5205657442410787 min to generate the data set.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "from Bio.Align.Applications import ClustalwCommandline\n",
    "from DataSetGenerator import DataSetGenerator\n",
    "from SeqAlignment import SeqAlignment\n",
    "clustalw_path = os.environ.get('CLUSTALW_PATH')\n",
    "protein_list_dir = os.path.join(input_dir, 'ProteinLists')\n",
    "if not os.path.isdir(protein_list_dir):\n",
    "    os.makedirs(protein_list_dir)\n",
    "small_list_fn = os.path.join(protein_list_dir, 'SmallDataSetOld.txt')\n",
    "proteins_of_interest = ['2ysdA', '1c17A', '3tnuA', '7hvpA', '135lA', '206lA', '2werA', '1bolA', '3q05A', '1axbA',\n",
    "                        '2rh1A', '1hckA', '3b6vA', '2z0eA', '1jwlA', '1a26A', '1c0kA', '4lliA', '4ycuA', '2iopA',\n",
    "                        '2zxeA', '2b59A', '1h1vA']\n",
    "if not os.path.isfile(small_list_fn):\n",
    "    with open(small_list_fn, 'w') as small_list_handle:\n",
    "        for p_id in proteins_of_interest:\n",
    "            small_list_handle.write('{}\\n'.format(p_id))\n",
    "generator = DataSetGenerator(input_dir)\n",
    "start = time()\n",
    "generator.pdb_path = os.path.join(input_dir, 'Old_Data')\n",
    "generator.sequence_path = None\n",
    "generator.blast_path = None\n",
    "generator.filtered_blast_path = None\n",
    "generator.alignment_path = None\n",
    "generator.filtered_alignment_path = None\n",
    "generator.final_alingment_path = generator.pdb_path\n",
    "generator.protein_data = {}\n",
    "summary = {'Protein_ID': [], 'Accession': [], 'BLAST_Hits': [], 'Filtered_BLAST': [],\n",
    "           'Length': [], 'Filtered_Alignment': [], 'Total_Size': []}\n",
    "for p_id in proteins_of_interest:\n",
    "    generator.protein_data[p_id] = {}\n",
    "    if p_id == '2rh1A':\n",
    "        generator.protein_data[p_id]['PDB'] = os.path.join(input_dir, 'Old_Data', '{}_NEW.pdb'.format(p_id))\n",
    "        generator.protein_data[p_id]['Final_FA_Aln'] = os.path.join(input_dir, 'Old_Data', '{}_NEW.fa'.format(p_id))\n",
    "    else:\n",
    "        generator.protein_data[p_id]['PDB'] = os.path.join(input_dir, 'Old_Data', 'query_{}.pdb'.format(p_id))\n",
    "        generator.protein_data[p_id]['Final_FA_Aln'] = os.path.join(input_dir, 'Old_Data', '{}.fa'.format(p_id))\n",
    "    generator.protein_data[p_id]['Chain'] = 'A'\n",
    "    seq_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id='query_' + p_id)\n",
    "    seq_aln.import_alignment()\n",
    "    seq_aln_non_gap = seq_aln.remove_gaps()\n",
    "    generator.protein_data[p_id]['Sequence'] = seq_aln_non_gap.query_sequence\n",
    "    generator.protein_data[p_id]['Length'] = seq_aln_non_gap.seq_length\n",
    "    generator.protein_data[p_id]['Seq_Fasta'] = None\n",
    "    generator.protein_data[p_id]['Accession'] = None\n",
    "    generator.protein_data[p_id]['Filter_Count'] = None\n",
    "    generator.protein_data[p_id]['Filtered_BLAST'] = None\n",
    "    generator.protein_data[p_id]['MSF_Aln'] = None\n",
    "    generator.protein_data[p_id]['FA_Aln'] = None\n",
    "    generator.protein_data[p_id]['Final_Count'] = seq_aln_non_gap.size\n",
    "    generator.protein_data[p_id]['Filtered_Alignment'] = None\n",
    "    generator.protein_data[p_id]['Final_MSF_Aln'] = os.path.splitext(generator.protein_data[p_id]['Final_FA_Aln'])[0] + '.msf'\n",
    "    if not os.path.isfile(generator.protein_data[p_id]['Final_MSF_Aln']):\n",
    "        msf_cline = ClustalwCommandline(clustalw_path, infile=generator.protein_data[p_id]['Final_FA_Aln'], convert=True,\n",
    "                                        outfile=generator.protein_data[p_id]['Final_MSF_Aln'], output='GCG')\n",
    "        print(msf_cline)\n",
    "        stdout, stderr = msf_cline()\n",
    "        print(stdout)\n",
    "        print(stderr)\n",
    "    summary['Protein_ID'].append(p_id)\n",
    "    summary['Accession'].append(None)\n",
    "    summary['BLAST_Hits'].append(None)\n",
    "    summary['Filtered_BLAST'].append(None)\n",
    "    summary['Length'].append(seq_aln_non_gap.seq_length)\n",
    "    summary['Filtered_Alignment'].append(seq_aln_non_gap.size)\n",
    "    summary['Total_Size'].append(seq_aln_non_gap.seq_length * seq_aln_non_gap.size)\n",
    "summary = pd.DataFrame(summary)\n",
    "summary.sort_values(by=['Filtered_Alignment', 'Length'], axis=0, inplace=True)\n",
    "summary_columns = ['Protein_ID', 'Accession', 'BLAST_Hits', 'Filtered_BLAST', 'Filtered_Alignment', 'Length',\n",
    "                   'Total_Size']\n",
    "print(summary[summary_columns])\n",
    "end = time()\n",
    "print('It took {} min to generate the data set.'.format((end - start) / 60.0))\n",
    "summary.to_csv(os.path.join(input_dir, 'small_data_set_old_summary.tsv'), sep='\\t', index=False, header=True,\n",
    "               columns=summary_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a location to store the output of this method comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.environ.get('OUTPUT_PATH')\n",
    "small_set_out_dir = os.path.join(output_dir, 'SmallTestSetOldAln')\n",
    "if not os.path.isdir(small_set_out_dir):\n",
    "    os.makedirs(small_set_out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Scoring For Each Method\n",
    "To reduce memory load during prediction and evaluation, the scoring objects needed to compute the metrics used to compare methods will be created ahead of time so they are available to each method when it computes its predictions for a given protein. This will ensure that results do not need to be kept in memory while waiting for all other results to be computed, only the metrics measured for each method will be recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.00014820098876953126 min\n",
      "Importing the PDB file took 0.0007074673970540365 min\n",
      "Removing gaps took 0.00010912418365478515 min\n",
      "Importing the PDB file took 0.0005945881207784017 min\n",
      "Mapping query sequence and pdb took 0.000799103577931722 min\n",
      "Computing the distance matrix based on the PDB file took 0.0065544327100118 min\n",
      "Removing gaps took 7.826884587605795e-05 min\n",
      "Importing the PDB file took 0.0004143476486206055 min\n",
      "Mapping query sequence and pdb took 0.0005833307902018229 min\n",
      "Computing the distance matrix based on the PDB file took 0.008337736129760742 min\n",
      "Removing gaps took 0.00011073748270670572 min\n",
      "Importing the PDB file took 0.0009888966878255209 min\n",
      "Removing gaps took 0.00010394652684529623 min\n",
      "Importing the PDB file took 0.0002715468406677246 min\n",
      "Mapping query sequence and pdb took 0.0004179994265238444 min\n",
      "Computing the distance matrix based on the PDB file took 0.00265347162882487 min\n",
      "Removing gaps took 0.0001109162966410319 min\n",
      "Importing the PDB file took 0.00026937723159790037 min\n",
      "Mapping query sequence and pdb took 0.0004349668820699056 min\n",
      "Computing the distance matrix based on the PDB file took 0.00318986972173055 min\n",
      "Removing gaps took 0.00010202328364054362 min\n",
      "Importing the PDB file took 0.00016099214553833008 min\n",
      "Removing gaps took 9.555816650390625e-05 min\n",
      "Importing the PDB file took 0.00016665061314900717 min\n",
      "Mapping query sequence and pdb took 0.00028475522994995115 min\n",
      "Computing the distance matrix based on the PDB file took 0.0010593891143798827 min\n",
      "Removing gaps took 9.428262710571289e-05 min\n",
      "Importing the PDB file took 0.00016102393468221028 min\n",
      "Mapping query sequence and pdb took 0.000282593568166097 min\n",
      "Computing the distance matrix based on the PDB file took 0.0011636734008789063 min\n",
      "Removing gaps took 1.5262762705485026e-05 min\n",
      "Importing the PDB file took 0.0002457737922668457 min\n",
      "Removing gaps took 1.8926461537679038e-05 min\n",
      "Importing the PDB file took 0.00024576981862386066 min\n",
      "Mapping query sequence and pdb took 0.0003022472063700358 min\n",
      "Computing the distance matrix based on the PDB file took 0.0007259567578633626 min\n",
      "Removing gaps took 1.4793872833251952e-05 min\n",
      "Importing the PDB file took 0.00024390220642089844 min\n",
      "Mapping query sequence and pdb took 0.0002872943878173828 min\n",
      "Computing the distance matrix based on the PDB file took 0.0010296821594238282 min\n",
      "Removing gaps took 0.00041667620340983075 min\n",
      "Importing the PDB file took 0.00027559598286946616 min\n",
      "Removing gaps took 0.0003975669542948405 min\n",
      "Importing the PDB file took 0.0011193434397379558 min\n",
      "Mapping query sequence and pdb took 0.0015714248021443686 min\n",
      "Computing the distance matrix based on the PDB file took 0.0027822573979695638 min\n",
      "Removing gaps took 0.00040545463562011717 min\n",
      "Importing the PDB file took 0.00026927789052327475 min\n",
      "Mapping query sequence and pdb took 0.0007426063219706218 min\n",
      "Computing the distance matrix based on the PDB file took 0.00326382319132487 min\n",
      "Removing gaps took 0.002292478084564209 min\n",
      "Importing the PDB file took 0.0003391544024149577 min\n",
      "Removing gaps took 0.003039729595184326 min\n",
      "Importing the PDB file took 0.0003500501314798991 min\n",
      "Mapping query sequence and pdb took 0.0034790833791097007 min\n",
      "Computing the distance matrix based on the PDB file took 0.004860277970631917 min\n",
      "Removing gaps took 0.0022693872451782227 min\n",
      "Importing the PDB file took 0.00035760800043741864 min\n",
      "Mapping query sequence and pdb took 0.002744575341542562 min\n",
      "Computing the distance matrix based on the PDB file took 0.005962657928466797 min\n",
      "Removing gaps took 0.011695984999338787 min\n",
      "Importing the PDB file took 0.0005160848299662272 min\n",
      "Removing gaps took 0.011199394861857096 min\n",
      "Importing the PDB file took 0.001300505797068278 min\n",
      "Mapping query sequence and pdb took 0.012724177042643229 min\n",
      "Computing the distance matrix based on the PDB file took 0.011256166299184163 min\n",
      "Removing gaps took 0.011075989405314127 min\n",
      "Importing the PDB file took 0.0005029122034708659 min\n",
      "Mapping query sequence and pdb took 0.011790736516316732 min\n",
      "Computing the distance matrix based on the PDB file took 0.01163857380549113 min\n",
      "Removing gaps took 0.009286534786224366 min\n",
      "Importing the PDB file took 0.00041368007659912107 min\n",
      "Removing gaps took 0.009124688307444255 min\n",
      "Importing the PDB file took 0.0004338343938191732 min\n",
      "Mapping query sequence and pdb took 0.009705233573913574 min\n",
      "Computing the distance matrix based on the PDB file took 0.007239000002543131 min\n",
      "Removing gaps took 0.009236411253611247 min\n",
      "Importing the PDB file took 0.00040996869405110676 min\n",
      "Mapping query sequence and pdb took 0.009806124369303386 min\n",
      "Computing the distance matrix based on the PDB file took 0.008504744370778401 min\n",
      "Removing gaps took 0.008948719501495362 min\n",
      "Importing the PDB file took 0.00021102428436279297 min\n",
      "Removing gaps took 0.008090678850809734 min\n",
      "Importing the PDB file took 0.00021247466405232746 min\n",
      "Mapping query sequence and pdb took 0.008407270908355713 min\n",
      "Computing the distance matrix based on the PDB file took 0.0018235842386881511 min\n",
      "Removing gaps took 0.008044683933258056 min\n",
      "Importing the PDB file took 0.00020883878072102863 min\n",
      "Mapping query sequence and pdb took 0.00921324094136556 min\n",
      "Computing the distance matrix based on the PDB file took 0.002000856399536133 min\n",
      "Removing gaps took 0.010368688901265462 min\n",
      "Importing the PDB file took 0.00134965976079305 min\n",
      "Removing gaps took 0.010423620541890463 min\n",
      "Importing the PDB file took 0.00047910610834757487 min\n",
      "Mapping query sequence and pdb took 0.011084334055582682 min\n",
      "Computing the distance matrix based on the PDB file took 0.008221328258514404 min\n",
      "Removing gaps took 0.010370858510335286 min\n",
      "Importing the PDB file took 0.00046410957972208656 min\n",
      "Mapping query sequence and pdb took 0.0110198974609375 min\n",
      "Computing the distance matrix based on the PDB file took 0.009726428985595703 min\n",
      "Removing gaps took 0.01894357204437256 min\n",
      "Importing the PDB file took 0.0006273309389750163 min\n",
      "Removing gaps took 0.01926263968149821 min\n",
      "Importing the PDB file took 0.0006308396657307943 min\n",
      "Mapping query sequence and pdb took 0.02016817331314087 min\n",
      "Computing the distance matrix based on the PDB file took 0.016401636600494384 min\n",
      "Removing gaps took 0.023198541005452475 min\n",
      "Importing the PDB file took 0.0006321152051289876 min\n",
      "Mapping query sequence and pdb took 0.024123072624206543 min\n",
      "Computing the distance matrix based on the PDB file took 0.019658021132151284 min\n",
      "Removing gaps took 0.036833763122558594 min\n",
      "Importing the PDB file took 0.0005841294924418132 min\n",
      "Removing gaps took 0.03718725045522054 min\n",
      "Importing the PDB file took 0.0015819827715555827 min\n",
      "Mapping query sequence and pdb took 0.039082189400990806 min\n",
      "Computing the distance matrix based on the PDB file took 0.017554505666097005 min\n",
      "Removing gaps took 0.04114253520965576 min\n",
      "Importing the PDB file took 0.0005730311075846354 min\n",
      "Mapping query sequence and pdb took 0.042027167479197186 min\n",
      "Computing the distance matrix based on the PDB file took 0.016177697976430257 min\n",
      "Removing gaps took 0.048635101318359374 min\n",
      "Importing the PDB file took 0.000580139954884847 min\n",
      "Removing gaps took 0.051079920927683514 min\n",
      "Importing the PDB file took 0.0005933523178100586 min\n",
      "Mapping query sequence and pdb took 0.052003335952758786 min\n",
      "Computing the distance matrix based on the PDB file took 0.014099442958831787 min\n",
      "Removing gaps took 0.04901582400004069 min\n",
      "Importing the PDB file took 0.0005672613779703777 min\n",
      "Mapping query sequence and pdb took 0.04991117318471273 min\n",
      "Computing the distance matrix based on the PDB file took 0.015942124525705974 min\n",
      "Removing gaps took 0.0819602648417155 min\n",
      "Importing the PDB file took 0.0015836517016092936 min\n",
      "Removing gaps took 0.08363765080769857 min\n",
      "Importing the PDB file took 0.0015954136848449706 min\n",
      "Mapping query sequence and pdb took 0.08668365875879923 min\n",
      "Computing the distance matrix based on the PDB file took 0.10097974936167399 min\n",
      "Removing gaps took 0.08414335250854492 min\n",
      "Importing the PDB file took 0.0016004403432210287 min\n",
      "Mapping query sequence and pdb took 0.08723647991816202 min\n",
      "Computing the distance matrix based on the PDB file took 0.11801866292953492 min\n",
      "Removing gaps took 0.03621915578842163 min\n",
      "Importing the PDB file took 0.00047768751780192056 min\n",
      "Removing gaps took 0.036869104703267416 min\n",
      "Importing the PDB file took 0.0004898627599080403 min\n",
      "Mapping query sequence and pdb took 0.037643675009409586 min\n",
      "Computing the distance matrix based on the PDB file took 0.011788801352183024 min\n",
      "Removing gaps took 0.03714056015014648 min\n",
      "Importing the PDB file took 0.0004722277323404948 min\n",
      "Mapping query sequence and pdb took 0.03790652354558309 min\n",
      "Computing the distance matrix based on the PDB file took 0.013144691785176596 min\n",
      "Removing gaps took 0.04258013566335042 min\n",
      "Importing the PDB file took 0.000473785400390625 min\n",
      "Removing gaps took 0.04338118235270182 min\n",
      "Importing the PDB file took 0.000494837760925293 min\n",
      "Mapping query sequence and pdb took 0.04416311979293823 min\n",
      "Computing the distance matrix based on the PDB file took 0.009275551637013752 min\n",
      "Removing gaps took 0.04314949909845988 min\n",
      "Importing the PDB file took 0.00048021078109741213 min\n",
      "Mapping query sequence and pdb took 0.04394909143447876 min\n",
      "Computing the distance matrix based on the PDB file took 0.010883537928263347 min\n",
      "Removing gaps took 0.0668074091275533 min\n",
      "Importing the PDB file took 0.0005825400352478027 min\n",
      "Removing gaps took 0.06911573012669882 min\n",
      "Importing the PDB file took 0.0006018678347269694 min\n",
      "Mapping query sequence and pdb took 0.07010809183120728 min\n",
      "Computing the distance matrix based on the PDB file took 0.014783624807993572 min\n",
      "Removing gaps took 0.06716604232788086 min\n",
      "Importing the PDB file took 0.0005710999170939128 min\n",
      "Mapping query sequence and pdb took 0.0681436816851298 min\n",
      "Computing the distance matrix based on the PDB file took 0.01673120657602946 min\n",
      "Removing gaps took 0.004273728529612223 min\n",
      "Importing the PDB file took 0.001547380288441976 min\n",
      "Removing gaps took 0.004197728633880615 min\n",
      "Importing the PDB file took 0.00016483863194783528 min\n",
      "Mapping query sequence and pdb took 0.004505618413289388 min\n",
      "Computing the distance matrix based on the PDB file took 0.0003840923309326172 min\n",
      "Removing gaps took 0.004273891448974609 min\n",
      "Importing the PDB file took 0.00017329851786295573 min\n",
      "Mapping query sequence and pdb took 0.004593280951182047 min\n",
      "Computing the distance matrix based on the PDB file took 0.0005623221397399903 min\n",
      "Removing gaps took 0.07766879796981811 min\n",
      "Importing the PDB file took 0.0010036508242289226 min\n",
      "Removing gaps took 0.07705703179041544 min\n",
      "Importing the PDB file took 0.0010102589925130208 min\n",
      "Mapping query sequence and pdb took 0.07879343430201212 min\n",
      "Computing the distance matrix based on the PDB file took 0.0376500407854716 min\n",
      "Removing gaps took 0.08046483993530273 min\n",
      "Importing the PDB file took 0.0010587453842163086 min\n",
      "Mapping query sequence and pdb took 0.08225248654683431 min\n",
      "Computing the distance matrix based on the PDB file took 0.04782102505366007 min\n",
      "Removing gaps took 0.03688427209854126 min\n",
      "Importing the PDB file took 0.00045787493387858074 min\n",
      "Removing gaps took 0.036883004506429035 min\n",
      "Importing the PDB file took 0.000471651554107666 min\n",
      "Mapping query sequence and pdb took 0.037678106625874834 min\n",
      "Computing the distance matrix based on the PDB file took 0.010700515906016032 min\n",
      "Removing gaps took 0.035759409268697105 min\n",
      "Importing the PDB file took 0.002012753486633301 min\n",
      "Mapping query sequence and pdb took 0.038110510508219404 min\n",
      "Computing the distance matrix based on the PDB file took 0.011055302619934083 min\n",
      "Removing gaps took 0.06363096237182617 min\n",
      "Importing the PDB file took 0.0008329153060913086 min\n",
      "Removing gaps took 0.06427156527837118 min\n",
      "Importing the PDB file took 0.0008341193199157715 min\n",
      "Mapping query sequence and pdb took 0.06562343041102091 min\n",
      "Computing the distance matrix based on the PDB file took 0.028952280680338543 min\n",
      "Removing gaps took 0.07094558477401733 min\n",
      "Importing the PDB file took 0.0008072972297668457 min\n",
      "Mapping query sequence and pdb took 0.07271334330240885 min\n",
      "Computing the distance matrix based on the PDB file took 0.03404947916666667 min\n",
      "Removing gaps took 0.028017322222391765 min\n",
      "Importing the PDB file took 0.0003658016522725423 min\n",
      "Removing gaps took 0.031992789109547934 min\n",
      "Importing the PDB file took 0.0003777464230855306 min\n",
      "Mapping query sequence and pdb took 0.032594736417134604 min\n",
      "Computing the distance matrix based on the PDB file took 0.004806780815124511 min\n",
      "Removing gaps took 0.02811001936594645 min\n",
      "Importing the PDB file took 0.00037256479263305666 min\n",
      "Mapping query sequence and pdb took 0.028729307651519775 min\n",
      "Computing the distance matrix based on the PDB file took 0.00624004602432251 min\n",
      "Removing gaps took 0.007802200317382812 min\n",
      "Importing the PDB file took 0.00014893213907877603 min\n",
      "Removing gaps took 0.0060182611147562666 min\n",
      "Importing the PDB file took 0.00015851656595865886 min\n",
      "Mapping query sequence and pdb took 0.006341509024302165 min\n",
      "Computing the distance matrix based on the PDB file took 0.0009575883547465006 min\n",
      "Removing gaps took 0.006099859873453776 min\n",
      "Importing the PDB file took 0.00015496412913004558 min\n",
      "Mapping query sequence and pdb took 0.00643157958984375 min\n",
      "Computing the distance matrix based on the PDB file took 0.000999156634012858 min\n"
     ]
    }
   ],
   "source": [
    "from SeqAlignment import SeqAlignment\n",
    "from PDBReference import PDBReference\n",
    "from ContactScorer import ContactScorer, plot_z_scores\n",
    "protein_order = list(summary['Protein_ID'])\n",
    "method_order = ['DCA', 'EVC Standard', 'EVC Mean Field', 'ET-MIp', 'cET-MIp']\n",
    "sequence_separation_order = ['Any', 'Neighbors', 'Short', 'Medium', 'Long']\n",
    "protein_scorers = {}\n",
    "small_comparison_df = None\n",
    "small_comparison_fn = os.path.join(small_set_out_dir, 'Small_Comparision_Data.csv')\n",
    "if os.path.isfile(small_comparison_fn):\n",
    "    small_comparison_df = pd.read_csv(small_comparison_fn, sep='\\t', header=0, index_col=False)\n",
    "else:\n",
    "    for p_id in summary['Protein_ID']:\n",
    "        protein_scorers[p_id] = {}\n",
    "        # Import alignment and remove gaps\n",
    "        full_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id='query_' + p_id)\n",
    "        full_aln.import_alignment()\n",
    "        non_gap_aln = full_aln.remove_gaps()\n",
    "        # Import structure\n",
    "        pdb_structure = PDBReference(pdb_file=generator.protein_data[p_id]['PDB'])\n",
    "        pdb_structure.import_pdb(structure_id=p_id)\n",
    "        protein_scorers[p_id]['Structure'] = pdb_structure\n",
    "        # Initialize Beta Carbon distance scorer\n",
    "        contact_scorer_cb = ContactScorer(query=p_id, seq_alignment=non_gap_aln,\n",
    "                                          pdb_reference=pdb_structure, cutoff=8.0)\n",
    "        contact_scorer_cb.best_chain = generator.protein_data[p_id]['Chain']\n",
    "        contact_scorer_cb.fit()\n",
    "        contact_scorer_cb.measure_distance(method='CB')\n",
    "        protein_scorers[p_id]['Scorer_CB'] = contact_scorer_cb\n",
    "        # Initialize distance scorer minimizing distance between any atoms\n",
    "        contact_scorer_any = ContactScorer(query=p_id, seq_alignment=non_gap_aln,\n",
    "                                           pdb_reference=pdb_structure, cutoff=8.0)\n",
    "        contact_scorer_any.best_chain = generator.protein_data[p_id]['Chain']\n",
    "        contact_scorer_any.fit()\n",
    "        contact_scorer_any.measure_distance(method='Any')\n",
    "        protein_scorers[p_id]['Scorer_Any'] = contact_scorer_any\n",
    "        # Initialize z-scoring subproblems\n",
    "        protein_scorers[p_id]['biased_w2_ave'] = None\n",
    "        protein_scorers[p_id]['unbiased_w2_ave'] = None\n",
    "output_columns = ['Protein', 'Protein Length', 'Alignment Size', 'Method', 'Distance', 'Init Time', 'Import Time', 'Dist Tree Time', 'Trace Time', 'Total Time', \n",
    "                  'Sequence_Separation', 'AUROC', 'AUPRC', 'AUTPRFDRC',\n",
    "                  'Top K Predictions', 'Precision', 'Recall', 'F1 Score',\n",
    "                  'Biased Z-Score at 10%', 'Biased Z-Score at 30%', 'Max Biased Z-Score', 'AUC Biased Z-Score',\n",
    "                  'Unbiased Z-Score at 10%', 'Biased Z-Score at 30%', 'Max Unbiased Z-Score', 'AUC Unbiased Z-Score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Values For Comparision#\n",
    "To determine the effectiveness of the new method and implementation the covariation of the same proteins will be computed using the previous Evolutionary Trace covariation method (ET-MIp) and other methods in the field.\n",
    "\n",
    "## ET-MIp##\n",
    "Scoring the the covariation of the proteins using the previous Evolutionary Trace covariation method (ET-MIp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ETMIPWrapper import ETMIPWrapper\n",
    "import numpy as np\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    old_etmip_out_dir = os.path.join(small_set_out_dir, 'wetc_ET-MIp')\n",
    "    if not os.path.isdir(old_etmip_out_dir):\n",
    "        os.makedirs(old_etmip_out_dir)\n",
    "    old_etmip_method_fn = os.path.join(old_etmip_out_dir, 'wetc_ET-MIp_Method_Data.csv')\n",
    "    if os.path.isfile(old_etmip_method_fn):\n",
    "        old_etmip_method_df = pd.read_csv(old_etmip_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:    \n",
    "        old_etmip_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "        for p_id in summary['Protein_ID']:\n",
    "            print('Attempting to calculate ET-MIp covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(old_etmip_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "                counts['success'] += 1\n",
    "            else:\n",
    "                start_time = time()\n",
    "                curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id='query_' + p_id,\n",
    "                                        polymer_type='Protein')\n",
    "                curr_aln.import_alignment()\n",
    "                curr_etmip = ETMIPWrapper(alignment=curr_aln)\n",
    "                curr_etmip.calculate_scores(out_dir=protein_dir, delete_files=False)\n",
    "                end_time = time()\n",
    "                print('Successfully computed ET-MIp covariance for: {} in {} sec'.format(p_id, end-start))\n",
    "                # Compute statistics for the final scores of the ET-MIp model\n",
    "                protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                    predictor=curr_etmip, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                    unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=2, rank_type='max',\n",
    "                    file_prefix='ET-MIp_Scores_', plots=True)\n",
    "                protein_df2, _, _ = protein_scorers[p_id]['Scorer_Any'].evaluate_predictor(\n",
    "                    predictor=curr_etmip, verbosity=2, out_dir=protein_dir, dist='Any', biased_w2_ave=None,\n",
    "                    unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=2, rank_type='max',\n",
    "                    file_prefix='ET-MIp_Scores_Dist_Any', plots=True)\n",
    "                protein_df = protein_df.append(protein_df2)\n",
    "                # Score Prediction Clustering\n",
    "                z_score_fn = os.path.join(protein_dir, 'ET-MIp_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                z_score_plot_fn = os.path.join(protein_dir, 'ET-MIp_Scores_Dist-Any_{}_ZScores.png')\n",
    "                z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                    1.0 - curr_etmip.coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                    w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                    protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                    1.0 - curr_etmip.coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                    w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                    protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                # Record execution times\n",
    "                protein_df['Init Time'] = None\n",
    "                protein_df['Import Time'] = None\n",
    "                protein_df['Dist Tree Time'] = None\n",
    "                protein_df['Trace Time'] = None\n",
    "                protein_df['Total Time'] = curr_etmip.time\n",
    "                # Record static data for this protein\n",
    "                protein_df['Protein'] = p_id\n",
    "                protein_df['Method'] = 'wetc_ET-MIp'\n",
    "                protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                print('Metrics meastured for ET-MIp covariance for: {}'.format(p_id))\n",
    "                counts['success'] += 1\n",
    "            if old_etmip_method_df is None:\n",
    "                old_etmip_method_df = protein_df\n",
    "            else:\n",
    "                old_etmip_method_df = old_etmip_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        old_etmip_method_df.to_csv(old_etmip_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = old_etmip_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(old_etmip_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ET-MIp (Continued)\n",
    "The previous implementation is not able to run for alignments of the size used here. Instead we use the new implementation with the same parameterization used by the previous implementation (Distance Model - blosum62 similarity, Tree - ET UPGMA variant, Scoring Metric - filtered average product corrected mutual information, Ranks - all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from EvolutionaryTrace import EvolutionaryTrace\n",
    "import numpy as np\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    etmip_out_dir = os.path.join(small_set_out_dir, 'ET-MIp')\n",
    "    if not os.path.isdir(etmip_out_dir):\n",
    "        os.makedirs(etmip_out_dir)\n",
    "    etmip_method_fn = os.path.join(etmip_out_dir, 'ET-MIp_Method_Data.csv')\n",
    "    if os.path.isfile(etmip_method_fn):\n",
    "        etmip_method_df = pd.read_csv(etmip_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:    \n",
    "        etmip_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "        for p_id in generator.protein_data:\n",
    "            print('Attempting to calculate ET-MIp covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(etmip_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "            else:\n",
    "                start_time = time()\n",
    "                curr_etmip = EvolutionaryTrace(query_id='query_' + p_id, polymer_type='Protein',\n",
    "                                               aln_fn=generator.protein_data[p_id]['Final_FA_Aln'], et_distance=True,\n",
    "                                               distance_model='blosum62', tree_building_method='et', tree_building_options={},\n",
    "                                               ranks=None, position_type='pair',\n",
    "                                               scoring_metric='filtered_average_product_corrected_mutual_information',\n",
    "                                               gap_correction=None, out_dir=protein_dir,\n",
    "                                               output_files={'original_aln', 'non_gap_aln', 'tree', 'scores'},\n",
    "                                               processors=10, low_memory=True)\n",
    "                init_time = time()\n",
    "                curr_etmip.import_and_process_aln()\n",
    "                import_time = time()\n",
    "                curr_etmip.compute_distance_matrix_tree_and_assignments()\n",
    "                dist_tree_time = time()\n",
    "                curr_etmip.perform_trace()\n",
    "                end_time = time()\n",
    "                print('Successfully computed ET-MIp covariance for: {}'.format(p_id))\n",
    "                # Compute statistics for the final scores of the ET-MIp model\n",
    "                protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                    predictor=curr_etmip, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                    unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=curr_etmip.scorer.position_size,\n",
    "                    rank_type=curr_etmip.scorer.rank_type, file_prefix='ET-MIp_Scores_', plots=True)\n",
    "                protein_df2, _, _ = protein_scorers[p_id]['Scorer_Any'].evaluate_predictor(\n",
    "                    predictor=curr_etmip, verbosity=2, out_dir=protein_dir, dist='Any', biased_w2_ave=None,\n",
    "                    unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=curr_etmip.scorer.position_size,\n",
    "                    rank_type=curr_etmip.scorer.rank_type, file_prefix='ET-MIp_Scores_Dist_Any', plots=True)\n",
    "                protein_df = protein_df.append(protein_df2)\n",
    "                # Score Prediction Clustering\n",
    "                z_score_fn = os.path.join(protein_dir, 'ET-MIp_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                z_score_plot_fn = os.path.join(protein_dir, 'ET-MIp_Scores_Dist-Any_{}_ZScores.png')\n",
    "                z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                    1.0 - curr_etmip.coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                    w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                    protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                    1.0 - curr_etmip.coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                    w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                    protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                # Record execution times\n",
    "                protein_df['Init Time'] = init_time - start_time\n",
    "                protein_df['Import Time'] = import_time - init_time\n",
    "                protein_df['Dist Tree Time'] = dist_tree_time - import_time\n",
    "                protein_df['Trace Time'] = end_time - dist_tree_time\n",
    "                protein_df['Total Time'] = end_time - start_time\n",
    "                # Record static data for this protein\n",
    "                protein_df['Protein'] = p_id\n",
    "                protein_df['Method'] = 'ET-MIp'\n",
    "                protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                temp_data = os.path.join(protein_dir, 'unique_node_data')\n",
    "                for temp_fn in os.listdir(temp_data):\n",
    "                    if not temp_fn.endswith(\"_pair_rank_filtered_average_product_corrected_mutual_information_score.npz\"):\n",
    "                        os.remove(os.path.join(temp_data, temp_fn))\n",
    "                print('Metrics meastured for ET-MIp covariance for: {}'.format(p_id))\n",
    "                counts['success'] += 1\n",
    "            if etmip_method_df is None:\n",
    "                etmip_method_df = protein_df\n",
    "            else:\n",
    "                etmip_method_df = etmip_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        etmip_method_df.to_csv(etmip_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = etmip_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(etmip_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cET-MIp\n",
    "This segment the ET-MIp method, when constrained to an arbitrary set of nodes (1, 2, 3, 5, 7, 10, 25) at the top of the phylogenetic tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile(small_comparison_fn):\n",
    "    cetmip_out_dir = os.path.join(small_set_out_dir, 'cET-MIp')\n",
    "    if not os.path.isdir(cetmip_out_dir):\n",
    "        os.makedirs(cetmip_out_dir)\n",
    "    cetmip_method_fn = os.path.join(cetmip_out_dir, 'cET-MIp_Method_Data.csv')\n",
    "    if os.path.isfile(cetmip_method_fn):\n",
    "        cetmip_method_df = pd.read_csv(cetmip_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:\n",
    "        cetmip_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0, 'key': 0}\n",
    "        for p_id in generator.protein_data:\n",
    "            print('Attempting to calculate cET-MIp covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(cetmip_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "            else:\n",
    "                start_time = time()\n",
    "                curr_cetmip = EvolutionaryTrace(query_id='query_' + p_id, polymer_type='Protein',\n",
    "                                               aln_fn=generator.protein_data[p_id]['Final_FA_Aln'], et_distance=True,\n",
    "                                               distance_model='blosum62', tree_building_method='et', tree_building_options={},\n",
    "                                               ranks=[1, 2, 3, 5, 7, 10, 25], position_type='pair',\n",
    "                                               scoring_metric='filtered_average_product_corrected_mutual_information',\n",
    "                                               gap_correction=None, out_dir=protein_dir,\n",
    "                                               output_files={'original_aln', 'non_gap_aln', 'tree', 'scores'},\n",
    "                                               processors=10, low_memory=True)\n",
    "                init_time = time()\n",
    "                curr_cetmip.import_and_process_aln()\n",
    "                import_time = time()\n",
    "                curr_cetmip.compute_distance_matrix_tree_and_assignments()\n",
    "                dist_tree_time = time()\n",
    "                curr_cetmip.perform_trace()\n",
    "                end_time = time()\n",
    "                # Compute statistics for the final scores of the ET-MIp model\n",
    "                protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                    predictor=curr_cetmip, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                    unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=curr_cetmip.scorer.position_size,\n",
    "                    rank_type=curr_cetmip.scorer.rank_type, file_prefix='cET-MIp_Scores_', plots=True)\n",
    "                protein_df2, _, _ = protein_scorers[p_id]['Scorer_Any'].evaluate_predictor(\n",
    "                    predictor=curr_cetmip, verbosity=2, out_dir=protein_dir, dist='Any', biased_w2_ave=None,\n",
    "                    unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=curr_cetmip.scorer.position_size,\n",
    "                    rank_type=curr_cetmip.scorer.rank_type, file_prefix='cET-MIp_Scores_Dist_Any', plots=True)\n",
    "                protein_df = protein_df.append(protein_df2)\n",
    "                # Score Prediction Clustering\n",
    "                z_score_fn = os.path.join(protein_dir, 'cET-MIp_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                z_score_plot_fn = os.path.join(protein_dir, 'cET-MIp_Scores_Dist-Any_{}_ZScores.png')\n",
    "                z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                    1.0 - curr_cetmip.coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                    w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                    protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                    1.0 - curr_cetmip.coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                    w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                    protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                # Record execution times\n",
    "                protein_df['Init Time'] = init_time - start_time\n",
    "                protein_df['Import Time'] = import_time - init_time\n",
    "                protein_df['Dist Tree Time'] = dist_tree_time - import_time\n",
    "                protein_df['Trace Time'] = end_time - dist_tree_time\n",
    "                protein_df['Total Time'] = end_time - start_time\n",
    "                # Record static data for this protein\n",
    "                protein_df['Protein'] = p_id\n",
    "                protein_df['Method'] = 'cET-MIp'\n",
    "                protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                temp_data = os.path.join(protein_dir, 'unique_node_data')\n",
    "                for temp_fn in os.listdir(temp_data):\n",
    "                    if not temp_fn.endswith(\"_pair_rank_filtered_average_product_corrected_mutual_information_score.npz\"):\n",
    "                        os.remove(os.path.join(temp_data, temp_fn))\n",
    "                print('Successfully computed cET-MIp covariance for: {}'.format(p_id))\n",
    "                counts['success'] += 1\n",
    "            if cetmip_method_df is None:\n",
    "                cetmip_method_df = protein_df\n",
    "            else:\n",
    "                cetmip_method_df = cetmip_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        cetmip_method_df.to_csv(cetmip_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = cetmip_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(cetmip_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCA##\n",
    "Scoring the the covariation of the proteins using a DCA julia implementation. This uses default parameterization when calling DCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DCAWrapper import DCAWrapper\n",
    "from utils import compute_rank_and_coverage\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    dca_out_dir = os.path.join(small_set_out_dir, 'DCA-DANNY-GDCA-Version')\n",
    "    if not os.path.isdir(dca_out_dir):\n",
    "        os.makedirs(dca_out_dir)\n",
    "    dca_method_fn = os.path.join(dca_out_dir, 'DCA_Method_Data.csv')\n",
    "    if os.path.isfile(dca_method_fn):\n",
    "        dca_method_df = pd.read_csv(dca_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:\n",
    "        dca_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "        for p_id in generator.protein_data:\n",
    "            print('Attempting to calculate DCA covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(dca_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "            else:\n",
    "                curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id='query_' + p_id,\n",
    "                                        polymer_type='Protein')\n",
    "                curr_aln.import_alignment()\n",
    "                # Since the DCA implementation used here does not provide a way to specify the query sequence we remove the gaps\n",
    "                # from the query sequences so positions will be referenced correctly for that sequence (and unnecessary\n",
    "                # computations can be avoided).\n",
    "                curr_aln = curr_aln.remove_gaps()\n",
    "                new_aln_fn = os.path.join(protein_dir, '{}_no_gap.fasta'.format(p_id))\n",
    "                curr_aln.write_out_alignment(new_aln_fn)\n",
    "                curr_aln.file_name = new_aln_fn\n",
    "                curr_dca = DCAWrapper(alignment=curr_aln)\n",
    "                curr_dca.calculate_scores(out_dir=protein_dir, delete_file=False)\n",
    "                # Compute statistics for the final scores of the ET-MIp model\n",
    "                protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                    predictor=curr_dca, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                    unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=2, rank_type='max', file_prefix='DCA_Scores_', plots=True)\n",
    "                protein_df2, _, _ = protein_scorers[p_id]['Scorer_Any'].evaluate_predictor(\n",
    "                    predictor=curr_dca, verbosity=2, out_dir=protein_dir, dist='Any', biased_w2_ave=None,\n",
    "                    unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=2, rank_type='max', file_prefix='DCA_Scores_Dist_Any', plots=True)\n",
    "                protein_df = protein_df.append(protein_df2)\n",
    "                # Score Prediction Clustering\n",
    "                _, dca_coverage  = compute_rank_and_coverage(seq_length=curr_dca.alignment.seq_length, scores=curr_dca.scores, pos_size=2,\n",
    "                    rank_type='max')\n",
    "                z_score_fn = os.path.join(protein_dir, 'DCA_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                z_score_plot_fn = os.path.join(protein_dir, 'DCA_Scores_Dist-Any_{}_ZScores.png')\n",
    "                z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                    1.0 - dca_coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                    w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                    protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                    1.0 - dca_coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                    w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                    protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                # Record execution times\n",
    "                protein_df['Init Time'] = None\n",
    "                protein_df['Import Time'] = None\n",
    "                protein_df['Dist Tree Time'] = None\n",
    "                protein_df['Trace Time'] = None\n",
    "                protein_df['Total Time'] = None\n",
    "                # Record static data for this protein\n",
    "                protein_df['Protein'] = p_id\n",
    "                protein_df['Method'] = 'DCA-Default'\n",
    "                protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                print('Successfully computed DCA covariance for: {}'.format(p_id))\n",
    "                counts['success'] += 1\n",
    "            if dca_method_df is None:\n",
    "                dca_method_df = protein_df\n",
    "            else:\n",
    "                dca_method_df = dca_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        dca_method_df.to_csv(dca_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = dca_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(dca_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCA (continued) ##\n",
    "Scoring the the covariation of the proteins using a DCA julia implementation. This uses a parameterization employed by Benu Atri while working on this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DCAWrapper import DCAWrapper\n",
    "from utils import compute_rank_and_coverage\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    dca_out_dir = os.path.join(small_set_out_dir, 'DCA')\n",
    "    if not os.path.isdir(dca_out_dir):\n",
    "        os.makedirs(dca_out_dir)\n",
    "    dca_method_fn = os.path.join(dca_out_dir, 'DCA_Method_Data.csv')\n",
    "    if os.path.isfile(dca_method_fn):\n",
    "        dca_method_df = pd.read_csv(dca_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:\n",
    "        dca_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "        for p_id in generator.protein_data:\n",
    "            print('Attempting to calculate DCA covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(dca_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "            else:\n",
    "                curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id='query_' + p_id,\n",
    "                                        polymer_type='Protein')\n",
    "                curr_aln.import_alignment()\n",
    "                # Since the DCA implementation used here does not provide a way to specify the query sequence we remove the gaps\n",
    "                # from the query sequences so positions will be referenced correctly for that sequence (and unnecessary\n",
    "                # computations can be avoided).\n",
    "                curr_aln = curr_aln.remove_gaps()\n",
    "                new_aln_fn = os.path.join(protein_dir, '{}_no_gap.fasta'.format(p_id))\n",
    "                curr_aln.write_out_alignment(new_aln_fn)\n",
    "                curr_aln.file_name = new_aln_fn\n",
    "                curr_dca = DCAWrapper(alignment=curr_aln)\n",
    "                curr_dca.calculate_scores(out_dir=protein_dir, delete_file=False)\n",
    "                # Compute statistics for the final scores of the ET-MIp model\n",
    "                protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                    predictor=curr_dca, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                    unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=2, rank_type='max', file_prefix='DCA_Scores_', plots=True)\n",
    "                protein_df2, _, _ = protein_scorers[p_id]['Scorer_Any'].evaluate_predictor(\n",
    "                    predictor=curr_dca, verbosity=2, out_dir=protein_dir, dist='Any', biased_w2_ave=None,\n",
    "                    unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=2, rank_type='max', file_prefix='DCA_Scores_Dist_Any', plots=True)\n",
    "                protein_df = protein_df.append(protein_df2)\n",
    "                # Score Prediction Clustering\n",
    "                _, dca_coverage  = compute_rank_and_coverage(seq_length=curr_dca.alignment.seq_length, scores=curr_dca.scores, pos_size=2,\n",
    "                    rank_type='max')\n",
    "                z_score_fn = os.path.join(protein_dir, 'DCA_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                z_score_plot_fn = os.path.join(protein_dir, 'DCA_Scores_Dist-Any_{}_ZScores.png')\n",
    "                z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                    1.0 - dca_coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                    w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                    protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                    1.0 - dca_coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                    w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                    protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                # Record execution times\n",
    "                protein_df['Init Time'] = None\n",
    "                protein_df['Import Time'] = None\n",
    "                protein_df['Dist Tree Time'] = None\n",
    "                protein_df['Trace Time'] = None\n",
    "                protein_df['Total Time'] = None\n",
    "                # Record static data for this protein\n",
    "                protein_df['Protein'] = p_id\n",
    "                protein_df['Method'] = 'DCA'\n",
    "                protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                print('Successfully computed DCA covariance for: {}'.format(p_id))\n",
    "                counts['success'] += 1\n",
    "            if dca_method_df is None:\n",
    "                dca_method_df = protein_df\n",
    "            else:\n",
    "                dca_method_df = dca_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        dca_method_df.to_csv(dca_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = dca_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(dca_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVCouplings##\n",
    "Scoring the the covariation of the proteins using the EVCouplings method standard protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from EVCouplingsWrapper import EVCouplingsWrapper\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    evc_standard_out_dir = os.path.join(small_set_out_dir, 'EVCouplings_Standard')\n",
    "    if not os.path.isdir(evc_standard_out_dir):\n",
    "        os.makedirs(evc_standard_out_dir)\n",
    "    evc_standard_method_fn = os.path.join(evc_standard_out_dir, 'EVCouplings_Standard_Method_Data.csv')\n",
    "    if os.path.isfile(evc_standard_method_fn):\n",
    "        evc_standard_method_df = pd.read_csv(evc_standard_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:\n",
    "        evc_standard_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "        for p_id in generator.protein_data:\n",
    "            print('Attempting to calculate EV couplings standard protocol covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(evc_standard_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "            else:\n",
    "                curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id='query_' + p_id,\n",
    "                                        polymer_type='Protein')\n",
    "                curr_aln.import_alignment()\n",
    "                curr_evc = EVCouplingsWrapper(alignment=curr_aln, protocol='standard')\n",
    "                curr_evc.calculate_scores(out_dir=protein_dir, cores=10, delete_files=True)\n",
    "                # Compute statistics for the final scores of the ET-MIp model\n",
    "                protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                    predictor=curr_evc, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                    unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=2,\n",
    "                    rank_type='max', file_prefix='EVC_Standard_Scores_', plots=True)\n",
    "                protein_df2, _, _ = protein_scorers[p_id]['Scorer_Any'].evaluate_predictor(\n",
    "                    predictor=curr_evc, verbosity=2, out_dir=protein_dir, dist='Any', biased_w2_ave=None,\n",
    "                    unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=2,\n",
    "                    rank_type='max', file_prefix='EVC_Standard_Scores_Dist_Any', plots=True)\n",
    "                protein_df = protein_df.append(protein_df2)\n",
    "                # Score Prediction Clustering\n",
    "                _, evc_standard_coverage  = compute_rank_and_coverage(seq_length=curr_evc.alignment.seq_length, scores=curr_evc.scores, pos_size=2,\n",
    "                    rank_type='max')\n",
    "                z_score_fn = os.path.join(protein_dir, 'EVC_Standard_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                z_score_plot_fn = os.path.join(protein_dir, 'EVC_Standard_Scores_Dist-Any_{}_ZScores.png')\n",
    "                z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                    1.0 - evc_standard_coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                    w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                    protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                    1.0 - evc_standard_coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                    w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                    protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                # Record execution times\n",
    "                protein_df['Init Time'] = None\n",
    "                protein_df['Import Time'] = None\n",
    "                protein_df['Dist Tree Time'] = None\n",
    "                protein_df['Trace Time'] = None\n",
    "                protein_df['Total Time'] = None\n",
    "                # Record static data for this protein\n",
    "                protein_df['Protein'] = p_id\n",
    "                protein_df['Method'] = 'EVC Standard'\n",
    "                protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                print('Successfully computed EV couplings standard protocol covariance for: {}'.format(p_id))\n",
    "                counts['success'] += 1\n",
    "            if evc_standard_method_df is None:\n",
    "                evc_standard_method_df = protein_df\n",
    "            else:\n",
    "                evc_standard_method_df = evc_standard_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        evc_standard_method_df.to_csv(evc_standard_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = evc_standard_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(evc_standard_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring the covariation of the proteins using the EVCouplings method mean field protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(small_comparison_fn):\n",
    "    evc_mf_out_dir = os.path.join(small_set_out_dir, 'EVCouplings_Mean_Field')\n",
    "    if not os.path.isdir(evc_mf_out_dir):\n",
    "        os.makedirs(evc_mf_out_dir)\n",
    "    evc_mf_method_fn = os.path.join(evc_mf_out_dir, 'EVCouplings_Mean_Field_Method_Data.csv')\n",
    "    if os.path.isfile(evc_mf_method_fn):\n",
    "        evc_mf_method_df = pd.read_csv(evc_mf_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:\n",
    "        evc_mf_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0, 'type': 0}\n",
    "        for p_id in generator.protein_data:\n",
    "            print('Attempting to calculate EV couplings covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(evc_mf_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id='query_' + p_id,\n",
    "                                    polymer_type='Protein')\n",
    "            curr_aln.import_alignment()\n",
    "            curr_evc = EVCouplingsWrapper(alignment=curr_aln, protocol='mean_field')\n",
    "            curr_evc.calculate_scores(out_dir=protein_dir, cores=10, delete_files=True)\n",
    "            # Compute statistics for the final scores of the ET-MIp model\n",
    "            protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                predictor=curr_evc, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=2, rank_type='max',\n",
    "                file_prefix='EVC_Mean_Field_Scores_', plots=True)\n",
    "            protein_df2, _, _ = protein_scorers[p_id]['Scorer_Any'].evaluate_predictor(\n",
    "                predictor=curr_evc, verbosity=2, out_dir=protein_dir, dist='Any', biased_w2_ave=None,\n",
    "                unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=2, rank_type='max',\n",
    "                file_prefix='EVC_Mean_Field_Scores_Dist_Any', plots=True)\n",
    "            protein_df = protein_df.append(protein_df2)\n",
    "            # Score Prediction Clustering\n",
    "            _, evc_mf_coverage  = compute_rank_and_coverage(seq_length=curr_evc.alignment.seq_length, scores=curr_evc.scores, pos_size=2,\n",
    "                rank_type='max')\n",
    "            z_score_fn = os.path.join(protein_dir, 'EVC_Mean_Field_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "            z_score_plot_fn = os.path.join(protein_dir, 'EVC_Mean_Field_Scores_Dist-Any_{}_ZScores.png')\n",
    "            z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                1.0 - evc_mf_coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "            if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                    protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "            biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "            protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "            protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "            protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "            protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "            plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "            z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                1.0 - evc_mf_coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "            if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                    protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "            unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "            protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "            protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "            protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "            protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "            plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "            # Record execution times\n",
    "            protein_df['Init Time'] = None\n",
    "            protein_df['Import Time'] = None\n",
    "            protein_df['Dist Tree Time'] = None\n",
    "            protein_df['Trace Time'] = None\n",
    "            protein_df['Total Time'] = None\n",
    "            # Record static data for this protein\n",
    "            protein_df['Protein'] = p_id\n",
    "            protein_df['Method'] = 'EVC Mean Field'\n",
    "            protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "            protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "            print('Successfully computed EV couplings covariance for: {}'.format(p_id))\n",
    "            counts['success'] += 1\n",
    "            if evc_mf_method_df is None:\n",
    "                evc_mf_method_df = protein_df\n",
    "            else:\n",
    "                evc_mf_method_df = evc_mf_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors\\n{}\\tType Errors'.format(counts['success'], counts['value'],\n",
    "                                                                                              counts['attribute'], counts['type']))\n",
    "        evc_mf_method_df.to_csv(evc_mf_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = evc_mf_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(evc_mf_method_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out final comparison data so it can be loaded later for generating figures.\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    small_comparison_df['Protein Length'] = small_comparison_df['Protein'].apply(lambda x: generator.protein_data[x]['Length'])\n",
    "    small_comparison_df.to_csv(small_comparison_fn, sep='\\t', header=True, index=False, columns=output_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Execution Time for ET-MIp and cET-MIp\n",
    "The time to compute the trace for the full phylogenetic tree and the trace constrained to a subset of the top levels should take significantly less time to compute, here we evaluate if that is in fact the case or not.\n",
    "\n",
    "## Data Cleaning\n",
    "At least one protein in this data set has a very small alignment and could not be evaluated by cET-MIp because the tree was too small to each the levels set for other proteins. Here we remove those proteins.\n",
    "\n",
    "In addition since this analysis focuses on times and there are many other types of data (some of which cause redundancies in the time data), we will use this opportunity to subset the data and drop duplicates.\n",
    "\n",
    "Finally, for some it will be more informative to view execution time in terms of minutes or hours, as opposed to the originally reported seconds, so we will add columns for these units as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_method_groups = small_comparison_df[['Protein', 'Method']].drop_duplicates().groupby('Protein').count()\n",
    "method_max = protein_method_groups['Method'].max()\n",
    "proteins_to_keep = protein_method_groups.index[protein_method_groups['Method'] == method_max]\n",
    "comparable_method_proteins = small_comparison_df[small_comparison_df['Protein'].isin(proteins_to_keep)]\n",
    "time_columns = ['Protein', 'Protein Length', 'Alignment Size', 'Method', 'Init Time', 'Import Time', 'Dist Tree Time',\n",
    "                'Trace Time', 'Total Time']\n",
    "time_subset_df = comparable_method_proteins.loc[comparable_method_proteins['Method'].isin(['ET-MIp', 'cET-MIp']), time_columns]\n",
    "time_subset_df['Total Time (min)'] = time_subset_df['Total Time'].apply(lambda x: x / 60.0)\n",
    "time_subset_df['Total Time (hr)'] = time_subset_df['Total Time (min)'].apply(lambda x: x / 60.0)\n",
    "time_columns += ['Total Time (min)', 'Total Time (hr)']\n",
    "time_subset_df = time_subset_df.drop_duplicates(subset=None, inplace=False, keep='first')\n",
    "time_subset_df.to_csv(os.path.join(small_set_out_dir, 'Small_Time_Comaprison_Data.csv'), sep='\\t', header=True, index=False,\n",
    "                      columns=time_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Comparison\n",
    "Now that only comparable proteins are present in the data we compare the runtime of individual proteins by method, ordered by their length and the size of their alignemnts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Displayed by protein length order\n",
    "protein_length_order = comparable_method_proteins.sort_values('Protein Length')['Protein'].unique()\n",
    "protein_length_time_plot = sns.barplot(x='Protein', y='Total Time', hue='Method', order=protein_length_order,\n",
    "                                       hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_length_time_plot.set_xticklabels(protein_length_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_length_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Length_Time_Comparison_Sec.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "protein_length_time_plot = sns.barplot(x='Protein', y='Total Time (min)', hue='Method', order=protein_length_order,\n",
    "                                       hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_length_time_plot.set_xticklabels(protein_length_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_length_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Length_Time_Comparison_Min.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "protein_length_time_plot = sns.barplot(x='Protein', y='Total Time (hr)', hue='Method', order=protein_length_order,\n",
    "                                       hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_length_time_plot.set_xticklabels(protein_length_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_length_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Length_Time_Comparison_Hr.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Displayed by alignment size order\n",
    "protein_alignment_order = comparable_method_proteins.sort_values('Alignment Size')['Protein'].unique()\n",
    "protein_alignment_time_plot = sns.barplot(x='Protein', y='Total Time', hue='Method', order=protein_alignment_order,\n",
    "                                          hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_alignment_time_plot.set_xticklabels(protein_alignment_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_alignment_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Alignment_Time_Comparison_Sec.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "protein_alignment_time_plot = sns.barplot(x='Protein', y='Total Time (min)', hue='Method', order=protein_alignment_order,\n",
    "                                          hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_alignment_time_plot.set_xticklabels(protein_alignment_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_alignment_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Alignment_Time_Comparison_Min.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "protein_alignment_time_plot = sns.barplot(x='Protein', y='Total Time (hr)', hue='Method', order=protein_alignment_order,\n",
    "                                          hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_alignment_time_plot.set_xticklabels(protein_alignment_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_alignment_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Alignment_Time_Comparison_Hr.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall comparison of time by method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of ET-MIp and cET-MIp total computation time (sec).\n",
    "protein_method_comp_plot = sns.boxplot(x='Method', y='Total Time', order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_method_comp_plot.set_xticklabels(protein_method_comp_plot.get_xticklabels(), rotation=90)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_Time_Comparison_Sec.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Comparison of ET-MIp and cET-MIp total computation time (sec).\n",
    "protein_method_comp_plot = sns.boxplot(x='Method', y='Total Time (min)', order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_method_comp_plot.set_xticklabels(protein_method_comp_plot.get_xticklabels(), rotation=90)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_Time_Comparison_Min.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Comparison of ET-MIp and cET-MIp total computation time (sec).\n",
    "protein_method_comp_plot = sns.boxplot(x='Method', y='Total Time (hr)', order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_method_comp_plot.set_xticklabels(protein_method_comp_plot.get_xticklabels(), rotation=90)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_Time_Comparison_Hr.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Statistical comparison\n",
    "from scipy.stats import wilcoxon\n",
    "et_mip_sub_df = time_subset_df[time_subset_df['Method'] == 'ET-MIp']\n",
    "cet_mip_sub_df = time_subset_df[time_subset_df['Method'] == 'cET-MIp']\n",
    "sec_stat, sec_p_val = wilcoxon(x=et_mip_sub_df['Total Time'], y=cet_mip_sub_df['Total Time'], zero_method='wilcox')\n",
    "min_stat, min_p_val = wilcoxon(x=et_mip_sub_df['Total Time (min)'], y=cet_mip_sub_df['Total Time (min)'], zero_method='wilcox')\n",
    "hr_stat, hr_p_val = wilcoxon(x=et_mip_sub_df['Total Time (hr)'], y=cet_mip_sub_df['Total Time (hr)'], zero_method='wilcox')\n",
    "time_statistics = {'Time Unit': ['sec', 'min', 'hr'], 'Statistic': [sec_stat, min_stat, hr_stat], 'P-Value': [sec_p_val, min_p_val, hr_p_val]}\n",
    "pd.DataFrame(time_statistics).to_csv(os.path.join(small_set_out_dir, 'Small_Time_Comaprison_Statistics.csv'), sep='\\t', header=True,\n",
    "                                     index=False, columns=['Time Unit', 'Statistic', 'P-Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method Comparison\n",
    "We now begin comparing methods based on their ability to predict the structural contacts in the proteins in this test set. There is an important consideration in the case of sequence separation and different measures by which to compare the methods.\n",
    "\n",
    "### Data Cleaning\n",
    "These data need an additional cleaning step beyond what was performed for the timing comparison. Since there are multiple categories of sequence separation and some proteins may not have any True Positive contacts for a category the scoring for that protein is incomplete. We will remove all such proteins from the comparison, performing the clean up separate for each metric of success. Another contributing factor which necessitates this kind of cleaning is assessment of the top K predictions for a protein or best L/K predictions which for poor predictions may not include any predictions of True Positives.\n",
    "\n",
    "### Sequence Separation\n",
    "One important consideration for the difficulty of prediction and interest in predictions is the distance between the residues for which coupling was predicted. As has been documented in the literature, especially in the CASP competitions, there are several categories of prediction:\n",
    "* Neighbors (1 - 5 residues apart) - This is the least interesting category of predictions. It is highly likely that residues this close together will show covariance signal. Predicting two residues are in contact that are this close together is trivial and uninformative.\n",
    "* Short (6 - 12 residues apart) - This is also not a very interesting type of prediction. Residues this close in proximity can be more easily modeled by alogrithms which focus on 2D protein structure modeling (identifying beta sheets, alpha helices, etc.).\n",
    "* Medium (13 - 24 residues apart) - This is a more interesting type of prediction. The resiudes in this range of separation are on the edge of the 2D protein structure prediction range.\n",
    "* Long (24 and more residues apart) - The most interesting category of predictions. Resiudes this far apart are not easily modeled by 2D protein structure modeling systems. They are also very useful for 3D and 4D protein structure prediction becausae they provide constraints on potential protein (similar to NMR data) folds which makes protein folding a more tractable problem for modelers.\n",
    "* Any/All - All categories can be considered at once, this provides a summary value, but is often skewed by one particularly good category of predictions.\n",
    "\n",
    "### Metrics of Success\n",
    "* AUROC - This measures the True Positive Rate vs the False Positive Rate of prediction, it can be considered a measure of the accuracy of the measure. This can be strongly influenced by the class imbalance which is present when predicting structural contacts since there are many fewer contacts than non-contacts. The True Positive case is if the C-beta of two amino acids is within 8.0 Angstroms of one another (as is done in the CASP competitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_order = ['DCA-Default', 'DCA', 'wetc_ET-MIp', 'ET-MIp', 'cET-MIp', 'EVC Standard', 'EVC Mean Field']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_columns = ['Protein', 'Method', 'Distance', 'Sequence_Separation', 'AUROC']\n",
    "protein_auroc_groups = comparable_method_proteins[auroc_columns].drop_duplicates().groupby('Protein')['AUROC'].apply(\n",
    "    lambda x: not x.isnull().any())\n",
    "complete_proteins = protein_auroc_groups.index[protein_auroc_groups.values]\n",
    "comparable_auroc_proteins = small_comparison_df[small_comparison_df['Protein'].isin(complete_proteins)]\n",
    "auroc_protein_length_order = [x for x in protein_length_order if x in complete_proteins]\n",
    "auroc_protein_alignment_order = [x for x in protein_alignment_order if x in complete_proteins]\n",
    "auroc_subset_df = comparable_auroc_proteins.loc[:, auroc_columns].drop_duplicates()\n",
    "auroc_subset_df = auroc_subset_df.loc[auroc_subset_df['Distance'] == 'CB', :]\n",
    "# Plot the methods vs AUROC per protein ordered by protein length\n",
    "auroc_subset_df.to_csv(os.path.join(small_set_out_dir, 'Small_AUROC_Comaprison_Data.csv'), sep='\\t', header=True, index=False,\n",
    "                       columns=auroc_columns)\n",
    "protein_order_auroc_plot = sns.catplot(x=\"Protein\", y=\"AUROC\", hue=\"Method\", row=\"Sequence_Separation\", data=auroc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auroc_protein_length_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "protein_order_auroc_plot.set_xticklabels(auroc_protein_length_order, rotation=90)\n",
    "protein_order_auroc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUROC_Comparison_Protein_Length_Order.png'),\n",
    "                                 bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUROC per protein ordered by protein alignment size\n",
    "alignment_order_auroc_plot = sns.catplot(x=\"Protein\", y=\"AUROC\", hue=\"Method\", row=\"Sequence_Separation\", data=auroc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auroc_protein_alignment_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "alignment_order_auroc_plot.set_xticklabels(auroc_protein_alignment_order, rotation=90)\n",
    "alignment_order_auroc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUROC_Comparison_Alignment_Size_Order.png'),\n",
    "                                   bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUROC grouped together to see overall trends\n",
    "overall_auroc_plot = sns.boxplot(x=\"Sequence_Separation\", y=\"AUROC\", hue=\"Method\", data=auroc_subset_df,\n",
    "                                 order=sequence_separation_order, hue_order=method_order)\n",
    "overall_auroc_plot.set_xticklabels(sequence_separation_order, rotation=90)\n",
    "overall_auroc_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUROC_Comparison.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Compute statistics comparing methods at each sequence separation\n",
    "auroc_statistics = {'Sequence Separation': [], 'Method 1': [], 'Method 2': [], 'Statistic': [], 'P-Value': []}\n",
    "for sep in sequence_separation_order:\n",
    "    sep_auroc_subset_df = auroc_subset_df.loc[auroc_subset_df['Sequence_Separation'] == sep, :]\n",
    "    for i in range(len(method_order)):\n",
    "        m1_sep_auroc_subset_df = sep_auroc_subset_df.loc[sep_auroc_subset_df['Method'] == method_order[i], :]\n",
    "        for j in range(i + 1, len(method_order)):\n",
    "            m2_sep_auroc_subset_df = sep_auroc_subset_df.loc[sep_auroc_subset_df['Method'] == method_order[j], :]\n",
    "            try:\n",
    "                stat, p_val = wilcoxon(x=m1_sep_auroc_subset_df['AUROC'], y=m2_sep_auroc_subset_df['AUROC'], zero_method='wilcox')\n",
    "            except ValueError:\n",
    "                stat, p_val = None, None\n",
    "                print('Cannot compare: {} and {} size miss match: {} vs {}'.format(method_order[i], method_order[j],\n",
    "                                                                                   len(m1_sep_auroc_subset_df['AUROC']),\n",
    "                                                                                   len(m2_sep_auroc_subset_df['AUROC'])))\n",
    "            auroc_statistics['Sequence Separation'].append(sep)\n",
    "            auroc_statistics['Method 1'].append(method_order[i])\n",
    "            auroc_statistics['Method 2'].append(method_order[j])\n",
    "            auroc_statistics['Statistic'].append(stat)\n",
    "            auroc_statistics['P-Value'].append(p_val)\n",
    "pd.DataFrame(auroc_statistics).to_csv(os.path.join(small_set_out_dir, 'Small_AUROC_Comaprison_Statistics.csv'), sep='\\t', header=True,\n",
    "                                      index=False, columns=['Sequence Separation', 'Method 1', 'Method 2', 'Statistic', 'P-Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "auroc_columns = ['Protein', 'Method', 'Distance', 'Sequence_Separation', 'AUROC']\n",
    "protein_auroc_groups = comparable_method_proteins[auroc_columns].drop_duplicates().groupby('Protein')['AUROC'].apply(\n",
    "    lambda x: not x.isnull().any())\n",
    "complete_proteins = protein_auroc_groups.index[protein_auroc_groups.values]\n",
    "comparable_auroc_proteins = small_comparison_df[small_comparison_df['Protein'].isin(complete_proteins)]\n",
    "auroc_protein_length_order = [x for x in protein_length_order if x in complete_proteins]\n",
    "auroc_protein_alignment_order = [x for x in protein_alignment_order if x in complete_proteins]\n",
    "auroc_subset_df = comparable_auroc_proteins.loc[:, auroc_columns].drop_duplicates(subset=['Protein', 'Method', 'Sequence_Separation', 'Distance'])\n",
    "auroc_subset_df = auroc_subset_df.loc[auroc_subset_df['Distance'] == 'Any', :]\n",
    "# Plot the methods vs AUROC per protein ordered by protein length\n",
    "auroc_subset_df.to_csv(os.path.join(small_set_out_dir, 'Small_AUROC_Comaprison_Data_Dist_Any.csv'), sep='\\t', header=True, index=False,\n",
    "                       columns=auroc_columns)\n",
    "protein_order_auroc_plot = sns.catplot(x=\"Protein\", y=\"AUROC\", hue=\"Method\", row=\"Sequence_Separation\", data=auroc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auroc_protein_length_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "protein_order_auroc_plot.set_xticklabels(auroc_protein_length_order, rotation=90)\n",
    "protein_order_auroc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUROC_Comparison_Protein_Length_Order_Dist_Any.png'),\n",
    "                                 bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUROC per protein ordered by protein alignment size\n",
    "alignment_order_auroc_plot = sns.catplot(x=\"Protein\", y=\"AUROC\", hue=\"Method\", row=\"Sequence_Separation\", data=auroc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auroc_protein_alignment_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "alignment_order_auroc_plot.set_xticklabels(auroc_protein_alignment_order, rotation=90)\n",
    "alignment_order_auroc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUROC_Comparison_Alignment_Size_Order_Dist_Any.png'),\n",
    "                                   bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUROC grouped together to see overall trends\n",
    "overall_auroc_plot = sns.boxplot(x=\"Sequence_Separation\", y=\"AUROC\", hue=\"Method\", data=auroc_subset_df,\n",
    "                                 order=sequence_separation_order, hue_order=method_order)\n",
    "overall_auroc_plot.set_xticklabels(sequence_separation_order, rotation=90)\n",
    "overall_auroc_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUROC_Comparison_Dist_Any.png'), bbox_inches='tight', transparent=True,\n",
    "            dpi=300)\n",
    "plt.close()\n",
    "# Compute statistics comparing methods at each sequence separation\n",
    "auroc_statistics = {'Sequence Separation': [], 'Method 1': [], 'Method 2': [], 'Statistic': [], 'P-Value': []}\n",
    "for sep in sequence_separation_order:\n",
    "    sep_auroc_subset_df = auroc_subset_df.loc[auroc_subset_df['Sequence_Separation'] == sep, :]\n",
    "    for i in range(len(method_order)):\n",
    "        m1_sep_auroc_subset_df = sep_auroc_subset_df.loc[sep_auroc_subset_df['Method'] == method_order[i], :]\n",
    "        m1_sep_auroc_subset_df.drop_duplicates(inplace=True)\n",
    "        for j in range(i + 1, len(method_order)):\n",
    "            m2_sep_auroc_subset_df = sep_auroc_subset_df.loc[sep_auroc_subset_df['Method'] == method_order[j], :]\n",
    "            m2_sep_auroc_subset_df.drop_duplicates(inplace=True)\n",
    "            try:\n",
    "                stat, p_val = wilcoxon(x=m1_sep_auroc_subset_df['AUROC'], y=m2_sep_auroc_subset_df['AUROC'], zero_method='wilcox')\n",
    "            except ValueError:\n",
    "                stat, p_val = None, None\n",
    "                print('Cannot compare: {} and {} size miss match: {} vs {}'.format(method_order[i], method_order[j],\n",
    "                                                                                   len(m1_sep_auroc_subset_df['AUROC']),\n",
    "                                                                                   len(m2_sep_auroc_subset_df['AUROC'])))\n",
    "            auroc_statistics['Sequence Separation'].append(sep)\n",
    "            auroc_statistics['Method 1'].append(method_order[i])\n",
    "            auroc_statistics['Method 2'].append(method_order[j])\n",
    "            auroc_statistics['Statistic'].append(stat)\n",
    "            auroc_statistics['P-Value'].append(p_val)\n",
    "pd.DataFrame(auroc_statistics).to_csv(os.path.join(small_set_out_dir, 'Small_AUROC_Comaprison_Statistics_Dist_any.csv'), sep='\\t',\n",
    "                                      header=True, index=False,\n",
    "                                      columns=['Sequence Separation', 'Method 1', 'Method 2', 'Statistic', 'P-Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics of Success (Continued)\n",
    "* AUPRC - This measures the Precision vs the Recall of the predictions, it can be considered a measure of the accuracy of the measure. This is less strongly influenced by the class imbalance which is present when predicting structural contacts since there are many fewer contacts than non-contacts. The True Positive case is if the C-beta of two amino acids is within 8.0 Angstroms of one another (as is done in the CASP competitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot compare: DCA-Default and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: DCA and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: wetc_ET-MIp and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: ET-MIp and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: cET-MIp and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: EVC Standard and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: DCA-Default and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: DCA and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: wetc_ET-MIp and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: ET-MIp and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: cET-MIp and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: EVC Standard and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: DCA-Default and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: DCA and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: wetc_ET-MIp and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: ET-MIp and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: cET-MIp and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: EVC Standard and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: DCA-Default and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: DCA and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: wetc_ET-MIp and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: ET-MIp and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: cET-MIp and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: EVC Standard and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: DCA-Default and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: DCA and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: wetc_ET-MIp and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: ET-MIp and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: cET-MIp and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n",
      "Cannot compare: EVC Standard and EVC Mean Field size miss match: 22 vs 22\n",
      "Unequal N in wilcoxon.  Aborting.\n"
     ]
    }
   ],
   "source": [
    "auprc_columns = ['Protein', 'Method', 'Distance', 'Sequence_Separation', 'AUPRC']\n",
    "protein_auprc_groups = comparable_method_proteins[auprc_columns].drop_duplicates().groupby('Protein')['AUPRC'].apply(\n",
    "    lambda x: not x.isnull().any())\n",
    "complete_proteins = protein_auprc_groups.index[protein_auprc_groups.values]\n",
    "comparable_auprc_proteins = small_comparison_df[small_comparison_df['Protein'].isin(complete_proteins)]\n",
    "auprc_protein_length_order = [x for x in protein_length_order if x in complete_proteins]\n",
    "auprc_protein_alignment_order = [x for x in protein_alignment_order if x in complete_proteins]\n",
    "auprc_subset_df = comparable_auprc_proteins.loc[:, auprc_columns].drop_duplicates(subset=['Protein', 'Method', 'Sequence_Separation', 'Distance'])\n",
    "auprc_subset_df = auprc_subset_df.loc[auprc_subset_df['Distance'] == 'CB', :]\n",
    "# Plot the methods vs AUPRC per protein ordered by protein length\n",
    "auprc_subset_df.to_csv(os.path.join(small_set_out_dir, 'Small_AUPRC_Comaprison_Data.csv'), sep='\\t', header=True, index=False,\n",
    "                       columns=auprc_columns)\n",
    "protein_order_auprc_plot = sns.catplot(x=\"Protein\", y=\"AUPRC\", hue=\"Method\", row=\"Sequence_Separation\", data=auprc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auprc_protein_length_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "protein_order_auprc_plot.set_xticklabels(auprc_protein_length_order, rotation=90)\n",
    "protein_order_auprc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUPRC_Comparison_Protein_Length_Order.png'),\n",
    "                                 bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUPRC per protein ordered by protein alignment size\n",
    "alignment_order_auprc_plot = sns.catplot(x=\"Protein\", y=\"AUPRC\", hue=\"Method\", row=\"Sequence_Separation\", data=auprc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auprc_protein_alignment_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "alignment_order_auprc_plot.set_xticklabels(auprc_protein_alignment_order, rotation=90)\n",
    "alignment_order_auprc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUPRC_Comparison_Alignment_Size_Order.png'),\n",
    "                                   bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUPRC grouped together to see overall trends\n",
    "overall_auprc_plot = sns.boxplot(x=\"Sequence_Separation\", y=\"AUPRC\", hue=\"Method\", data=auprc_subset_df,\n",
    "                                 order=sequence_separation_order, hue_order=method_order)\n",
    "overall_auprc_plot.set_xticklabels(sequence_separation_order, rotation=90)\n",
    "overall_auprc_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUPRC_Comparison.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Compute statistics comparing methods at each sequence separation\n",
    "auprc_statistics = {'Sequence Separation': [], 'Method 1': [], 'Method 2': [], 'Statistic': [], 'P-Value': []}\n",
    "for sep in sequence_separation_order:\n",
    "    sep_auprc_subset_df = auprc_subset_df.loc[auprc_subset_df['Sequence_Separation'] == sep, :]\n",
    "    for i in range(len(method_order)):\n",
    "        m1_sep_auprc_subset_df = sep_auprc_subset_df.loc[sep_auprc_subset_df['Method'] == method_order[i], :]\n",
    "        for j in range(i + 1, len(method_order)):\n",
    "            m2_sep_auprc_subset_df = sep_auprc_subset_df.loc[sep_auprc_subset_df['Method'] == method_order[j], :]\n",
    "            try:\n",
    "                stat, p_val = wilcoxon(x=m1_sep_auprc_subset_df['AUPRC'], y=m2_sep_auprc_subset_df['AUPRC'], zero_method='wilcox')\n",
    "            except ValueError as e:\n",
    "                stat, p_val = None, None\n",
    "                print('Cannot compare: {} and {} size miss match: {} vs {}'.format(method_order[i], method_order[j],\n",
    "                                                                                   len(m1_sep_auroc_subset_df['AUROC']),\n",
    "                                                                                   len(m2_sep_auroc_subset_df['AUROC'])))\n",
    "            auprc_statistics['Sequence Separation'].append(sep)\n",
    "            auprc_statistics['Method 1'].append(method_order[i])\n",
    "            auprc_statistics['Method 2'].append(method_order[j])\n",
    "            auprc_statistics['Statistic'].append(stat)\n",
    "            auprc_statistics['P-Value'].append(p_val)\n",
    "pd.DataFrame(auprc_statistics).to_csv(os.path.join(small_set_out_dir, 'Small_AUPRC_Comaprison_Statistics.csv'), sep='\\t', header=True,\n",
    "                                      index=False, columns=['Sequence Separation', 'Method 1', 'Method 2', 'Statistic', 'P-Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "auprc_columns = ['Protein', 'Method', 'Distance', 'Sequence_Separation', 'AUPRC']\n",
    "protein_auprc_groups = comparable_method_proteins[auprc_columns].drop_duplicates().groupby('Protein')['AUPRC'].apply(\n",
    "    lambda x: not x.isnull().any())\n",
    "complete_proteins = protein_auprc_groups.index[protein_auprc_groups.values]\n",
    "comparable_auprc_proteins = small_comparison_df[small_comparison_df['Protein'].isin(complete_proteins)]\n",
    "auprc_protein_length_order = [x for x in protein_length_order if x in complete_proteins]\n",
    "auprc_protein_alignment_order = [x for x in protein_alignment_order if x in complete_proteins]\n",
    "auprc_subset_df = comparable_auprc_proteins.loc[:, auprc_columns].drop_duplicates(subset=['Protein', 'Method', 'Sequence_Separation', 'Distance'])\n",
    "auprc_subset_df = auprc_subset_df.loc[auprc_subset_df['Distance'] == 'Any', :]\n",
    "# Plot the methods vs AUPRC per protein ordered by protein length\n",
    "auprc_subset_df.to_csv(os.path.join(small_set_out_dir, 'Small_AUPRC_Comaprison_Data_Dist_Any.csv'), sep='\\t', header=True, index=False,\n",
    "                       columns=auprc_columns)\n",
    "protein_order_auprc_plot = sns.catplot(x=\"Protein\", y=\"AUPRC\", hue=\"Method\", row=\"Sequence_Separation\", data=auprc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auprc_protein_length_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "protein_order_auprc_plot.set_xticklabels(auprc_protein_length_order, rotation=90)\n",
    "protein_order_auprc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUPRC_Comparison_Protein_Length_Order_Dist_Any.png'),\n",
    "                                 bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUPRC per protein ordered by protein alignment size\n",
    "alignment_order_auprc_plot = sns.catplot(x=\"Protein\", y=\"AUPRC\", hue=\"Method\", row=\"Sequence_Separation\", data=auprc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auprc_protein_alignment_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "alignment_order_auprc_plot.set_xticklabels(auprc_protein_alignment_order, rotation=90)\n",
    "alignment_order_auprc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUPRC_Comparison_Alignment_Size_Order_Dist_Any.png'),\n",
    "                                   bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUPRC grouped together to see overall trends\n",
    "overall_auprc_plot = sns.boxplot(x=\"Sequence_Separation\", y=\"AUPRC\", hue=\"Method\", data=auprc_subset_df,\n",
    "                                 order=sequence_separation_order, hue_order=method_order)\n",
    "overall_auprc_plot.set_xticklabels(sequence_separation_order, rotation=90)\n",
    "overall_auprc_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUPRC_Comparison_Dist_Any.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Compute statistics comparing methods at each sequence separation\n",
    "auprc_statistics = {'Sequence Separation': [], 'Method 1': [], 'Method 2': [], 'Statistic': [], 'P-Value': []}\n",
    "for sep in sequence_separation_order:\n",
    "    sep_auprc_subset_df = auprc_subset_df.loc[auprc_subset_df['Sequence_Separation'] == sep, :]\n",
    "    for i in range(len(method_order)):\n",
    "        if method_order[i] == 'EVC Mean Field':\n",
    "            continue\n",
    "        m1_sep_auprc_subset_df = sep_auprc_subset_df.loc[sep_auprc_subset_df['Method'] == method_order[i], :]\n",
    "        for j in range(i + 1, len(method_order)):\n",
    "            if method_order[j] == 'EVC Mean Field':\n",
    "                continue\n",
    "            m2_sep_auprc_subset_df = sep_auprc_subset_df.loc[sep_auprc_subset_df['Method'] == method_order[j], :]\n",
    "            stat, p_val = wilcoxon(x=m1_sep_auprc_subset_df['AUPRC'], y=m2_sep_auprc_subset_df['AUPRC'], zero_method='wilcox')\n",
    "            auprc_statistics['Sequence Separation'].append(sep)\n",
    "            auprc_statistics['Method 1'].append(method_order[i])\n",
    "            auprc_statistics['Method 2'].append(method_order[j])\n",
    "            auprc_statistics['Statistic'].append(stat)\n",
    "            auprc_statistics['P-Value'].append(p_val)\n",
    "pd.DataFrame(auprc_statistics).to_csv(os.path.join(small_set_out_dir, 'Small_AUPRC_Comaprison_Statistics_Dist_Any.csv'), sep='\\t',\n",
    "                                      header=True, index=False,\n",
    "                                      columns=['Sequence Separation', 'Method 1', 'Method 2', 'Statistic', 'P-Value'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (PyET3)",
   "language": "python",
   "name": "pyet3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
