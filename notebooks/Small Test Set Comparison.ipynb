{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Test Set #\n",
    "## Goal ##\n",
    "The goal of this test set is to perform proof of concept testing on a small number of proteins with a wide range of sizes and available homologs, orthologs, and paralogs. By doing so it should be possible to test the best parameterization for this tool as well as identifying the strengths and weaknesses of the tool using various measurments as end points.\n",
    "## Warning ##\n",
    "Before attempting to use this notebook make sure that your .env file has been properly setup to reflect the correct locations of command line tools and the location of files and directories needed for execution.\n",
    "### Initial Import###\n",
    "This first cell performs the necessary imports required to begin this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "try:\n",
    "    dotenv_path = find_dotenv(raise_error_if_not_found=True)\n",
    "except IOError:\n",
    "    dotenv_path = find_dotenv(raise_error_if_not_found=True, usecwd=True)\n",
    "load_dotenv(dotenv_path)\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ.get('PROJECT_PATH'), 'src'))\n",
    "sys.path.append(os.path.join(os.environ.get('PROJECT_PATH'), 'src', 'SupportingClasses'))\n",
    "input_dir = os.environ.get('INPUT_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set Construction ##\n",
    "The first task required to test the data set is to download the required data and construct any necessary input files for all down stream analyses.\n",
    "In this case that means:\n",
    "* Downloading PDB files for the proteins in our small test set.\n",
    "* Extracting a query sequence from each PDB file.\n",
    "* Searching for paralogs, homologs, and orthologs in a custom BLAST database built by filtering the Uniref90 database.\n",
    "* Filtering the hits from the BLAST search to meet minimum and maximum length requirements, as well as minimum and maximum identity requirements.\n",
    "* Building alignments using CLUSTALW in both the fasta and msf formats since some of the tools which will be used for comparison need different formats.\n",
    "* Filtering the alignment for maximum identity similarity between seqeunces.\n",
    "* Re-aligning the filtered sequences using CLUSTALW.\n",
    "This is all handeled by the DataSetGenerator class found in the src/SupportingClasses folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing protein list\n",
      "Downloading structures and parsing in query sequences\n",
      "Unique Sequences Found: 23!\n",
      "BLASTing query sequences\n",
      "Filtering BLAST hits, aligning, filtering by identity, and re-aligning\n",
      "   Protein_ID Chain     Accession  BLAST_Hits  Filtered_BLAST  \\\n",
      "13       2b59     B    CIPA_CLOTM        1606               4   \n",
      "12       7hvp     A     POL_HV1A2        2500              33   \n",
      "18       1c0k     A    OXDA_RHOTO        2500              51   \n",
      "3        206l     A      LYS_BPT4        1039             131   \n",
      "8        1bol     A    RNRH_RHINI        2500             131   \n",
      "16       3q05     A     P53_HUMAN         932             306   \n",
      "0        1jwl     A    LACI_ECOLI        2500             228   \n",
      "5        1a26     A   PARP1_CHICK        2500             267   \n",
      "6        2ysd     A   MAGI1_HUMAN        2500             412   \n",
      "11       2z0e     A   ATG4B_HUMAN        2111             360   \n",
      "20       4lli     A   MYO5A_HUMAN        2500             441   \n",
      "21       2rh1     A   ADRB2_HUMAN        2500             416   \n",
      "1        3b6v     A   KIF3C_HUMAN        2500             481   \n",
      "17       1h1v     G    GELS_HUMAN        2500             654   \n",
      "22       2zxe     A  Q4H132_SQUAC        2500             880   \n",
      "2        1c17     A    ATPL_ECOLI        1671             850   \n",
      "9        135l     A    LYSC_MELGA        1913             853   \n",
      "10       2wer     A   HSP82_YEAST        2500            1327   \n",
      "19       3tnu     A   K1C14_HUMAN        2500            1681   \n",
      "4        1hck     A    CDK2_HUMAN        2500            2468   \n",
      "7        1axb     A    BLAT_ECOLI        2500            2102   \n",
      "15       4ycu     A     SYK_HUMAN        2500            2421   \n",
      "14       2iop     A    HTPG_ECOLI        2500            2478   \n",
      "\n",
      "    Filtered_Alignment  Length  Total_Size  \n",
      "13                   4    1853      7412.0  \n",
      "12                  33    1437     47421.0  \n",
      "18                  51     368     18768.0  \n",
      "3                   92     164     15088.0  \n",
      "8                  127     238     30226.0  \n",
      "16                 210     393     82530.0  \n",
      "0                  226     360     81360.0  \n",
      "5                  261    1011    263871.0  \n",
      "6                  318    1491    474138.0  \n",
      "11                 344     393    135192.0  \n",
      "20                 352    1855    652960.0  \n",
      "21                 399     413    164787.0  \n",
      "1                  441     793    349713.0  \n",
      "17                 599     782    468418.0  \n",
      "22                 795    1028    817260.0  \n",
      "2                  813      79     64227.0  \n",
      "9                  818     147    120246.0  \n",
      "10                1207     709    855763.0  \n",
      "19                1518     472    716496.0  \n",
      "4                 1681     298    500938.0  \n",
      "7                 2087     286    596882.0  \n",
      "15                2347     597   1401159.0  \n",
      "14                2472     624   1542528.0  \n",
      "It took 0.16981738408406574 min to generate the data set.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from DataSetGenerator import DataSetGenerator\n",
    "protein_list_dir = os.path.join(input_dir, 'ProteinLists')\n",
    "if not os.path.isdir(protein_list_dir):\n",
    "    os.makedirs(protein_list_dir)\n",
    "small_list_fn = os.path.join(protein_list_dir, 'SmallDataSet.txt')\n",
    "if not os.path.isfile(small_list_fn):\n",
    "    proteins_of_interest = ['2ysdA', '1c17A', '3tnuA', '7hvpA', '135lA', '206lA', '2werA', '1bolA', '3q05A', '1axbA',\n",
    "                            '2rh1A', '1hckA', '3b6vA', '2z0eA', '1jwlA', '1a26A', '1c0kA', '4lliA', '4ycuA', '2iopA',\n",
    "                            '2zxeA', '2b59B', '1h1vG']\n",
    "    with open(small_list_fn, 'w') as small_list_handle:\n",
    "        for p_id in proteins_of_interest:\n",
    "            small_list_handle.write('{}\\n'.format(p_id))\n",
    "generator = DataSetGenerator(input_dir)\n",
    "start = time()\n",
    "summary = generator.build_pdb_alignment_dataset(protein_list_fn=os.path.basename(small_list_fn), processes=10,\n",
    "                                                database='customuniref90.fasta', max_target_seqs=2500, remote=False,\n",
    "                                                verbose=False)\n",
    "summary['Chain'] = summary['Protein_ID'].apply(lambda x: generator.protein_data[x]['Chain'])\n",
    "summary['Accession'] = summary['Protein_ID'].apply(lambda x: generator.protein_data[x]['Accession'])\n",
    "summary['Length'] = summary['Protein_ID'].apply(lambda x: generator.protein_data[x]['Length'])\n",
    "summary['Total_Size'] = summary.apply(lambda x: float(x['Length']) * float(x['Filtered_Alignment']), axis=1)\n",
    "summary.sort_values(by=['Filtered_Alignment', 'Length'], axis=0, inplace=True)\n",
    "summary_columns = ['Protein_ID', 'Chain', 'Accession', 'BLAST_Hits', 'Filtered_BLAST',\n",
    "                   'Filtered_Alignment', 'Length', 'Total_Size']\n",
    "print(summary[summary_columns])\n",
    "end = time()\n",
    "print('It took {} min to generate the data set.'.format((end - start) / 60.0))\n",
    "summary.to_csv(os.path.join(input_dir, 'small_data_set_summary.tsv'), sep='\\t', index=False, header=True,\n",
    "               columns=summary_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a location to store the output of this method comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.environ.get('OUTPUT_PATH')\n",
    "small_set_out_dir = os.path.join(output_dir, 'SmallTestSet')\n",
    "if not os.path.isdir(small_set_out_dir):\n",
    "    os.makedirs(small_set_out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Scoring For Each Method\n",
    "To reduce memory load during prediction and evaluation, the scoring objects needed to compute the metrics used to compare methods will be created ahead of time so they are available to each method when it computes its predictions for a given protein. This will ensure that results do not need to be kept in memory while waiting for all other results to be computed, only the metrics measured for each method will be recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.00035448869069417316 min\n",
      "Importing the PDB file took 0.00295257568359375 min\n",
      "Removing gaps took 0.0002918402353922526 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2960.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3114.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2960.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3114.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.0008218606313069661 min\n",
      "Mapping query sequence and pdb took 0.0015140334765116374 min\n",
      "Computing the distance matrix based on the PDB file took 0.0032189289728800454 min\n",
      "Removing gaps took 0.00025299390157063805 min\n",
      "Importing the PDB file took 0.0007321755091349284 min\n",
      "Mapping query sequence and pdb took 0.0013996720314025878 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2960.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3114.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.0033975442250569663 min\n",
      "Removing gaps took 0.0005528767903645833 min\n",
      "Importing the PDB file took 0.0007227540016174316 min\n",
      "Removing gaps took 0.0005472064018249512 min\n",
      "Importing the PDB file took 0.00046416521072387693 min\n",
      "Mapping query sequence and pdb took 0.0012325803438822428 min\n",
      "Computing the distance matrix based on the PDB file took 0.001221609115600586 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2100.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 2138.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 2191.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2100.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 2138.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 2191.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.0005501945813496908 min\n",
      "Importing the PDB file took 0.0013462305068969727 min\n",
      "Mapping query sequence and pdb took 0.002103900909423828 min\n",
      "Computing the distance matrix based on the PDB file took 0.001413885752360026 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2100.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 2138.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 2191.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.0008589585622151692 min\n",
      "Importing the PDB file took 0.0019921342531840007 min\n",
      "Removing gaps took 0.0006333231925964355 min\n",
      "Importing the PDB file took 0.001498874028523763 min\n",
      "Mapping query sequence and pdb took 0.0023056904474894205 min\n",
      "Computing the distance matrix based on the PDB file took 0.016188510258992515 min\n",
      "Removing gaps took 0.0006013671557108561 min\n",
      "Importing the PDB file took 0.0022334973017374676 min\n",
      "Mapping query sequence and pdb took 0.0030104438463846844 min\n",
      "Computing the distance matrix based on the PDB file took 0.01547383467356364 min\n",
      "Removing gaps took 0.00031191110610961914 min\n",
      "Importing the PDB file took 0.0007027506828308106 min\n",
      "Removing gaps took 0.0003069758415222168 min\n",
      "Importing the PDB file took 0.00034294525782267254 min\n",
      "Mapping query sequence and pdb took 0.0007106184959411622 min\n",
      "Computing the distance matrix based on the PDB file took 0.00291824738184611 min\n",
      "Removing gaps took 0.0003141045570373535 min\n",
      "Importing the PDB file took 0.00035209258397420247 min\n",
      "Mapping query sequence and pdb took 0.0007306178410847982 min\n",
      "Computing the distance matrix based on the PDB file took 0.0031993826230367023 min\n",
      "Removing gaps took 0.0008160630861918131 min\n",
      "Importing the PDB file took 0.0018528421719868978 min\n",
      "Removing gaps took 0.0009216626485188802 min\n",
      "Importing the PDB file took 0.0004010756810506185 min\n",
      "Mapping query sequence and pdb took 0.0014155785242716472 min\n",
      "Computing the distance matrix based on the PDB file took 0.005036469300587972 min\n",
      "Removing gaps took 0.0008123477300008138 min\n",
      "Importing the PDB file took 0.00038098494211832683 min\n",
      "Mapping query sequence and pdb took 0.0012928406397501627 min\n",
      "Computing the distance matrix based on the PDB file took 0.00622706413269043 min\n",
      "Removing gaps took 0.006679058074951172 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 9163.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 9164.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 9165.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 9166.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 9167.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 9201.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 9267.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 9314.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain K is discontinuous at line 9321.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain L is discontinuous at line 9325.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.0035878340403238933 min\n",
      "Removing gaps took 0.006623355547587076 min\n",
      "Importing the PDB file took 0.0030640522638956708 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 9163.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 9164.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 9165.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 9166.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 9167.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 9201.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 9267.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 9314.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain K is discontinuous at line 9321.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain L is discontinuous at line 9325.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping query sequence and pdb took 0.010444319248199463 min\n",
      "Computing the distance matrix based on the PDB file took 0.006792255242665609 min\n",
      "Removing gaps took 0.005558439095815023 min\n",
      "Importing the PDB file took 0.0028164188067118325 min\n",
      "Mapping query sequence and pdb took 0.008840560913085938 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 9163.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 9164.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 9165.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 9166.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 9167.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 9201.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 9267.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 9314.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain K is discontinuous at line 9321.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain L is discontinuous at line 9325.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.007679335276285807 min\n",
      "Removing gaps took 0.0025298078854878742 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 8081.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 8101.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 8121.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.0024524887402852377 min\n",
      "Removing gaps took 0.004487029711405436 min\n",
      "Importing the PDB file took 0.0017618656158447266 min\n",
      "Mapping query sequence and pdb took 0.006524860858917236 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 8081.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 8101.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 8121.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.013206561406453451 min\n",
      "Removing gaps took 0.003176093101501465 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 8081.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 8101.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 8121.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.001575934886932373 min\n",
      "Mapping query sequence and pdb took 0.004966668287913005 min\n",
      "Computing the distance matrix based on the PDB file took 0.014677631855010986 min\n",
      "Removing gaps took 0.016823991139729818 min\n",
      "Importing the PDB file took 0.0011104544003804524 min\n",
      "Removing gaps took 0.016859098275502523 min\n",
      "Importing the PDB file took 0.000636752446492513 min\n",
      "Mapping query sequence and pdb took 0.01814029614130656 min\n",
      "Computing the distance matrix based on the PDB file took 0.014306322733561198 min\n",
      "Removing gaps took 0.0159624973932902 min\n",
      "Importing the PDB file took 0.0006195624669392903 min\n",
      "Mapping query sequence and pdb took 0.01717799504597982 min\n",
      "Computing the distance matrix based on the PDB file took 0.015506307284037272 min\n",
      "Removing gaps took 0.027545313040415447 min\n",
      "Importing the PDB file took 0.006336939334869385 min\n",
      "Removing gaps took 0.027912700176239015 min\n",
      "Importing the PDB file took 0.004471099376678467 min\n",
      "Mapping query sequence and pdb took 0.04518070618311564 min\n",
      "Computing the distance matrix based on the PDB file took 0.0004034876823425293 min\n",
      "Removing gaps took 0.027220245202382407 min\n",
      "Importing the PDB file took 0.004477377732594808 min\n",
      "Mapping query sequence and pdb took 0.045135247707366946 min\n",
      "Computing the distance matrix based on the PDB file took 0.0005420168240865071 min\n",
      "Removing gaps took 0.010166855653127034 min\n",
      "Importing the PDB file took 0.0011406461397806802 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 3897.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4034.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.010118178526560466 min\n",
      "Importing the PDB file took 0.0008331735928853353 min\n",
      "Mapping query sequence and pdb took 0.011278891563415527 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 3897.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4034.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.011556661128997803 min\n",
      "Removing gaps took 0.010106412569681804 min\n",
      "Importing the PDB file took 0.002200170358022054 min\n",
      "Mapping query sequence and pdb took 0.012665911515553793 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 3897.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4034.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.011967909336090089 min\n",
      "Removing gaps took 0.05211108922958374 min\n",
      "Importing the PDB file took 0.0019611756006876627 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6531.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 6714.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.05139153003692627 min\n",
      "Importing the PDB file took 0.0014017105102539062 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6531.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 6714.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping query sequence and pdb took 0.05574634075164795 min\n",
      "Computing the distance matrix based on the PDB file took 0.017377714316050213 min\n",
      "Removing gaps took 0.05163764556248983 min\n",
      "Importing the PDB file took 0.0013614495595296223 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6531.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 6714.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping query sequence and pdb took 0.05598045984903972 min\n",
      "Computing the distance matrix based on the PDB file took 0.01905044714609782 min\n",
      "Removing gaps took 0.009032491842905681 min\n",
      "Importing the PDB file took 0.0015851815541585287 min\n",
      "Removing gaps took 0.009233335653940836 min\n",
      "Importing the PDB file took 0.0008548021316528321 min\n",
      "Mapping query sequence and pdb took 0.01824487845102946 min\n",
      "Computing the distance matrix based on the PDB file took 0.02260514497756958 min\n",
      "Removing gaps took 0.00908361275990804 min\n",
      "Importing the PDB file took 0.00081482728322347 min\n",
      "Mapping query sequence and pdb took 0.019734756151835123 min\n",
      "Computing the distance matrix based on the PDB file took 0.022429891427357993 min\n",
      "Removing gaps took 0.030356661478678385 min\n",
      "Importing the PDB file took 0.0014519929885864259 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5418.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/Atom.py:189: PDBConstructionWarning: Used element 'U' for Atom (name=UNK) with given element 'X'\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5449.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5482.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5486.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.03056495189666748 min\n",
      "Importing the PDB file took 0.001043097178141276 min\n",
      "Mapping query sequence and pdb took 0.0327010711034139 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5418.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/Atom.py:189: PDBConstructionWarning: Used element 'U' for Atom (name=UNK) with given element 'X'\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5449.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5482.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5486.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.010560905933380127 min\n",
      "Removing gaps took 0.028395013014475504 min\n",
      "Importing the PDB file took 0.0010316054026285808 min\n",
      "Mapping query sequence and pdb took 0.03008322318394979 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5418.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/Atom.py:189: PDBConstructionWarning: Used element 'U' for Atom (name=UNK) with given element 'X'\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5449.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5482.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5486.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.012718061606089274 min\n",
      "Removing gaps took 0.04435940186182658 min\n",
      "Importing the PDB file took 0.002049831549326579 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6161.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 6193.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6197.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 6393.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.042897788683573405 min\n",
      "Importing the PDB file took 0.0030073285102844237 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6161.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 6193.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6197.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 6393.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping query sequence and pdb took 0.04659052689870199 min\n",
      "Computing the distance matrix based on the PDB file took 0.012828175226847332 min\n",
      "Removing gaps took 0.04304961760838826 min\n",
      "Importing the PDB file took 0.001264802614847819 min\n",
      "Mapping query sequence and pdb took 0.045000338554382326 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6161.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 6193.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6197.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 6393.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.01294180949529012 min\n",
      "Removing gaps took 0.08557557264963786 min\n",
      "Importing the PDB file took 0.0030492464701334637 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11066.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 11103.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11145.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.08657513062159221 min\n",
      "Importing the PDB file took 0.0021982630093892413 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11066.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 11103.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11145.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping query sequence and pdb took 0.0908399780591329 min\n",
      "Computing the distance matrix based on the PDB file took 0.10321513017018637 min\n",
      "Removing gaps took 0.0870049516359965 min\n",
      "Importing the PDB file took 0.002177604039510091 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11066.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 11103.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11145.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping query sequence and pdb took 0.09115610520044963 min\n",
      "Computing the distance matrix based on the PDB file took 0.11475462913513183 min\n",
      "Removing gaps took 0.004340732097625732 min\n",
      "Importing the PDB file took 0.0036269386609395346 min\n",
      "Removing gaps took 0.004336166381835938 min\n",
      "Importing the PDB file took 0.0031528790791829427 min\n",
      "Mapping query sequence and pdb took 0.007641708850860596 min\n",
      "Computing the distance matrix based on the PDB file took 0.0007528026898701985 min\n",
      "Removing gaps took 0.004668188095092773 min\n",
      "Importing the PDB file took 0.003124562899271647 min\n",
      "Mapping query sequence and pdb took 0.007964050769805909 min\n",
      "Computing the distance matrix based on the PDB file took 0.001045393943786621 min\n",
      "Removing gaps took 0.011876972516377766 min\n",
      "Importing the PDB file took 0.0006187160809834799 min\n",
      "Removing gaps took 0.011845787366231283 min\n",
      "Importing the PDB file took 0.00027118126551310223 min\n",
      "Mapping query sequence and pdb took 0.01232525110244751 min\n",
      "Computing the distance matrix based on the PDB file took 0.0021085858345031737 min\n",
      "Removing gaps took 0.012063451608022054 min\n",
      "Importing the PDB file took 0.0002818107604980469 min\n",
      "Mapping query sequence and pdb took 0.012551514307657878 min\n",
      "Computing the distance matrix based on the PDB file took 0.0020967880884806317 min\n",
      "Removing gaps took 0.10573997894922892 min\n",
      "Importing the PDB file took 0.0016306996345520019 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 4201.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4226.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 4251.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4395.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.10845912297566732 min\n",
      "Importing the PDB file took 0.0009331782658894857 min\n",
      "Mapping query sequence and pdb took 0.11086005767186483 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 4201.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4226.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 4251.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4395.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.004923967520395914 min\n",
      "Removing gaps took 0.10247501134872436 min\n",
      "Importing the PDB file took 0.0008765737215677897 min\n",
      "Mapping query sequence and pdb took 0.10470443964004517 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 4201.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4226.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 4251.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4395.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.006156512101491292 min\n",
      "Removing gaps took 0.07223594586054484 min\n",
      "Importing the PDB file took 0.0008329113324483235 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 3478.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3488.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.07305128574371338 min\n",
      "Importing the PDB file took 0.0028575976689656575 min\n",
      "Mapping query sequence and pdb took 0.07684874137242635 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 3478.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3488.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.000978696346282959 min\n",
      "Removing gaps took 0.0698118527730306 min\n",
      "Importing the PDB file took 0.0005704283714294434 min\n",
      "Mapping query sequence and pdb took 0.07132985989252726 min\n",
      "Computing the distance matrix based on the PDB file took 0.0009394447008768717 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 3478.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3488.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.07178196509679159 min\n",
      "Importing the PDB file took 0.0007531404495239258 min\n",
      "Removing gaps took 0.07369396686553956 min\n",
      "Importing the PDB file took 0.0005734523137410481 min\n",
      "Mapping query sequence and pdb took 0.07533979813257853 min\n",
      "Computing the distance matrix based on the PDB file took 0.009917831420898438 min\n",
      "Removing gaps took 0.0708172877629598 min\n",
      "Importing the PDB file took 0.0005646149317423502 min\n",
      "Mapping query sequence and pdb took 0.07257393598556519 min\n",
      "Computing the distance matrix based on the PDB file took 0.010777175426483154 min\n",
      "Removing gaps took 0.04690283536911011 min\n",
      "Importing the PDB file took 0.0030245304107666014 min\n",
      "Removing gaps took 0.047337039311726885 min\n",
      "Importing the PDB file took 0.0004982352256774902 min\n",
      "Mapping query sequence and pdb took 0.048462438583374026 min\n",
      "Computing the distance matrix based on the PDB file took 0.00776062806447347 min\n",
      "Removing gaps took 0.047049395243326825 min\n",
      "Importing the PDB file took 0.003061016400655111 min\n",
      "Mapping query sequence and pdb took 0.050783288478851316 min\n",
      "Computing the distance matrix based on the PDB file took 0.010075585047403971 min\n",
      "Removing gaps took 0.16641433636347452 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 17206.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 17292.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 17378.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 18052.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 18724.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.0037268797556559243 min\n",
      "Removing gaps took 0.16820600032806396 min\n",
      "Importing the PDB file took 0.0032723387082417804 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 17206.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 17292.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 17378.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 18052.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 18724.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping query sequence and pdb took 0.17356289625167848 min\n",
      "Computing the distance matrix based on the PDB file took 0.030497666200002035 min\n",
      "Removing gaps took 0.16094518899917604 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 17206.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 17292.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 17378.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 18052.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 18724.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.006329743067423502 min\n",
      "Mapping query sequence and pdb took 0.17222086985905966 min\n",
      "Computing the distance matrix based on the PDB file took 0.03648796876271566 min\n",
      "Removing gaps took 0.10521034399668376 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 20520.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 20547.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 20574.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 20601.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.007506024837493896 min\n",
      "Removing gaps took 0.10873920917510986 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 20520.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 20547.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 20574.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 20601.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.0040263175964355465 min\n",
      "Mapping query sequence and pdb took 0.11404651006062826 min\n",
      "Computing the distance matrix based on the PDB file took 0.04424318472544352 min\n",
      "Removing gaps took 0.10761497815450033 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 20520.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 20547.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 20574.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 20601.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.0072989225387573246 min\n",
      "Mapping query sequence and pdb took 0.11623253424962361 min\n",
      "Computing the distance matrix based on the PDB file took 0.04610510667165121 min\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from SeqAlignment import SeqAlignment\n",
    "from PDBReference import PDBReference\n",
    "from ContactScorer import ContactScorer, plot_z_scores\n",
    "protein_order = list(summary['Protein_ID'])\n",
    "method_order = ['DCA', 'EVC Standard', 'EVC Mean Field', 'ET-MIp', 'cET-MIp', 'ET-MIp_MAX']\n",
    "sequence_separation_order = ['Any', 'Neighbors', 'Short', 'Medium', 'Long']\n",
    "protein_scorers = {}\n",
    "small_comparison_df = None\n",
    "small_comparison_fn = os.path.join(small_set_out_dir, 'Small_Comparision_Data.csv')\n",
    "if os.path.isfile(small_comparison_fn):\n",
    "    small_comparison_df = pd.read_csv(small_comparison_fn, sep='\\t', header=0, index_col=False)\n",
    "else:\n",
    "    for p_id in summary['Protein_ID']:\n",
    "        protein_scorers[p_id] = {}\n",
    "        # Import alignment and remove gaps\n",
    "        full_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id)\n",
    "        full_aln.import_alignment()\n",
    "        non_gap_aln = full_aln.remove_gaps()\n",
    "        # Import structure\n",
    "        pdb_structure = PDBReference(pdb_file=generator.protein_data[p_id]['PDB'])\n",
    "        pdb_structure.import_pdb(structure_id=p_id)\n",
    "        protein_scorers[p_id]['Structure'] = pdb_structure\n",
    "        # Initialize Beta Carbon distance scorer\n",
    "        contact_scorer_cb = ContactScorer(query=p_id, seq_alignment=non_gap_aln,\n",
    "                                          pdb_reference=pdb_structure, cutoff=8.0)\n",
    "        contact_scorer_cb.best_chain = generator.protein_data[p_id]['Chain']\n",
    "        contact_scorer_cb.fit()\n",
    "        contact_scorer_cb.measure_distance(method='CB')\n",
    "        protein_scorers[p_id]['Scorer_CB'] = contact_scorer_cb\n",
    "        # Initialize distance scorer minimizing distance between any atoms\n",
    "        contact_scorer_any = ContactScorer(query=p_id, seq_alignment=non_gap_aln,\n",
    "                                           pdb_reference=pdb_structure, cutoff=8.0)\n",
    "        contact_scorer_any.best_chain = generator.protein_data[p_id]['Chain']\n",
    "        contact_scorer_any.fit()\n",
    "        contact_scorer_any.measure_distance(method='Any')\n",
    "        protein_scorers[p_id]['Scorer_Any'] = contact_scorer_any\n",
    "        # Initialize z-scoring subproblems\n",
    "        protein_scorers[p_id]['biased_w2_ave'] = None\n",
    "        protein_scorers[p_id]['unbiased_w2_ave'] = None\n",
    "output_columns = ['Protein', 'Protein Length', 'Alignment Size', 'Method', 'Distance', 'Init Time', 'Import Time', 'Dist Tree Time', 'Trace Time', 'Total Time', \n",
    "                  'Sequence_Separation', 'AUROC', 'AUPRC', 'AUTPRFDRC',\n",
    "                  'Top K Predictions', 'Precision', 'Recall', 'F1 Score',\n",
    "                  'Biased Z-Score at 10%', 'Biased Z-Score at 30%', 'Max Biased Z-Score', 'AUC Biased Z-Score',\n",
    "                  'Unbiased Z-Score at 10%', 'Biased Z-Score at 30%', 'Max Unbiased Z-Score', 'AUC Unbiased Z-Score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Values For Comparision#\n",
    "To determine the effectiveness of the new method and implementation the covariation of the same proteins will be computed using the previous Evolutionary Trace covariation method (ET-MIp) and other methods in the field.\n",
    "\n",
    "## ET-MIp##\n",
    "Scoring the the covariation of the proteins using the previous Evolutionary Trace covariation method (ET-MIp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from ETMIPWrapper import ETMIPWrapper\n",
    "# etmip_out_dir = os.path.join(small_set_out_dir, 'ET-MIp')\n",
    "# if not os.path.isdir(etmip_out_dir):\n",
    "#     os.makedirs(etmip_out_dir)\n",
    "# etmip_scores = {}\n",
    "# counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "# for p_id in generator.protein_data:\n",
    "#     print('Attempting to calculate ET-MIp covariance for: {}'.format(p_id))\n",
    "#     try:\n",
    "#         protein_out_dir = os.path.join(etmip_out_dir, p_id)\n",
    "#         if not os.path.isdir(protein_out_dir):\n",
    "#             os.makedirs(protein_out_dir)\n",
    "#         curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id, polymer_type='Protein')\n",
    "#         curr_aln.import_alignment()\n",
    "#         curr_etmip = ETMIPWrapper(alignment=curr_aln)\n",
    "#         curr_etmip.calculate_scores(out_dir=protein_out_dir, delete_files=False)\n",
    "#         etmip_scores[p_id] = curr_etmip\n",
    "#         print('Successfully computed ET-MIp covariance for: {}'.format(p_id))\n",
    "#         counts['success'] += 1\n",
    "#     except ValueError:\n",
    "#         print('Could not compute ET-MIp covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "#             p_id, curr_aln.seq_length, curr_aln.size))\n",
    "#         counts['value'] += 1\n",
    "#     except AttributeError:\n",
    "#         print('Could not compute ET-MIp covariance for: {} no alignment'.format(p_id))\n",
    "#         counts['attribute'] += 1\n",
    "# print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "#                                                                      counts['attribute']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ET-MIp (Continued)\n",
    "The previous implementation is not able to run for alignments of the size used here. Instead we use the new implementation with the same parameterization used by the previous implementation (Distance Model - blosum62 similarity, Tree - ET UPGMA variant, Scoring Metric - filtered average product corrected mutual information, Ranks - all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EvolutionaryTrace import EvolutionaryTrace\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    etmip_out_dir = os.path.join(small_set_out_dir, 'ET-MIp')\n",
    "    if not os.path.isdir(etmip_out_dir):\n",
    "        os.makedirs(etmip_out_dir)\n",
    "    etmip_method_fn = os.path.join(etmip_out_dir, 'ET-MIp_Method_Data.csv')\n",
    "    if os.path.isfile(etmip_method_fn):\n",
    "        etmip_method_df = pd.read_csv(etmip_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:    \n",
    "        etmip_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "        for p_id in summary['Protein_ID']:\n",
    "            print('Attempting to calculate ET-MIp covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(etmip_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "            else:\n",
    "                try:\n",
    "\n",
    "                    start_time = time()\n",
    "                    curr_etmip = EvolutionaryTrace(query_id=p_id, polymer_type='Protein',\n",
    "                                                   aln_fn=generator.protein_data[p_id]['Final_FA_Aln'], et_distance=True,\n",
    "                                                   distance_model='blosum62', tree_building_method='et', tree_building_options={},\n",
    "                                                   ranks=None, position_type='pair',\n",
    "                                                   scoring_metric='filtered_average_product_corrected_mutual_information',\n",
    "                                                   gap_correction=None, maximize=False, out_dir=protein_dir,\n",
    "                                                   output_files={'original_aln', 'non_gap_aln', 'tree', 'scores'},\n",
    "                                                   processors=10, low_memory=True)\n",
    "                    init_time = time()\n",
    "                    curr_etmip.import_and_process_aln()\n",
    "                    import_time = time()\n",
    "                    curr_etmip.compute_distance_matrix_tree_and_assignments()\n",
    "                    dist_tree_time = time()\n",
    "                    curr_etmip.perform_trace()\n",
    "                    end_time = time()\n",
    "                    print('Successfully computed ET-MIp covariance for: {}'.format(p_id))\n",
    "                    # Compute statistics for the final scores of the ET-MIp model\n",
    "                    protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                        predictor=curr_etmip, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                        unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=curr_etmip.scorer.position_size,\n",
    "                        rank_type=curr_etmip.scorer.rank_type, file_prefix='ET-MIp_Scores_', plots=True)\n",
    "                    # Score Prediction Clustering\n",
    "                    z_score_fn = os.path.join(protein_dir, 'ET-MIp_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                    z_score_plot_fn = os.path.join(protein_dir, 'ET-MIp_Scores_Dist-Any_{}_ZScores.png')\n",
    "                    z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - curr_etmip.coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                    biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                    protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                    plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                    z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - curr_etmip.coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                    unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                    protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                    plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                    # Record execution times\n",
    "                    protein_df['Init Time'] = init_time - start_time\n",
    "                    protein_df['Import Time'] = import_time - init_time\n",
    "                    protein_df['Dist Tree Time'] = dist_tree_time - import_time\n",
    "                    protein_df['Trace Time'] = end_time - dist_tree_time\n",
    "                    protein_df['Total Time'] = end_time - start_time\n",
    "                    # Record static data for this protein\n",
    "                    protein_df['Protein'] = p_id\n",
    "                    protein_df['Method'] = 'ET-MIp'\n",
    "                    protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                    protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                    temp_data = os.path.join(protein_dir, 'unique_node_data')\n",
    "                    for temp_fn in os.listdir(temp_data):\n",
    "                        if not temp_fn.endswith(\"_pair_rank_filtered_average_product_corrected_mutual_information_score.npz\"):\n",
    "                            os.remove(os.path.join(temp_data, temp_fn))\n",
    "                    print('Metrics meastured for ET-MIp covariance for: {}'.format(p_id))\n",
    "                    counts['success'] += 1\n",
    "                except ValueError:\n",
    "                    print('Could not compute ET-MIp covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "                        p_id, curr_etmip.original_aln.seq_length, curr_etmip.original_aln.size))\n",
    "                    counts['value'] += 1\n",
    "                    continue\n",
    "                except AttributeError:\n",
    "                    print('Could not compute ET-MIp covariance for: {} no alignment'.format(p_id))\n",
    "                    counts['attribute'] += 1\n",
    "                    continue\n",
    "            if etmip_method_df is None:\n",
    "                etmip_method_df = protein_df\n",
    "            else:\n",
    "                etmip_method_df = etmip_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        etmip_method_df.to_csv(etmip_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = etmip_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(etmip_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cET-MIp\n",
    "This segment the ET-MIp method, when constrained to an arbitrary set of nodes (1, 2, 3, 5, 7, 10, 25) at the top of the phylogenetic tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(small_comparison_fn):\n",
    "    cetmip_out_dir = os.path.join(small_set_out_dir, 'cET-MIp')\n",
    "    if not os.path.isdir(cetmip_out_dir):\n",
    "        os.makedirs(cetmip_out_dir)\n",
    "    cetmip_method_fn = os.path.join(cetmip_out_dir, 'cET-MIp_Method_Data.csv')\n",
    "    if os.path.isfile(cetmip_method_fn):\n",
    "        cetmip_method_df = pd.read_csv(cetmip_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:\n",
    "        cetmip_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0, 'key': 0}\n",
    "        for p_id in summary['Protein_ID']:\n",
    "            print('Attempting to calculate cET-MIp covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(cetmip_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "            else:\n",
    "                try:\n",
    "                    start_time = time()\n",
    "                    curr_cetmip = EvolutionaryTrace(query_id=p_id, polymer_type='Protein',\n",
    "                                                   aln_fn=generator.protein_data[p_id]['Final_FA_Aln'], et_distance=True,\n",
    "                                                   distance_model='blosum62', tree_building_method='et', tree_building_options={},\n",
    "                                                   ranks=[1, 2, 3, 5, 7, 10, 25], position_type='pair',\n",
    "                                                   scoring_metric='filtered_average_product_corrected_mutual_information',\n",
    "                                                   gap_correction=None, maximize=False, out_dir=protein_dir,\n",
    "                                                   output_files={'original_aln', 'non_gap_aln', 'tree', 'scores'},\n",
    "                                                   processors=10, low_memory=True)\n",
    "                    init_time = time()\n",
    "                    curr_cetmip.import_and_process_aln()\n",
    "                    import_time = time()\n",
    "                    curr_cetmip.compute_distance_matrix_tree_and_assignments()\n",
    "                    dist_tree_time = time()\n",
    "                    curr_cetmip.perform_trace()\n",
    "                    end_time = time()\n",
    "                    # Compute statistics for the final scores of the ET-MIp model\n",
    "                    protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                        predictor=curr_cetmip, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                        unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=curr_cetmip.scorer.position_size,\n",
    "                        rank_type=curr_cetmip.scorer.rank_type, file_prefix='cET-MIp_Scores_', plots=True)\n",
    "                    # Score Prediction Clustering\n",
    "                    z_score_fn = os.path.join(protein_dir, 'cET-MIp_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                    z_score_plot_fn = os.path.join(protein_dir, 'cET-MIp_Scores_Dist-Any_{}_ZScores.png')\n",
    "                    z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - curr_cetmip.coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                    biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                    protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                    plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                    z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - curr_cetmip.coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                    unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                    protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                    plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                    # Record execution times\n",
    "                    protein_df['Init Time'] = init_time - start_time\n",
    "                    protein_df['Import Time'] = import_time - init_time\n",
    "                    protein_df['Dist Tree Time'] = dist_tree_time - import_time\n",
    "                    protein_df['Trace Time'] = end_time - dist_tree_time\n",
    "                    protein_df['Total Time'] = end_time - start_time\n",
    "                    # Record static data for this protein\n",
    "                    protein_df['Protein'] = p_id\n",
    "                    protein_df['Method'] = 'cET-MIp'\n",
    "                    protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                    protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                    temp_data = os.path.join(protein_dir, 'unique_node_data')\n",
    "                    for temp_fn in os.listdir(temp_data):\n",
    "                        if not temp_fn.endswith(\"_pair_rank_filtered_average_product_corrected_mutual_information_score.npz\"):\n",
    "                            os.remove(os.path.join(temp_data, temp_fn))\n",
    "                    print('Successfully computed cET-MIp covariance for: {}'.format(p_id))\n",
    "                    counts['success'] += 1\n",
    "                except ValueError:\n",
    "                    print('Could not compute cET-MIp covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "                        p_id, curr_cetmip.original_aln.seq_length, curr_etmip.original_aln.size))\n",
    "                    counts['value'] += 1\n",
    "                    continue\n",
    "                except AttributeError:\n",
    "                    print('Could not compute cET-MIp covariance for: {} no alignment'.format(p_id))\n",
    "                    counts['attribute'] += 1\n",
    "                    continue\n",
    "                except KeyError:\n",
    "                    print('Could not compute cET-MIp covariance for: {} not enough sequences'.format('p_ied'))\n",
    "                    counts['key'] += 1\n",
    "                    continue\n",
    "            if cetmip_method_df is None:\n",
    "                cetmip_method_df = protein_df\n",
    "            else:\n",
    "                cetmip_method_df = cetmip_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        cetmip_method_df.to_csv(cetmip_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = cetmip_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(cetmip_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ET-MIp with Group Maximiziation ###\n",
    "This cell generates data for and tests the effect of maximizing the group score when moving from a parent node to child nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?sequences/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 2b59\n",
      "Removing gaps took 0.0005765557289123535 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4/4 [00:00<00:00, 14.53sequences/s]\n",
      "100%|| 6/6 [00:00<00:00, 21.78distances/s]\n",
      "  0%|          | 0/7 [00:00<?, ?characterizations/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing tree took: 4.7087669372558594e-05 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7/7 [02:53<00:00, 21.29s/characterizations] \n",
      "100%|| 7/7 [00:01<00:00,  2.77group/s]\n",
      "  0%|          | 0/4 [00:00<?, ?rank/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Score MAXIMIZATION Took: 0.0437274177869161 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4/4 [00:00<00:00,  5.05rank/s]\n",
      "100%|| 1715878/1715878 [20:35<00:00, 1388.94variation/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to file in 20.892080398400626 min\n",
      "Successfully computed ET-MIp MAX covariance for: 2b59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/Documents/git/ETMIP/src/SupportingClasses/ContactScorer.py:760: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fdr = fps / fdr_denominator\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/numpy/lib/function_base.py:4523: RuntimeWarning: invalid value encountered in multiply\n",
      "  ret = (d * (y[slice1] + y[slice2]) / 2.0).sum(axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute SCW Z-Score took 0.21411661307017008 min\n",
      "Compute SCW Z-Score took 0.21895819505055744 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/pandas/core/indexing.py:1404: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "  0%|          | 0/33 [00:00<?, ?sequences/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics meastured for ET-MIp MAX covariance for: 2b59\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 7hvp\n",
      "Removing gaps took 0.0007304588953653972 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 33/33 [00:00<00:00, 76.85sequences/s]\n",
      "100%|| 528/528 [00:00<00:00, 680.85distances/s]\n",
      "  0%|          | 0/65 [00:00<?, ?characterizations/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing tree took: 0.0002676248550415039 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 65/65 [08:43<00:00,  3.19s/characterizations]  \n",
      "100%|| 65/65 [00:04<00:00, 15.33group/s]\n",
      "  0%|          | 0/33 [00:00<?, ?rank/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Score MAXIMIZATION Took: 0.4457614183425903 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 33/33 [00:04<00:00,  7.73rank/s]\n",
      " 31%|       | 315001/1031766 [03:54<09:10, 1302.30variation/s]"
     ]
    }
   ],
   "source": [
    "from EvolutionaryTrace import EvolutionaryTrace\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    etmip_out_dir = os.path.join(small_set_out_dir, 'ET-MIp_MAX')\n",
    "    if not os.path.isdir(etmip_out_dir):\n",
    "        os.makedirs(etmip_out_dir)\n",
    "    etmip_method_fn = os.path.join(etmip_out_dir, 'ET-MIp_MAX_Method_Data.csv')\n",
    "    if os.path.isfile(etmip_method_fn):\n",
    "        etmip_method_df = pd.read_csv(etmip_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:    \n",
    "        etmip_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "        for p_id in summary['Protein_ID']:\n",
    "            print('Attempting to calculate ET-MIp MAXIMIZED covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(etmip_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "            else:\n",
    "                try:\n",
    "\n",
    "                    start_time = time()\n",
    "                    curr_etmip = EvolutionaryTrace(query_id=p_id, polymer_type='Protein',\n",
    "                                                   aln_fn=generator.protein_data[p_id]['Final_FA_Aln'], et_distance=True,\n",
    "                                                   distance_model='blosum62', tree_building_method='et', tree_building_options={},\n",
    "                                                   ranks=None, position_type='pair',\n",
    "                                                   scoring_metric='filtered_average_product_corrected_mutual_information',\n",
    "                                                   gap_correction=None, maximize=True, out_dir=protein_dir,\n",
    "                                                   output_files={'original_aln', 'non_gap_aln', 'tree', 'scores'},\n",
    "                                                   processors=10, low_memory=True)\n",
    "                    init_time = time()\n",
    "                    curr_etmip.import_and_process_aln()\n",
    "                    import_time = time()\n",
    "                    curr_etmip.compute_distance_matrix_tree_and_assignments()\n",
    "                    dist_tree_time = time()\n",
    "                    curr_etmip.perform_trace()\n",
    "                    end_time = time()\n",
    "                    print('Successfully computed ET-MIp MAX covariance for: {}'.format(p_id))\n",
    "                    # Compute statistics for the final scores of the ET-MIp model\n",
    "                    protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                        predictor=curr_etmip, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                        unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=curr_etmip.scorer.position_size,\n",
    "                        rank_type=curr_etmip.scorer.rank_type, file_prefix='ET-MIp_MAX_Scores_', plots=True)\n",
    "                    # Score Prediction Clustering\n",
    "                    z_score_fn = os.path.join(protein_dir, 'ET-MIp_MAX_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                    z_score_plot_fn = os.path.join(protein_dir, 'ET-MIp_MAX_Scores_Dist-Any_{}_ZScores.png')\n",
    "                    z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - curr_etmip.coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                    biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                    protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                    plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                    z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - curr_etmip.coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                    unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                    protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                    plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                    # Record execution times\n",
    "                    protein_df['Init Time'] = init_time - start_time\n",
    "                    protein_df['Import Time'] = import_time - init_time\n",
    "                    protein_df['Dist Tree Time'] = dist_tree_time - import_time\n",
    "                    protein_df['Trace Time'] = end_time - dist_tree_time\n",
    "                    protein_df['Total Time'] = end_time - start_time\n",
    "                    # Record static data for this protein\n",
    "                    protein_df['Protein'] = p_id\n",
    "                    protein_df['Method'] = 'ET-MIp_MAX'\n",
    "                    protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                    protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                    temp_data = os.path.join(protein_dir, 'unique_node_data')\n",
    "                    for temp_fn in os.listdir(temp_data):\n",
    "                        if not temp_fn.endswith(\"_pair_rank_filtered_average_product_corrected_mutual_information_score.npz\"):\n",
    "                            os.remove(os.path.join(temp_data, temp_fn))\n",
    "                    print('Metrics meastured for ET-MIp MAX covariance for: {}'.format(p_id))\n",
    "                    counts['success'] += 1\n",
    "                except ValueError:\n",
    "                    print('Could not compute ET-MIp MAX covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "                        p_id, curr_etmip.original_aln.seq_length, curr_etmip.original_aln.size))\n",
    "                    counts['value'] += 1\n",
    "                    continue\n",
    "                except AttributeError:\n",
    "                    print('Could not compute ET-MIp MAX covariance for: {} no alignment'.format(p_id))\n",
    "                    counts['attribute'] += 1\n",
    "                    continue\n",
    "            if etmip_method_df is None:\n",
    "                etmip_method_df = protein_df\n",
    "            else:\n",
    "                etmip_method_df = etmip_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        etmip_method_df.to_csv(etmip_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = etmip_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(etmip_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCA##\n",
    "Scoring the the covariation of the proteins using a DCA julia implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DCAWrapper import DCAWrapper\n",
    "from utils import compute_rank_and_coverage\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    dca_out_dir = os.path.join(small_set_out_dir, 'DCA')\n",
    "    if not os.path.isdir(dca_out_dir):\n",
    "        os.makedirs(dca_out_dir)\n",
    "    dca_method_fn = os.path.join(dca_out_dir, 'DCA_Method_Data.csv')\n",
    "    if olarges.path.isfile(dca_method_fn):\n",
    "        dca_method_df = pd.read_csv(dca_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:\n",
    "        dca_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "        for p_id in generator.protein_data:\n",
    "            print('Attempting to calculate DCA covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(dca_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "            else:\n",
    "                try:\n",
    "                    curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id,\n",
    "                                            polymer_type='Protein')\n",
    "                    curr_aln.import_alignment()\n",
    "                    # Since the DCA implementation used here does not provide a way to specify the query sequence we remove the gaps\n",
    "                    # from the query sequences so positions will be referenced correctly for that sequence (and unnecessary\n",
    "                    # computations can be avoided).\n",
    "                    curr_aln = curr_aln.remove_gaps()\n",
    "                    new_aln_fn = os.path.join(protein_dir, '{}_no_gap.fasta'.format(p_id))\n",
    "                    curr_aln.write_out_alignment(new_aln_fn)\n",
    "                    curr_aln.file_name = new_aln_fn\n",
    "                    curr_dca = DCAWrapper(alignment=curr_aln)\n",
    "                    curr_dca.calculate_scores(out_dir=protein_dir, delete_file=False)\n",
    "                    # Compute statistics for the final scores of the ET-MIp model\n",
    "                    protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                        predictor=curr_dca, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                        unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=2, rank_type='max', file_prefix='DCA_Scores_', plots=True)\n",
    "                    # Score Prediction Clustering\n",
    "                    _, dca_coverage  = compute_rank_and_coverage(seq_length=curr_dca.alignment.seq_length, scores=curr_dca.scores, pos_size=2,\n",
    "                        rank_type='max')\n",
    "                    z_score_fn = os.path.join(protein_dir, 'DCA_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                    z_score_plot_fn = os.path.join(protein_dir, 'DCA_Scores_Dist-Any_{}_ZScores.png')\n",
    "                    z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - dca_coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                    biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                    protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                    plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                    z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - dca_coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                    unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                    protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                    plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                    # Record execution times\n",
    "                    protein_df['Init Time'] = None\n",
    "                    protein_df['Import Time'] = None\n",
    "                    protein_df['Dist Tree Time'] = None\n",
    "                    protein_df['Trace Time'] = None\n",
    "                    protein_df['Total Time'] = None\n",
    "                    # Record static data for this protein\n",
    "                    protein_df['Protein'] = p_id\n",
    "                    protein_df['Method'] = 'DCA'\n",
    "                    protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                    protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                    print('Successfully computed DCA covariance for: {}'.format(p_id))\n",
    "                    counts['success'] += 1\n",
    "                except ValueError:\n",
    "                    print('Could not compute DCA covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "                        p_id, curr_aln.seq_length, curr_aln.size))\n",
    "                    counts['value'] += 1\n",
    "                    continue\n",
    "                except AttributeError:\n",
    "                    print('Could not compute DCA covariance for: {} no alignment'.format(p_id))\n",
    "                    counts['attribute'] += 1\n",
    "                    continue\n",
    "            if dca_method_df is None:\n",
    "                dca_method_df = protein_df\n",
    "            else:\n",
    "                dca_method_df = dca_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        dca_method_df.to_csv(dca_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = dca_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(dca_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVCouplings##\n",
    "Scoring the the covariation of the proteins using the EVCouplings method standard protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EVCouplingsWrapper import EVCouplingsWrapper\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    evc_standard_out_dir = os.path.join(small_set_out_dir, 'EVCouplings_Standard')\n",
    "    if not os.path.isdir(evc_standard_out_dir):\n",
    "        os.makedirs(evc_standard_out_dir)\n",
    "    evc_standard_method_fn = os.path.join(evc_standard_out_dir, 'EVCouplings_Standard_Method_Data.csv')\n",
    "    if os.path.isfile(evc_standard_method_fn):\n",
    "        evc_standard_method_df = pd.read_csv(evc_standard_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:\n",
    "        evc_standard_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "        for p_id in generator.protein_data:\n",
    "            print('Attempting to calculate EV couplings standard protocol covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(evc_standard_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "            else:\n",
    "                try:\n",
    "                    curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id,\n",
    "                                            polymer_type='Protein')\n",
    "                    curr_aln.import_alignment()\n",
    "                    curr_evc = EVCouplingsWrapper(alignment=curr_aln, protocol='standard')\n",
    "                    curr_evc.calculate_scores(out_dir=protein_dir, cores=10, delete_files=True)\n",
    "                    # Compute statistics for the final scores of the ET-MIp model\n",
    "                    protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                        predictor=curr_evc, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                        unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=2,\n",
    "                        rank_type='max', file_prefix='EVC_Standard_Scores_', plots=True)\n",
    "                    # Score Prediction Clustering\n",
    "                    _, evc_standard_coverage  = compute_rank_and_coverage(seq_length=curr_evc.alignment.seq_length, scores=curr_evc.scores, pos_size=2,\n",
    "                        rank_type='max')\n",
    "                    z_score_fn = os.path.join(protein_dir, 'EVC_Standard_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                    z_score_plot_fn = os.path.join(protein_dir, 'EVC_Standard_Scores_Dist-Any_{}_ZScores.png')\n",
    "                    z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - evc_standard_coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                    biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                    protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                    plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                    z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - evc_standard_coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                    unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                    protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                    plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                    # Record execution times\n",
    "                    protein_df['Init Time'] = None\n",
    "                    protein_df['Import Time'] = None\n",
    "                    protein_df['Dist Tree Time'] = None\n",
    "                    protein_df['Trace Time'] = None\n",
    "                    protein_df['Total Time'] = None\n",
    "                    # Record static data for this protein\n",
    "                    protein_df['Protein'] = p_id\n",
    "                    protein_df['Method'] = 'EVC Standard'\n",
    "                    protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                    protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                    print('Successfully computed EV couplings standard protocol covariance for: {}'.format(p_id))\n",
    "                    counts['success'] += 1\n",
    "                except ValueError:\n",
    "                    print('Could not compute EV couplings standard protocol covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "                        p_id, curr_aln.seq_length, curr_aln.size))\n",
    "                    counts['value'] += 1\n",
    "                    continue\n",
    "                except AttributeError:\n",
    "                    print('Could not compute EV couplings standard protocol covariance for: {} no alignment'.format(p_id))\n",
    "                    counts['attribute'] += 1\n",
    "                    continue\n",
    "            if evc_standard_method_df is None:\n",
    "                evc_standard_method_df = protein_df\n",
    "            else:\n",
    "                evc_standard_method_df = evc_standard_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        evc_standard_method_df.to_csv(evc_standard_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = evc_standard_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(evc_standard_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring the covariation of the proteins using the EVCouplings method mean field protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(small_comparison_fn):\n",
    "    evc_mf_out_dir = os.path.join(small_set_out_dir, 'EVCouplings_Mean_Field')\n",
    "    if not os.path.isdir(evc_mf_out_dir):\n",
    "        os.makedirs(evc_mf_out_dir)\n",
    "    evc_mf_method_fn = os.path.join(evc_mf_out_dir, 'EVCouplings_Mean_Field_Method_Data.csv')\n",
    "    if os.path.isfile(evc_mf_method_fn):\n",
    "        evc_mf_method_df = pd.read_csv(evc_mf_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:\n",
    "        evc_mf_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "        for p_id in generator.protein_data:\n",
    "            print('Attempting to calculate EV couplings covariance for: {}'.format(p_id))\n",
    "            try:\n",
    "                protein_dir = os.path.join(evc_mf_out_dir, p_id)\n",
    "                if not os.path.isdir(protein_dir):\n",
    "                    os.makedirs(protein_dir)\n",
    "                curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id,\n",
    "                                        polymer_type='Protein')\n",
    "                curr_aln.import_alignment()\n",
    "                curr_evc = EVCouplingsWrapper(alignment=curr_aln, protocol='mean_field')\n",
    "                curr_evc.calculate_scores(out_dir=protein_dir, cores=10, delete_files=True)\n",
    "                # Compute statistics for the final scores of the ET-MIp model\n",
    "                protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                    predictor=curr_evc, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                    unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=2, rank_type='max',\n",
    "                    file_prefix='EVC_Standard_Scores_', plots=True)\n",
    "                # Score Prediction Clustering\n",
    "                _, evc_mf_coverage  = compute_rank_and_coverage(seq_length=curr_evc.alignment.seq_length, scores=curr_evc.scores, pos_size=2,\n",
    "                    rank_type='max')\n",
    "                z_score_fn = os.path.join(protein_dir, 'EVC_Mean_Field_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                z_score_plot_fn = os.path.join(protein_dir, 'EVC_Mean_Field_Scores_Dist-Any_{}_ZScores.png')\n",
    "                z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                    1.0 - evc_mf_coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                    w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                    1.0 - evc_mf_coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                    w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                # Record execution times\n",
    "                protein_df['Init Time'] = None\n",
    "                protein_df['Import Time'] = None\n",
    "                protein_df['Dist Tree Time'] = None\n",
    "                protein_df['Trace Time'] = None\n",
    "                protein_df['Total Time'] = None\n",
    "                # Record static data for this protein\n",
    "                protein_df['Protein'] = p_id\n",
    "                protein_df['Method'] = 'EVC Mean Field'\n",
    "                protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                print('Successfully computed EV couplings covariance for: {}'.format(p_id))\n",
    "                counts['success'] += 1\n",
    "            except ValueError:\n",
    "                print('Could not compute EV couplings covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "                    p_id, curr_aln.seq_length, curr_aln.size))\n",
    "                counts['value'] += 1\n",
    "                continue\n",
    "            except AttributeError:\n",
    "                print('Could not compute EV couplings covariance for: {} no alignment'.format(p_id))\n",
    "                counts['attribute'] += 1\n",
    "                continue\n",
    "            if evc_mf_method_df is None:\n",
    "                evc_mf_method_df = protein_df\n",
    "            else:\n",
    "                evc_mf_method_df = evc_mf_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        evc_mf_method_df.to_csv(evc_mf_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = evc_mf_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(evc_mf_method_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out final comparison data so it can be loaded later for generating figures.\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    small_comparison_df['Protein Length'] = small_comparison_df['Protein'].apply(lambda x: generator.protein_data[x]['Length'])\n",
    "    small_comparison_df.to_csv(small_comparison_fn, sep='\\t', header=True, index=False, columns=output_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Execution Time for ET-MIp and cET-MIp\n",
    "The time to compute the trace for the full phylogenetic tree and the trace constrained to a subset of the top levels should take significantly less time to compute, here we evaluate if that is in fact the case or not.\n",
    "\n",
    "## Data Cleaning\n",
    "At least one protein in this data set has a very small alignment and could not be evaluated by cET-MIp because the tree was too small to each the levels set for other proteins. Here we remove those proteins.\n",
    "\n",
    "In addition since this analysis focuses on times and there are many other types of data (some of which cause redundancies in the time data), we will use this opportunity to subset the data and drop duplicates.\n",
    "\n",
    "Finally, for some it will be more informative to view execution time in terms of minutes or hours, as opposed to the originally reported seconds, so we will add columns for these units as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_method_groups = small_comparison_df[['Protein', 'Method']].drop_duplicates().groupby('Protein').count()\n",
    "method_max = protein_method_groups['Method'].max()\n",
    "proteins_to_keep = protein_method_groups.index[protein_method_groups['Method'] == method_max]\n",
    "comparable_method_proteins = small_comparison_df[small_comparison_df['Protein'].isin(proteins_to_keep)]\n",
    "time_columns = ['Protein', 'Protein Length', 'Alignment Size', 'Method', 'Init Time', 'Import Time', 'Dist Tree Time',\n",
    "                'Trace Time', 'Total Time']\n",
    "time_subset_df = comparable_method_proteins.loc[comparable_method_proteins['Method'].isin(['ET-MIp', 'cET-MIp']), time_columns]\n",
    "time_subset_df['Total Time (min)'] = time_subset_df['Total Time'].apply(lambda x: x / 60.0)\n",
    "time_subset_df['Total Time (hr)'] = time_subset_df['Total Time (min)'].apply(lambda x: x / 60.0)\n",
    "time_columns += ['Total Time (min)', 'Total Time (hr)']\n",
    "time_subset_df = time_subset_df.drop_duplicates(subset=None, inplace=False, keep='first')\n",
    "time_subset_df.to_csv(os.path.join(small_set_out_dir, 'Small_Time_Comaprison_Data.csv'), sep='\\t', header=True, index=False,\n",
    "                      columns=time_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Comparison\n",
    "Now that only comparable proteins are present in the data we compare the runtime of individual proteins by method, ordered by their length and the size of their alignemnts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Displayed by protein length order\n",
    "protein_length_order = comparable_method_proteins.sort_values('Protein Length')['Protein'].unique()\n",
    "protein_length_time_plot = sns.barplot(x='Protein', y='Total Time', hue='Method', order=protein_length_order,\n",
    "                                       hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_length_time_plot.set_xticklabels(protein_length_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_length_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Length_Time_Comparison_Sec.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "protein_length_time_plot = sns.barplot(x='Protein', y='Total Time (min)', hue='Method', order=protein_length_order,\n",
    "                                       hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_length_time_plot.set_xticklabels(protein_length_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_length_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Length_Time_Comparison_Min.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "protein_length_time_plot = sns.barplot(x='Protein', y='Total Time (hr)', hue='Method', order=protein_length_order,\n",
    "                                       hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_length_time_plot.set_xticklabels(protein_length_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_length_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Length_Time_Comparison_Hr.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Displayed by alignment size order\n",
    "protein_alignment_order = comparable_method_proteins.sort_values('Alignment Size')['Protein'].unique()\n",
    "protein_alignment_time_plot = sns.barplot(x='Protein', y='Total Time', hue='Method', order=protein_alignment_order,\n",
    "                                          hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_alignment_time_plot.set_xticklabels(protein_alignment_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_alignment_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Alignment_Time_Comparison_Sec.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "protein_alignment_time_plot = sns.barplot(x='Protein', y='Total Time (min)', hue='Method', order=protein_alignment_order,\n",
    "                                          hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_alignment_time_plot.set_xticklabels(protein_alignment_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_alignment_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Alignment_Time_Comparison_Min.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "protein_alignment_time_plot = sns.barplot(x='Protein', y='Total Time (hr)', hue='Method', order=protein_alignment_order,\n",
    "                                          hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_alignment_time_plot.set_xticklabels(protein_alignment_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_alignment_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Alignment_Time_Comparison_Hr.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall comparison of time by method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of ET-MIp and cET-MIp total computation time (sec).\n",
    "protein_method_comp_plot = sns.boxplot(x='Method', y='Total Time', order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_method_comp_plot.set_xticklabels(protein_method_comp_plot.get_xticklabels(), rotation=90)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_Time_Comparison_Sec.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Comparison of ET-MIp and cET-MIp total computation time (sec).\n",
    "protein_method_comp_plot = sns.boxplot(x='Method', y='Total Time (min)', order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_method_comp_plot.set_xticklabels(protein_method_comp_plot.get_xticklabels(), rotation=90)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_Time_Comparison_Min.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Comparison of ET-MIp and cET-MIp total computation time (sec).\n",
    "protein_method_comp_plot = sns.boxplot(x='Method', y='Total Time (hr)', order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_method_comp_plot.set_xticklabels(protein_method_comp_plot.get_xticklabels(), rotation=90)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_Time_Comparison_Hr.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Statistical comparison\n",
    "from scipy.stats import wilcoxon\n",
    "et_mip_sub_df = time_subset_df[time_subset_df['Method'] == 'ET-MIp']\n",
    "cet_mip_sub_df = time_subset_df[time_subset_df['Method'] == 'cET-MIp']\n",
    "sec_stat, sec_p_val = wilcoxon(x=et_mip_sub_df['Total Time'], y=cet_mip_sub_df['Total Time'], zero_method='wilcox')\n",
    "min_stat, min_p_val = wilcoxon(x=et_mip_sub_df['Total Time (min)'], y=cet_mip_sub_df['Total Time (min)'], zero_method='wilcox')\n",
    "hr_stat, hr_p_val = wilcoxon(x=et_mip_sub_df['Total Time (hr)'], y=cet_mip_sub_df['Total Time (hr)'], zero_method='wilcox')\n",
    "time_statistics = {'Time Unit': ['sec', 'min', 'hr'], 'Statistic': [sec_stat, min_stat, hr_stat], 'P-Value': [sec_p_val, min_p_val, hr_p_val]}\n",
    "pd.DataFrame(time_statistics).to_csv(os.path.join(small_set_out_dir, 'Small_Time_Comaprison_Statistics.csv'), sep='\\t', header=True,\n",
    "                                     index=False, columns=['Time Unit', 'Statistic', 'P-Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method Comparison\n",
    "We now begin comparing methods based on their ability to predict the structural contacts in the proteins in this test set. There is an important consideration in the case of sequence separation and different measures by which to compare the methods.\n",
    "\n",
    "### Data Cleaning\n",
    "These data need an additional cleaning step beyond what was performed for the timing comparison. Since there are multiple categories of sequence separation and some proteins may not have any True Positive contacts for a category the scoring for that protein is incomplete. We will remove all such proteins from the comparison, performing the clean up separate for each metric of success. Another contributing factor which necessitates this kind of cleaning is assessment of the top K predictions for a protein or best L/K predictions which for poor predictions may not include any predictions of True Positives.\n",
    "\n",
    "### Sequence Separation\n",
    "One important consideration for the difficulty of prediction and interest in predictions is the distance between the residues for which coupling was predicted. As has been documented in the literature, especially in the CASP competitions, there are several categories of prediction:\n",
    "* Neighbors (1 - 5 residues apart) - This is the least interesting category of predictions. It is highly likely that residues this close together will show covariance signal. Predicting two residues are in contact that are this close together is trivial and uninformative.\n",
    "* Short (6 - 12 residues apart) - This is also not a very interesting type of prediction. Residues this close in proximity can be more easily modeled by alogrithms which focus on 2D protein structure modeling (identifying beta sheets, alpha helices, etc.).\n",
    "* Medium (13 - 24 residues apart) - This is a more interesting type of prediction. The resiudes in this range of separation are on the edge of the 2D protein structure prediction range.\n",
    "* Long (24 and more residues apart) - The most interesting category of predictions. Resiudes this far apart are not easily modeled by 2D protein structure modeling systems. They are also very useful for 3D and 4D protein structure prediction becausae they provide constraints on potential protein (similar to NMR data) folds which makes protein folding a more tractable problem for modelers.\n",
    "* Any/All - All categories can be considered at once, this provides a summary value, but is often skewed by one particularly good category of predictions.\n",
    "\n",
    "### Metrics of Success\n",
    "* AUROC - This measures the True Positive Rate vs the False Positive Rate of prediction, it can be considered a measure of the accuracy of the measure. This can be strongly influenced by the class imbalance which is present when predicting structural contacts since there are many fewer contacts than non-contacts. The True Positive case is if the C-beta of two amino acids is within 8.0 Angstroms of one another (as is done in the CASP competitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_order = ['DCA', 'EVC Standard', 'EVC Mean Field', 'ET-MIp', 'cET-MIp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_columns = ['Protein', 'Method', 'Sequence_Separation', 'AUROC']\n",
    "protein_auroc_groups = comparable_method_proteins[auroc_columns].drop_duplicates().groupby('Protein')['AUROC'].apply(\n",
    "    lambda x: not x.isnull().any())\n",
    "complete_proteins = protein_auroc_groups.index[protein_auroc_groups.values]\n",
    "comparable_auroc_proteins = small_comparison_df[small_comparison_df['Protein'].isin(complete_proteins)]\n",
    "auroc_protein_length_order = [x for x in protein_length_order if x in complete_proteins]\n",
    "auroc_protein_alignment_order = [x for x in protein_alignment_order if x in complete_proteins]\n",
    "auroc_subset_df = comparable_auroc_proteins.loc[:, auroc_columns].drop_duplicates()\n",
    "# Plot the methods vs AUROC per protein ordered by protein length\n",
    "auroc_subset_df.to_csv(os.path.join(small_set_out_dir, 'Small_AUROC_Comaprison_Data.csv'), sep='\\t', header=True, index=False,\n",
    "                       columns=auroc_columns)\n",
    "protein_order_auroc_plot = sns.catplot(x=\"Protein\", y=\"AUROC\", hue=\"Method\", row=\"Sequence_Separation\", data=auroc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auroc_protein_length_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "protein_order_auroc_plot.set_xticklabels(auroc_protein_length_order, rotation=90)\n",
    "protein_order_auroc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUROC_Comparison_Protein_Length_Order.png'),\n",
    "                                 bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUROC per protein ordered by protein alignment size\n",
    "alignment_order_auroc_plot = sns.catplot(x=\"Protein\", y=\"AUROC\", hue=\"Method\", row=\"Sequence_Separation\", data=auroc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auroc_protein_alignment_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "alignment_order_auroc_plot.set_xticklabels(auroc_protein_alignment_order, rotation=90)\n",
    "alignment_order_auroc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUROC_Comparison_Alignment_Size_Order.png'),\n",
    "                                   bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUROC grouped together to see overall trends\n",
    "overall_auroc_plot = sns.boxplot(x=\"Sequence_Separation\", y=\"AUROC\", hue=\"Method\", data=auroc_subset_df,\n",
    "                                 order=sequence_separation_order, hue_order=method_order)\n",
    "overall_auroc_plot.set_xticklabels(sequence_separation_order, rotation=90)\n",
    "overall_auroc_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUROC_Comparison.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Compute statistics comparing methods at each sequence separation\n",
    "auroc_statistics = {'Sequence Separation': [], 'Method 1': [], 'Method 2': [], 'Statistic': [], 'P-Value': []}\n",
    "for sep in sequence_separation_order:\n",
    "    sep_auroc_subset_df = auroc_subset_df.loc[auroc_subset_df['Sequence_Separation'] == sep, :]\n",
    "    for i in range(len(method_order)):\n",
    "        m1_sep_auroc_subset_df = sep_auroc_subset_df.loc[sep_auroc_subset_df['Method'] == method_order[i], :]\n",
    "        for j in range(i + 1, len(method_order)):\n",
    "            m2_sep_auroc_subset_df = sep_auroc_subset_df.loc[sep_auroc_subset_df['Method'] == method_order[j], :]\n",
    "            stat, p_val = wilcoxon(x=m1_sep_auroc_subset_df['AUROC'], y=m2_sep_auroc_subset_df['AUROC'], zero_method='wilcox')\n",
    "            auroc_statistics['Sequence Separation'].append(sep)\n",
    "            auroc_statistics['Method 1'].append(method_order[i])\n",
    "            auroc_statistics['Method 2'].append(method_order[j])\n",
    "            auroc_statistics['Statistic'].append(stat)\n",
    "            auroc_statistics['P-Value'].append(p_val)\n",
    "pd.DataFrame(auroc_statistics).to_csv(os.path.join(small_set_out_dir, 'Small_AUROC_Comaprison_Statistics.csv'), sep='\\t', header=True,\n",
    "                                      index=False, columns=['Sequence Separation', 'Method 1', 'Method 2', 'Statistic', 'P-Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics of Success (Continued)\n",
    "* AUPRC - This measures the Precision vs the Recall of the predictions, it can be considered a measure of the accuracy of the measure. This is less strongly influenced by the class imbalance which is present when predicting structural contacts since there are many fewer contacts than non-contacts. The True Positive case is if the C-beta of two amino acids is within 8.0 Angstroms of one another (as is done in the CASP competitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "auprc_columns = ['Protein', 'Method', 'Sequence_Separation', 'AUPRC']\n",
    "protein_auprc_groups = comparable_method_proteins[auprc_columns].drop_duplicates().groupby('Protein')['AUPRC'].apply(\n",
    "    lambda x: not x.isnull().any())\n",
    "complete_proteins = protein_auprc_groups.index[protein_auprc_groups.values]\n",
    "comparable_auprc_proteins = small_comparison_df[small_comparison_df['Protein'].isin(complete_proteins)]\n",
    "auprc_protein_length_order = [x for x in protein_length_order if x in complete_proteins]\n",
    "auprc_protein_alignment_order = [x for x in protein_alignment_order if x in complete_proteins]\n",
    "auprc_subset_df = comparable_auprc_proteins.loc[:, auprc_columns].drop_duplicates()\n",
    "# Plot the methods vs AUPRC per protein ordered by protein length\n",
    "auprc_subset_df.to_csv(os.path.join(small_set_out_dir, 'Small_AUPRC_Comaprison_Data.csv'), sep='\\t', header=True, index=False,\n",
    "                       columns=auprc_columns)\n",
    "protein_order_auprc_plot = sns.catplot(x=\"Protein\", y=\"AUPRC\", hue=\"Method\", row=\"Sequence_Separation\", data=auprc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auprc_protein_length_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "protein_order_auprc_plot.set_xticklabels(auprc_protein_length_order, rotation=90)\n",
    "protein_order_auprc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUPRC_Comparison_Protein_Length_Order.png'),\n",
    "                                 bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUPRC per protein ordered by protein alignment size\n",
    "alignment_order_auprc_plot = sns.catplot(x=\"Protein\", y=\"AUPRC\", hue=\"Method\", row=\"Sequence_Separation\", data=auprc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auprc_protein_alignment_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "alignment_order_auprc_plot.set_xticklabels(auprc_protein_alignment_order, rotation=90)\n",
    "alignment_order_auprc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUPRC_Comparison_Alignment_Size_Order.png'),\n",
    "                                   bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUPRC grouped together to see overall trends\n",
    "overall_auprc_plot = sns.boxplot(x=\"Sequence_Separation\", y=\"AUPRC\", hue=\"Method\", data=auprc_subset_df,\n",
    "                                 order=sequence_separation_order, hue_order=method_order)\n",
    "overall_auprc_plot.set_xticklabels(sequence_separation_order, rotation=90)\n",
    "overall_auprc_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUPRC_Comparison.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Compute statistics comparing methods at each sequence separation\n",
    "auprc_statistics = {'Sequence Separation': [], 'Method 1': [], 'Method 2': [], 'Statistic': [], 'P-Value': []}\n",
    "for sep in sequence_separation_order:\n",
    "    sep_auprc_subset_df = auprc_subset_df.loc[auprc_subset_df['Sequence_Separation'] == sep, :]\n",
    "    for i in range(len(method_order)):\n",
    "        m1_sep_auprc_subset_df = sep_auprc_subset_df.loc[sep_auprc_subset_df['Method'] == method_order[i], :]\n",
    "        for j in range(i + 1, len(method_order)):\n",
    "            m2_sep_auprc_subset_df = sep_auprc_subset_df.loc[sep_auprc_subset_df['Method'] == method_order[j], :]\n",
    "            stat, p_val = wilcoxon(x=m1_sep_auprc_subset_df['AUPRC'], y=m2_sep_auprc_subset_df['AUPRC'], zero_method='wilcox')\n",
    "            auprc_statistics['Sequence Separation'].append(sep)\n",
    "            auprc_statistics['Method 1'].append(method_order[i])\n",
    "            auprc_statistics['Method 2'].append(method_order[j])\n",
    "            auprc_statistics['Statistic'].append(stat)\n",
    "            auprc_statistics['P-Value'].append(p_val)\n",
    "pd.DataFrame(auprc_statistics).to_csv(os.path.join(small_set_out_dir, 'Small_AUPRC_Comaprison_Statistics.csv'), sep='\\t', header=True,\n",
    "                                      index=False, columns=['Sequence Separation', 'Method 1', 'Method 2', 'Statistic', 'P-Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Precision at K - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Recall at K - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* F1 at K - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Structural Cluster Weighting Z-Score - "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (PyET3)",
   "language": "python",
   "name": "pyet3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
