{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Test Set #\n",
    "## Goal ##\n",
    "The goal of this test set is to perform proof of concept testing on a small number of proteins with a wide range of sizes and available homologs, orthologs, and paralogs. By doing so it should be possible to test the best parameterization for this tool as well as identifying the strengths and weaknesses of the tool using various measurments as end points.\n",
    "## Warning ##\n",
    "Before attempting to use this notebook make sure that your .env file has been properly setup to reflect the correct locations of command line tools and the location of files and directories needed for execution.\n",
    "### Initial Import###\n",
    "This first cell performs the necessary imports required to begin this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "try:\n",
    "    dotenv_path = find_dotenv(raise_error_if_not_found=True)\n",
    "except IOError:\n",
    "    dotenv_path = find_dotenv(raise_error_if_not_found=True, usecwd=True)\n",
    "load_dotenv(dotenv_path)\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ.get('PROJECT_PATH'), 'src'))\n",
    "sys.path.append(os.path.join(os.environ.get('PROJECT_PATH'), 'src', 'SupportingClasses'))\n",
    "input_dir = os.environ.get('INPUT_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set Construction ##\n",
    "The first task required to test the data set is to download the required data and construct any necessary input files for all down stream analyses.\n",
    "In this case that means:\n",
    "* Downloading PDB files for the proteins in our small test set.\n",
    "* Extracting a query sequence from each PDB file.\n",
    "* Searching for paralogs, homologs, and orthologs in a custom BLAST database built by filtering the Uniref90 database.\n",
    "* Filtering the hits from the BLAST search to meet minimum and maximum length requirements, as well as minimum and maximum identity requirements.\n",
    "* Building alignments using CLUSTALW in both the fasta and msf formats since some of the tools which will be used for comparison need different formats.\n",
    "* Filtering the alignment for maximum identity similarity between seqeunces.\n",
    "* Re-aligning the filtered sequences using CLUSTALW.\n",
    "This is all handeled by the DataSetGenerator class found in the src/SupportingClasses folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing protein list\n",
      "Downloading structures and parsing in query sequences\n",
      "Unique Sequences Found: 23!\n",
      "BLASTing query sequences\n",
      "Filtering BLAST hits, aligning, filtering by identity, and re-aligning\n",
      "   Protein_ID Chain     Accession  BLAST_Hits  Filtered_BLAST  \\\n",
      "19       2b59     B    CIPA_CLOTM        1606               4   \n",
      "18       7hvp     A     POL_HV1A2        2500              33   \n",
      "13       1c0k     A    OXDA_RHOTO        2500              51   \n",
      "14       206l     A      LYS_BPT4        1039             131   \n",
      "16       1bol     A    RNRH_RHINI        2500             131   \n",
      "5        3q05     A     P53_HUMAN         932             306   \n",
      "3        1jwl     A    LACI_ECOLI        2500             228   \n",
      "7        1a26     A   PARP1_CHICK        2500             267   \n",
      "9        2ysd     A   MAGI1_HUMAN        2500             412   \n",
      "12       2z0e     A   ATG4B_HUMAN        2111             360   \n",
      "4        4lli     A   MYO5A_HUMAN        2500             441   \n",
      "22       2rh1     A   ADRB2_HUMAN        2500             416   \n",
      "17       3b6v     A   KIF3C_HUMAN        2500             481   \n",
      "20       1h1v     G    GELS_HUMAN        2500             654   \n",
      "0        2zxe     A  Q4H132_SQUAC        2500             880   \n",
      "15       1c17     A    ATPL_ECOLI        1671             850   \n",
      "10       135l     A    LYSC_MELGA        1913             853   \n",
      "2        2wer     A   HSP82_YEAST        2500            1327   \n",
      "6        3tnu     A   K1C14_HUMAN        2500            1681   \n",
      "21       1hck     A    CDK2_HUMAN        2500            2468   \n",
      "11       1axb     A    BLAT_ECOLI        2500            2102   \n",
      "8        4ycu     A     SYK_HUMAN        2500            2421   \n",
      "1        2iop     A    HTPG_ECOLI        2500            2478   \n",
      "\n",
      "    Filtered_Alignment  Length  Total_Size  \n",
      "19                   4    1853      7412.0  \n",
      "18                  33    1437     47421.0  \n",
      "13                  51     368     18768.0  \n",
      "14                  92     164     15088.0  \n",
      "16                 127     238     30226.0  \n",
      "5                  210     393     82530.0  \n",
      "3                  226     360     81360.0  \n",
      "7                  261    1011    263871.0  \n",
      "9                  318    1491    474138.0  \n",
      "12                 344     393    135192.0  \n",
      "4                  352    1855    652960.0  \n",
      "22                 399     413    164787.0  \n",
      "17                 441     793    349713.0  \n",
      "20                 599     782    468418.0  \n",
      "0                  795    1028    817260.0  \n",
      "15                 813      79     64227.0  \n",
      "10                 818     147    120246.0  \n",
      "2                 1207     709    855763.0  \n",
      "6                 1518     472    716496.0  \n",
      "21                1681     298    500938.0  \n",
      "11                2087     286    596882.0  \n",
      "8                 2347     597   1401159.0  \n",
      "1                 2472     624   1542528.0  \n",
      "It took 0.16727733612060547 min to generate the data set.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from DataSetGenerator import DataSetGenerator\n",
    "protein_list_dir = os.path.join(input_dir, 'ProteinLists')\n",
    "if not os.path.isdir(protein_list_dir):\n",
    "    os.makedirs(protein_list_dir)\n",
    "small_list_fn = os.path.join(protein_list_dir, 'SmallDataSet.txt')\n",
    "if not os.path.isfile(small_list_fn):\n",
    "    proteins_of_interest = ['2ysdA', '1c17A', '3tnuA', '7hvpA', '135lA', '206lA', '2werA', '1bolA', '3q05A', '1axbA',\n",
    "                            '2rh1A', '1hckA', '3b6vA', '2z0eA', '1jwlA', '1a26A', '1c0kA', '4lliA', '4ycuA', '2iopA',\n",
    "                            '2zxeA', '2b59B', '1h1vG']\n",
    "    with open(small_list_fn, 'w') as small_list_handle:\n",
    "        for p_id in proteins_of_interest:\n",
    "            small_list_handle.write('{}\\n'.format(p_id))\n",
    "generator = DataSetGenerator(input_dir)\n",
    "start = time()\n",
    "summary = generator.build_pdb_alignment_dataset(protein_list_fn=os.path.basename(small_list_fn), processes=10,\n",
    "                                                database='customuniref90.fasta', max_target_seqs=2500, remote=False,\n",
    "                                                verbose=False)\n",
    "summary['Chain'] = summary['Protein_ID'].apply(lambda x: generator.protein_data[x]['Chain'])\n",
    "summary['Accession'] = summary['Protein_ID'].apply(lambda x: generator.protein_data[x]['Accession'])\n",
    "summary['Length'] = summary['Protein_ID'].apply(lambda x: generator.protein_data[x]['Length'])\n",
    "summary['Total_Size'] = summary.apply(lambda x: float(x['Length']) * float(x['Filtered_Alignment']), axis=1)\n",
    "summary.sort_values(by=['Filtered_Alignment', 'Length'], axis=0, inplace=True)\n",
    "summary_columns = ['Protein_ID', 'Chain', 'Accession', 'BLAST_Hits', 'Filtered_BLAST',\n",
    "                   'Filtered_Alignment', 'Length', 'Total_Size']\n",
    "print(summary[summary_columns])\n",
    "end = time()\n",
    "print('It took {} min to generate the data set.'.format((end - start) / 60.0))\n",
    "summary.to_csv(os.path.join(input_dir, 'small_data_set_summary.tsv'), sep='\\t', index=False, header=True,\n",
    "               columns=summary_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a location to store the output of this method comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.environ.get('OUTPUT_PATH')\n",
    "small_set_out_dir = os.path.join(output_dir, 'SmallTestSet')\n",
    "if not os.path.isdir(small_set_out_dir):\n",
    "    os.makedirs(small_set_out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Scoring For Each Method\n",
    "To reduce memory load during prediction and evaluation, the scoring objects needed to compute the metrics used to compare methods will be created ahead of time so they are available to each method when it computes its predictions for a given protein. This will ensure that results do not need to be kept in memory while waiting for all other results to be computed, only the metrics measured for each method will be recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.00035761197408040366 min\n",
      "Importing the PDB file took 0.0029230634371439617 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2960.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3114.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2960.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3114.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.0005341450373331706 min\n",
      "Importing the PDB file took 0.0012839953104654947 min\n",
      "Mapping query sequence and pdb took 0.0023559808731079103 min\n",
      "Computing the distance matrix based on the PDB file took 0.0029813647270202637 min\n",
      "Removing gaps took 0.00022375186284383138 min\n",
      "Importing the PDB file took 0.0007433017094930013 min\n",
      "Mapping query sequence and pdb took 0.001366718610127767 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2960.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3114.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.003194904327392578 min\n",
      "Removing gaps took 0.0012140790621439615 min\n",
      "Importing the PDB file took 0.0010810414950052896 min\n",
      "Removing gaps took 0.0006622950236002604 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2100.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 2138.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 2191.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2100.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 2138.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 2191.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.0007343888282775879 min\n",
      "Mapping query sequence and pdb took 0.0016265432039896646 min\n",
      "Computing the distance matrix based on the PDB file took 0.0012339472770690918 min\n",
      "Removing gaps took 0.0006877462069193522 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2100.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 2138.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 2191.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.0019040981928507487 min\n",
      "Mapping query sequence and pdb took 0.002870655059814453 min\n",
      "Computing the distance matrix based on the PDB file took 0.0012443224589029948 min\n",
      "Removing gaps took 0.0006171027819315592 min\n",
      "Importing the PDB file took 0.0020156065622965497 min\n",
      "Removing gaps took 0.0006418267885843913 min\n",
      "Importing the PDB file took 0.0015513340632120768 min\n",
      "Mapping query sequence and pdb took 0.0023674686749776204 min\n",
      "Computing the distance matrix based on the PDB file took 0.01543415387471517 min\n",
      "Removing gaps took 0.0005736827850341796 min\n",
      "Importing the PDB file took 0.002214447657267253 min\n",
      "Mapping query sequence and pdb took 0.0029568831125895184 min\n",
      "Computing the distance matrix based on the PDB file took 0.015213024616241456 min\n",
      "Removing gaps took 0.00043114821116129555 min\n",
      "Importing the PDB file took 0.000867907206217448 min\n",
      "Removing gaps took 0.00037651856740315756 min\n",
      "Importing the PDB file took 0.0004058718681335449 min\n",
      "Mapping query sequence and pdb took 0.0008528788884480794 min\n",
      "Computing the distance matrix based on the PDB file took 0.002912724018096924 min\n",
      "Removing gaps took 0.0003132383028666178 min\n",
      "Importing the PDB file took 0.0003667036692301432 min\n",
      "Mapping query sequence and pdb took 0.0007490913073221842 min\n",
      "Computing the distance matrix based on the PDB file took 0.003151969114939372 min\n",
      "Removing gaps took 0.0011287291844685873 min\n",
      "Importing the PDB file took 0.001706238587697347 min\n",
      "Removing gaps took 0.0008337060610453288 min\n",
      "Importing the PDB file took 0.0004206697146097819 min\n",
      "Mapping query sequence and pdb took 0.001343683401743571 min\n",
      "Computing the distance matrix based on the PDB file took 0.0055454492568969725 min\n",
      "Removing gaps took 0.0008159160614013671 min\n",
      "Importing the PDB file took 0.0003882288932800293 min\n",
      "Mapping query sequence and pdb took 0.0013106107711791993 min\n",
      "Computing the distance matrix based on the PDB file took 0.005938037236531576 min\n",
      "Removing gaps took 0.005987048149108887 min\n",
      "Importing the PDB file took 0.0027661720911661782 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 9163.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 9164.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 9165.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 9166.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 9167.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 9201.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 9267.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 9314.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain K is discontinuous at line 9321.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain L is discontinuous at line 9325.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.005387806892395019 min\n",
      "Importing the PDB file took 0.0028868714968363443 min\n",
      "Mapping query sequence and pdb took 0.008743973573048909 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 9163.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 9164.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 9165.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 9166.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 9167.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 9201.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 9267.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 9314.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain K is discontinuous at line 9321.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain L is discontinuous at line 9325.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.006230103969573975 min\n",
      "Removing gaps took 0.0054977178573608395 min\n",
      "Importing the PDB file took 0.002827322483062744 min\n",
      "Mapping query sequence and pdb took 0.00878314177195231 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 9163.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 9164.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 9165.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 9166.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 9167.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 9201.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 9267.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 9314.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain K is discontinuous at line 9321.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain L is discontinuous at line 9325.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.007442951202392578 min\n",
      "Removing gaps took 0.0021175265312194822 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 8081.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 8101.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 8121.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.0020781397819519044 min\n",
      "Removing gaps took 0.003196132183074951 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 8081.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 8101.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 8121.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.0018346786499023437 min\n",
      "Mapping query sequence and pdb took 0.005248645941416423 min\n",
      "Computing the distance matrix based on the PDB file took 0.011430474122365315 min\n",
      "Removing gaps took 0.004404115676879883 min\n",
      "Importing the PDB file took 0.0016899903615315754 min\n",
      "Mapping query sequence and pdb took 0.006508477528889974 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 8081.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 8101.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 8121.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.014408087730407715 min\n",
      "Removing gaps took 0.017411466439565024 min\n",
      "Importing the PDB file took 0.0012807687123616537 min\n",
      "Removing gaps took 0.0181235671043396 min\n",
      "Importing the PDB file took 0.0006534973780314128 min\n",
      "Mapping query sequence and pdb took 0.02002082665761312 min\n",
      "Computing the distance matrix based on the PDB file took 0.013660172621409098 min\n",
      "Removing gaps took 0.016089022159576416 min\n",
      "Importing the PDB file took 0.0006278832753499349 min\n",
      "Mapping query sequence and pdb took 0.018182289600372315 min\n",
      "Computing the distance matrix based on the PDB file took 0.014986809094746907 min\n",
      "Removing gaps took 0.027816406885782876 min\n",
      "Importing the PDB file took 0.005727513631184896 min\n",
      "Removing gaps took 0.027064164479573567 min\n",
      "Importing the PDB file took 0.0057994683583577475 min\n",
      "Mapping query sequence and pdb took 0.04560620387395223 min\n",
      "Computing the distance matrix based on the PDB file took 0.0003823121388753255 min\n",
      "Removing gaps took 0.027780485153198243 min\n",
      "Importing the PDB file took 0.004843231042226156 min\n",
      "Mapping query sequence and pdb took 0.045588243007659915 min\n",
      "Computing the distance matrix based on the PDB file took 0.0005262573560078939 min\n",
      "Removing gaps took 0.010099053382873535 min\n",
      "Importing the PDB file took 0.0011657516161600748 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 3897.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4034.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.009760093688964844 min\n",
      "Importing the PDB file took 0.0008462270100911459 min\n",
      "Mapping query sequence and pdb took 0.010921068986256917 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 3897.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4034.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.010933597882588705 min\n",
      "Removing gaps took 0.011046934127807616 min\n",
      "Importing the PDB file took 0.0029242555300394695 min\n",
      "Mapping query sequence and pdb took 0.01472158432006836 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 3897.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4034.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.011497060457865397 min\n",
      "Removing gaps took 0.05157386859258016 min\n",
      "Importing the PDB file took 0.0017905195554097494 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6531.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 6714.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.051024095217386885 min\n",
      "Importing the PDB file took 0.0014230569203694662 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6531.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 6714.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping query sequence and pdb took 0.05539208253224691 min\n",
      "Computing the distance matrix based on the PDB file took 0.016651960213979085 min\n",
      "Removing gaps took 0.052708768844604494 min\n",
      "Importing the PDB file took 0.0014222423235575358 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6531.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 6714.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping query sequence and pdb took 0.057111823558807374 min\n",
      "Computing the distance matrix based on the PDB file took 0.01781843105951945 min\n",
      "Removing gaps took 0.009731245040893555 min\n",
      "Importing the PDB file took 0.001206827163696289 min\n",
      "Removing gaps took 0.009265279769897461 min\n",
      "Importing the PDB file took 0.0008852044741312663 min\n",
      "Mapping query sequence and pdb took 0.01847729682922363 min\n",
      "Computing the distance matrix based on the PDB file took 0.021158961455027263 min\n",
      "Removing gaps took 0.009330145517985026 min\n",
      "Importing the PDB file took 0.0008737921714782714 min\n",
      "Mapping query sequence and pdb took 0.020247141520182293 min\n",
      "Computing the distance matrix based on the PDB file took 0.022627011934916178 min\n",
      "Removing gaps took 0.028204989433288575 min\n",
      "Importing the PDB file took 0.0014022588729858398 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5418.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/Atom.py:189: PDBConstructionWarning: Used element 'U' for Atom (name=UNK) with given element 'X'\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5449.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5482.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5486.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.03028901815414429 min\n",
      "Importing the PDB file took 0.0010670940081278482 min\n",
      "Mapping query sequence and pdb took 0.03238084316253662 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5418.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/Atom.py:189: PDBConstructionWarning: Used element 'U' for Atom (name=UNK) with given element 'X'\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5449.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5482.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5486.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.010306803385416667 min\n",
      "Removing gaps took 0.028255903720855714 min\n",
      "Importing the PDB file took 0.0010560274124145508 min\n",
      "Mapping query sequence and pdb took 0.02994236946105957 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5418.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/Atom.py:189: PDBConstructionWarning: Used element 'U' for Atom (name=UNK) with given element 'X'\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5449.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5482.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5486.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.012384398778279623 min\n",
      "Removing gaps took 0.045598928133646646 min\n",
      "Importing the PDB file took 0.0021667718887329102 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6161.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 6193.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6197.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 6393.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.042883690198262533 min\n",
      "Importing the PDB file took 0.0029928843180338544 min\n",
      "Mapping query sequence and pdb took 0.04658692280451457 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6161.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 6193.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6197.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 6393.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.012373145421346028 min\n",
      "Removing gaps took 0.04329909880956014 min\n",
      "Importing the PDB file took 0.0013120333353678385 min\n",
      "Mapping query sequence and pdb took 0.04528274138768514 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6161.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 6193.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6197.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 6393.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.012838935852050782 min\n",
      "Removing gaps took 0.085567307472229 min\n",
      "Importing the PDB file took 0.002627249558766683 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11066.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 11103.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11145.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.0866447408994039 min\n",
      "Importing the PDB file took 0.0022523880004882814 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11066.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 11103.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11145.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping query sequence and pdb took 0.09087692101796468 min\n",
      "Computing the distance matrix based on the PDB file took 0.1012054721514384 min\n",
      "Removing gaps took 0.08756890296936035 min\n",
      "Importing the PDB file took 0.0022269129753112794 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11066.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 11103.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11145.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping query sequence and pdb took 0.09173396825790406 min\n",
      "Computing the distance matrix based on the PDB file took 0.11261076927185058 min\n",
      "Removing gaps took 0.004369878768920898 min\n",
      "Importing the PDB file took 0.0037349343299865724 min\n",
      "Removing gaps took 0.0042858044306437176 min\n",
      "Importing the PDB file took 0.003286643822987874 min\n",
      "Mapping query sequence and pdb took 0.007710385322570801 min\n",
      "Computing the distance matrix based on the PDB file took 0.000721124807993571 min\n",
      "Removing gaps took 0.0045958757400512695 min\n",
      "Importing the PDB file took 0.00322189728418986 min\n",
      "Mapping query sequence and pdb took 0.007970778147379558 min\n",
      "Computing the distance matrix based on the PDB file took 0.0010088562965393066 min\n",
      "Removing gaps took 0.011838038762410482 min\n",
      "Importing the PDB file took 0.0007766087849934896 min\n",
      "Removing gaps took 0.012195146083831787 min\n",
      "Importing the PDB file took 0.0002846240997314453 min\n",
      "Mapping query sequence and pdb took 0.01274776856104533 min\n",
      "Computing the distance matrix based on the PDB file took 0.0015455087025960286 min\n",
      "Removing gaps took 0.011775843302408854 min\n",
      "Importing the PDB file took 0.0002868215243021647 min\n",
      "Mapping query sequence and pdb took 0.012253900369008383 min\n",
      "Computing the distance matrix based on the PDB file took 0.0019301652908325195 min\n",
      "Removing gaps took 0.10432569185892741 min\n",
      "Importing the PDB file took 0.001219181219736735 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 4201.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4226.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 4251.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4395.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.10475523074467977 min\n",
      "Importing the PDB file took 0.0009712457656860351 min\n",
      "Mapping query sequence and pdb took 0.1069344719250997 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 4201.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4226.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 4251.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4395.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.004884541034698486 min\n",
      "Removing gaps took 0.10564639170964558 min\n",
      "Importing the PDB file took 0.0009310801823933919 min\n",
      "Mapping query sequence and pdb took 0.10788713693618775 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 4201.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4226.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 4251.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4395.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.005985097090403239 min\n",
      "Removing gaps took 0.07256233294804891 min\n",
      "Importing the PDB file took 0.0009890039761861166 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 3478.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3488.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.07266640663146973 min\n",
      "Importing the PDB file took 0.0029077887535095214 min\n",
      "Mapping query sequence and pdb took 0.0765071431795756 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 3478.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3488.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.0008477648099263509 min\n",
      "Removing gaps took 0.070345405737559 min\n",
      "Importing the PDB file took 0.0005972822507222494 min\n",
      "Mapping query sequence and pdb took 0.07190616130828857 min\n",
      "Computing the distance matrix based on the PDB file took 0.0009584228197733561 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 3478.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3488.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.07161407868067424 min\n",
      "Importing the PDB file took 0.0007194916407267253 min\n",
      "Removing gaps took 0.0713257114092509 min\n",
      "Importing the PDB file took 0.000567928949991862 min\n",
      "Mapping query sequence and pdb took 0.07296269337336223 min\n",
      "Computing the distance matrix based on the PDB file took 0.009139927228291829 min\n",
      "Removing gaps took 0.06906507809956869 min\n",
      "Importing the PDB file took 0.000557871659596761 min\n",
      "Mapping query sequence and pdb took 0.07077186107635498 min\n",
      "Computing the distance matrix based on the PDB file took 0.010944620768229166 min\n",
      "Removing gaps took 0.045420360565185544 min\n",
      "Importing the PDB file took 0.0030422210693359375 min\n",
      "Removing gaps took 0.045657014846801756 min\n",
      "Importing the PDB file took 0.0004896203676859538 min\n",
      "Mapping query sequence and pdb took 0.0467659592628479 min\n",
      "Computing the distance matrix based on the PDB file took 0.007254894574483236 min\n",
      "Removing gaps took 0.04579707384109497 min\n",
      "Importing the PDB file took 0.002964206536610921 min\n",
      "Mapping query sequence and pdb took 0.04939571619033813 min\n",
      "Computing the distance matrix based on the PDB file took 0.009412876764933268 min\n",
      "Removing gaps took 0.16132665077845257 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 17206.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 17292.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 17378.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 18052.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 18724.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.004579714934031169 min\n",
      "Removing gaps took 0.16463130712509155 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 17206.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 17292.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 17378.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 18052.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 18724.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.0034204403559366862 min\n",
      "Mapping query sequence and pdb took 0.17005398273468017 min\n",
      "Computing the distance matrix based on the PDB file took 0.03083344300587972 min\n",
      "Removing gaps took 0.1584663947423299 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 17206.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 17292.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 17378.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 18052.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 18724.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.006429104010264078 min\n",
      "Mapping query sequence and pdb took 0.16995570659637452 min\n",
      "Computing the distance matrix based on the PDB file took 0.03356578747431437 min\n",
      "Removing gaps took 0.10802408456802368 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 20520.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 20547.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 20574.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 20601.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.007451208432515463 min\n",
      "Removing gaps took 0.10627371470133463 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 20520.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 20547.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 20574.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 20601.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.0041050593058268225 min\n",
      "Mapping query sequence and pdb took 0.11167031129201253 min\n",
      "Computing the distance matrix based on the PDB file took 0.042313822110493976 min\n",
      "Removing gaps took 0.10394990841547648 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 20520.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 20547.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 20574.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 20601.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.007165094216664632 min\n",
      "Mapping query sequence and pdb took 0.11242412726084391 min\n",
      "Computing the distance matrix based on the PDB file took 0.04454504251480103 min\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from SeqAlignment import SeqAlignment\n",
    "from PDBReference import PDBReference\n",
    "from ContactScorer import ContactScorer, plot_z_scores\n",
    "protein_order = list(summary['Protein_ID'])\n",
    "method_order = ['DCA', 'EVC Standard', 'EVC Mean Field', 'ET-MIp', 'cET-MIp', 'ET-MIp_MAX']\n",
    "sequence_separation_order = ['Any', 'Neighbors', 'Short', 'Medium', 'Long']\n",
    "protein_scorers = {}\n",
    "small_comparison_df = None\n",
    "small_comparison_fn = os.path.join(small_set_out_dir, 'Small_Comparision_Data.csv')\n",
    "if os.path.isfile(small_comparison_fn):\n",
    "    small_comparison_df = pd.read_csv(small_comparison_fn, sep='\\t', header=0, index_col=False)\n",
    "else:\n",
    "    for p_id in summary['Protein_ID']:\n",
    "        protein_scorers[p_id] = {}\n",
    "        # Import alignment and remove gaps\n",
    "        full_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id)\n",
    "        full_aln.import_alignment()\n",
    "        non_gap_aln = full_aln.remove_gaps()\n",
    "        # Import structure\n",
    "        pdb_structure = PDBReference(pdb_file=generator.protein_data[p_id]['PDB'])\n",
    "        pdb_structure.import_pdb(structure_id=p_id)\n",
    "        protein_scorers[p_id]['Structure'] = pdb_structure\n",
    "        # Initialize Beta Carbon distance scorer\n",
    "        contact_scorer_cb = ContactScorer(query=p_id, seq_alignment=non_gap_aln,\n",
    "                                          pdb_reference=pdb_structure, cutoff=8.0)\n",
    "        contact_scorer_cb.best_chain = generator.protein_data[p_id]['Chain']\n",
    "        contact_scorer_cb.fit()\n",
    "        contact_scorer_cb.measure_distance(method='CB')\n",
    "        protein_scorers[p_id]['Scorer_CB'] = contact_scorer_cb\n",
    "        # Initialize distance scorer minimizing distance between any atoms\n",
    "        contact_scorer_any = ContactScorer(query=p_id, seq_alignment=non_gap_aln,\n",
    "                                           pdb_reference=pdb_structure, cutoff=8.0)\n",
    "        contact_scorer_any.best_chain = generator.protein_data[p_id]['Chain']\n",
    "        contact_scorer_any.fit()\n",
    "        contact_scorer_any.measure_distance(method='Any')\n",
    "        protein_scorers[p_id]['Scorer_Any'] = contact_scorer_any\n",
    "        # Initialize z-scoring subproblems\n",
    "        protein_scorers[p_id]['biased_w2_ave'] = None\n",
    "        protein_scorers[p_id]['unbiased_w2_ave'] = None\n",
    "output_columns = ['Protein', 'Protein Length', 'Alignment Size', 'Method', 'Distance', 'Init Time', 'Import Time', 'Dist Tree Time', 'Trace Time', 'Total Time', \n",
    "                  'Sequence_Separation', 'AUROC', 'AUPRC', 'AUTPRFDRC',\n",
    "                  'Top K Predictions', 'Precision', 'Recall', 'F1 Score',\n",
    "                  'Biased Z-Score at 10%', 'Biased Z-Score at 30%', 'Max Biased Z-Score', 'AUC Biased Z-Score',\n",
    "                  'Unbiased Z-Score at 10%', 'Biased Z-Score at 30%', 'Max Unbiased Z-Score', 'AUC Unbiased Z-Score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Values For Comparision#\n",
    "To determine the effectiveness of the new method and implementation the covariation of the same proteins will be computed using the previous Evolutionary Trace covariation method (ET-MIp) and other methods in the field.\n",
    "\n",
    "## ET-MIp##\n",
    "Scoring the the covariation of the proteins using the previous Evolutionary Trace covariation method (ET-MIp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from ETMIPWrapper import ETMIPWrapper\n",
    "# etmip_out_dir = os.path.join(small_set_out_dir, 'ET-MIp')\n",
    "# if not os.path.isdir(etmip_out_dir):\n",
    "#     os.makedirs(etmip_out_dir)\n",
    "# etmip_scores = {}\n",
    "# counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "# for p_id in generator.protein_data:\n",
    "#     print('Attempting to calculate ET-MIp covariance for: {}'.format(p_id))\n",
    "#     try:\n",
    "#         protein_out_dir = os.path.join(etmip_out_dir, p_id)\n",
    "#         if not os.path.isdir(protein_out_dir):\n",
    "#             os.makedirs(protein_out_dir)\n",
    "#         curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id, polymer_type='Protein')\n",
    "#         curr_aln.import_alignment()\n",
    "#         curr_etmip = ETMIPWrapper(alignment=curr_aln)\n",
    "#         curr_etmip.calculate_scores(out_dir=protein_out_dir, delete_files=False)\n",
    "#         etmip_scores[p_id] = curr_etmip\n",
    "#         print('Successfully computed ET-MIp covariance for: {}'.format(p_id))\n",
    "#         counts['success'] += 1\n",
    "#     except ValueError:\n",
    "#         print('Could not compute ET-MIp covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "#             p_id, curr_aln.seq_length, curr_aln.size))\n",
    "#         counts['value'] += 1\n",
    "#     except AttributeError:\n",
    "#         print('Could not compute ET-MIp covariance for: {} no alignment'.format(p_id))\n",
    "#         counts['attribute'] += 1\n",
    "# print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "#                                                                      counts['attribute']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ET-MIp (Continued)\n",
    "The previous implementation is not able to run for alignments of the size used here. Instead we use the new implementation with the same parameterization used by the previous implementation (Distance Model - blosum62 similarity, Tree - ET UPGMA variant, Scoring Metric - filtered average product corrected mutual information, Ranks - all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EvolutionaryTrace import EvolutionaryTrace\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    etmip_out_dir = os.path.join(small_set_out_dir, 'ET-MIp')\n",
    "    if not os.path.isdir(etmip_out_dir):\n",
    "        os.makedirs(etmip_out_dir)\n",
    "    etmip_method_fn = os.path.join(etmip_out_dir, 'ET-MIp_Method_Data.csv')\n",
    "    if os.path.isfile(etmip_method_fn):\n",
    "        etmip_method_df = pd.read_csv(etmip_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:    \n",
    "        etmip_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "        for p_id in summary['Protein_ID']:\n",
    "            print('Attempting to calculate ET-MIp covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(etmip_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "            else:\n",
    "                try:\n",
    "\n",
    "                    start_time = time()\n",
    "                    curr_etmip = EvolutionaryTrace(query_id=p_id, polymer_type='Protein',\n",
    "                                                   aln_fn=generator.protein_data[p_id]['Final_FA_Aln'], et_distance=True,\n",
    "                                                   distance_model='blosum62', tree_building_method='et', tree_building_options={},\n",
    "                                                   ranks=None, position_type='pair',\n",
    "                                                   scoring_metric='filtered_average_product_corrected_mutual_information',\n",
    "                                                   gap_correction=None, maximize=False, out_dir=protein_dir,\n",
    "                                                   output_files={'original_aln', 'non_gap_aln', 'tree', 'scores'},\n",
    "                                                   processors=10, low_memory=True)\n",
    "                    init_time = time()\n",
    "                    curr_etmip.import_and_process_aln()\n",
    "                    import_time = time()\n",
    "                    curr_etmip.compute_distance_matrix_tree_and_assignments()\n",
    "                    dist_tree_time = time()\n",
    "                    curr_etmip.perform_trace()\n",
    "                    end_time = time()\n",
    "                    print('Successfully computed ET-MIp covariance for: {}'.format(p_id))\n",
    "                    # Compute statistics for the final scores of the ET-MIp model\n",
    "                    protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                        predictor=curr_etmip, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                        unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=curr_etmip.scorer.position_size,\n",
    "                        rank_type=curr_etmip.scorer.rank_type, file_prefix='ET-MIp_Scores_', plots=True)\n",
    "                    # Score Prediction Clustering\n",
    "                    z_score_fn = os.path.join(protein_dir, 'ET-MIp_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                    z_score_plot_fn = os.path.join(protein_dir, 'ET-MIp_Scores_Dist-Any_{}_ZScores.png')\n",
    "                    z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - curr_etmip.coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                    biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                    protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                    plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                    z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - curr_etmip.coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                    unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                    protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                    plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                    # Record execution times\n",
    "                    protein_df['Init Time'] = init_time - start_time\n",
    "                    protein_df['Import Time'] = import_time - init_time\n",
    "                    protein_df['Dist Tree Time'] = dist_tree_time - import_time\n",
    "                    protein_df['Trace Time'] = end_time - dist_tree_time\n",
    "                    protein_df['Total Time'] = end_time - start_time\n",
    "                    # Record static data for this protein\n",
    "                    protein_df['Protein'] = p_id\n",
    "                    protein_df['Method'] = 'ET-MIp'\n",
    "                    protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                    protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                    temp_data = os.path.join(protein_dir, 'unique_node_data')\n",
    "                    for temp_fn in os.listdir(temp_data):\n",
    "                        if not temp_fn.endswith(\"_pair_rank_filtered_average_product_corrected_mutual_information_score.npz\"):\n",
    "                            os.remove(os.path.join(temp_data, temp_fn))\n",
    "                    print('Metrics meastured for ET-MIp covariance for: {}'.format(p_id))\n",
    "                    counts['success'] += 1\n",
    "                except ValueError:\n",
    "                    print('Could not compute ET-MIp covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "                        p_id, curr_etmip.original_aln.seq_length, curr_etmip.original_aln.size))\n",
    "                    counts['value'] += 1\n",
    "                    continue\n",
    "                except AttributeError:\n",
    "                    print('Could not compute ET-MIp covariance for: {} no alignment'.format(p_id))\n",
    "                    counts['attribute'] += 1\n",
    "                    continue\n",
    "            if etmip_method_df is None:\n",
    "                etmip_method_df = protein_df\n",
    "            else:\n",
    "                etmip_method_df = etmip_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        etmip_method_df.to_csv(etmip_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = etmip_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(etmip_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cET-MIp\n",
    "This segment the ET-MIp method, when constrained to an arbitrary set of nodes (1, 2, 3, 5, 7, 10, 25) at the top of the phylogenetic tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(small_comparison_fn):\n",
    "    cetmip_out_dir = os.path.join(small_set_out_dir, 'cET-MIp')\n",
    "    if not os.path.isdir(cetmip_out_dir):\n",
    "        os.makedirs(cetmip_out_dir)\n",
    "    cetmip_method_fn = os.path.join(cetmip_out_dir, 'cET-MIp_Method_Data.csv')\n",
    "    if os.path.isfile(cetmip_method_fn):\n",
    "        cetmip_method_df = pd.read_csv(cetmip_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:\n",
    "        cetmip_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0, 'key': 0}\n",
    "        for p_id in summary['Protein_ID']:\n",
    "            print('Attempting to calculate cET-MIp covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(cetmip_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "            else:\n",
    "                try:\n",
    "                    start_time = time()\n",
    "                    curr_cetmip = EvolutionaryTrace(query_id=p_id, polymer_type='Protein',\n",
    "                                                   aln_fn=generator.protein_data[p_id]['Final_FA_Aln'], et_distance=True,\n",
    "                                                   distance_model='blosum62', tree_building_method='et', tree_building_options={},\n",
    "                                                   ranks=[1, 2, 3, 5, 7, 10, 25], position_type='pair',\n",
    "                                                   scoring_metric='filtered_average_product_corrected_mutual_information',\n",
    "                                                   gap_correction=None, maximize=False, out_dir=protein_dir,\n",
    "                                                   output_files={'original_aln', 'non_gap_aln', 'tree', 'scores'},\n",
    "                                                   processors=10, low_memory=True)\n",
    "                    init_time = time()\n",
    "                    curr_cetmip.import_and_process_aln()\n",
    "                    import_time = time()\n",
    "                    curr_cetmip.compute_distance_matrix_tree_and_assignments()\n",
    "                    dist_tree_time = time()\n",
    "                    curr_cetmip.perform_trace()\n",
    "                    end_time = time()\n",
    "                    # Compute statistics for the final scores of the ET-MIp model\n",
    "                    protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                        predictor=curr_cetmip, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                        unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=curr_cetmip.scorer.position_size,\n",
    "                        rank_type=curr_cetmip.scorer.rank_type, file_prefix='cET-MIp_Scores_', plots=True)\n",
    "                    # Score Prediction Clustering\n",
    "                    z_score_fn = os.path.join(protein_dir, 'cET-MIp_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                    z_score_plot_fn = os.path.join(protein_dir, 'cET-MIp_Scores_Dist-Any_{}_ZScores.png')\n",
    "                    z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - curr_cetmip.coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                    biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                    protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                    plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                    z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - curr_cetmip.coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                    unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                    protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                    plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                    # Record execution times\n",
    "                    protein_df['Init Time'] = init_time - start_time\n",
    "                    protein_df['Import Time'] = import_time - init_time\n",
    "                    protein_df['Dist Tree Time'] = dist_tree_time - import_time\n",
    "                    protein_df['Trace Time'] = end_time - dist_tree_time\n",
    "                    protein_df['Total Time'] = end_time - start_time\n",
    "                    # Record static data for this protein\n",
    "                    protein_df['Protein'] = p_id\n",
    "                    protein_df['Method'] = 'cET-MIp'\n",
    "                    protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                    protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                    temp_data = os.path.join(protein_dir, 'unique_node_data')\n",
    "                    for temp_fn in os.listdir(temp_data):\n",
    "                        if not temp_fn.endswith(\"_pair_rank_filtered_average_product_corrected_mutual_information_score.npz\"):\n",
    "                            os.remove(os.path.join(temp_data, temp_fn))\n",
    "                    print('Successfully computed cET-MIp covariance for: {}'.format(p_id))\n",
    "                    counts['success'] += 1\n",
    "                except ValueError:\n",
    "                    print('Could not compute cET-MIp covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "                        p_id, curr_cetmip.original_aln.seq_length, curr_etmip.original_aln.size))\n",
    "                    counts['value'] += 1\n",
    "                    continue\n",
    "                except AttributeError:\n",
    "                    print('Could not compute cET-MIp covariance for: {} no alignment'.format(p_id))\n",
    "                    counts['attribute'] += 1\n",
    "                    continue\n",
    "                except KeyError:\n",
    "                    print('Could not compute cET-MIp covariance for: {} not enough sequences'.format('p_ied'))\n",
    "                    counts['key'] += 1\n",
    "                    continue\n",
    "            if cetmip_method_df is None:\n",
    "                cetmip_method_df = protein_df\n",
    "            else:\n",
    "                cetmip_method_df = cetmip_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        cetmip_method_df.to_csv(cetmip_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = cetmip_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(cetmip_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ET-MIp with Group Maximiziation ###\n",
    "This cell generates data for and tests the effect of maximizing the group score when moving from a parent node to child nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/pandas/core/frame.py:7116: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "from EvolutionaryTrace import EvolutionaryTrace\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    etmip_out_dir = os.path.join(small_set_out_dir, 'ET-MIp_MAX')\n",
    "    if not os.path.isdir(etmip_out_dir):\n",
    "        os.makedirs(etmip_out_dir)\n",
    "    etmip_method_fn = os.path.join(etmip_out_dir, 'ET-MIp_MAX_Method_Data.csv')\n",
    "    if os.path.isfile(etmip_method_fn):\n",
    "        etmip_method_df = pd.read_csv(etmip_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:    \n",
    "        etmip_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "        for p_id in summary['Protein_ID']:\n",
    "            print('Attempting to calculate ET-MIp MAXIMIZED covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(etmip_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "            else:\n",
    "                try:\n",
    "\n",
    "                    start_time = time()\n",
    "                    curr_etmip = EvolutionaryTrace(query_id=p_id, polymer_type='Protein',\n",
    "                                                   aln_fn=generator.protein_data[p_id]['Final_FA_Aln'], et_distance=True,\n",
    "                                                   distance_model='blosum62', tree_building_method='et', tree_building_options={},\n",
    "                                                   ranks=None, position_type='pair',\n",
    "                                                   scoring_metric='filtered_average_product_corrected_mutual_information',\n",
    "                                                   gap_correction=None, maximize=True, out_dir=protein_dir,\n",
    "                                                   output_files={'original_aln', 'non_gap_aln', 'tree', 'scores'},\n",
    "                                                   processors=10, low_memory=True)\n",
    "                    init_time = time()\n",
    "                    curr_etmip.import_and_process_aln()\n",
    "                    import_time = time()\n",
    "                    curr_etmip.compute_distance_matrix_tree_and_assignments()\n",
    "                    dist_tree_time = time()\n",
    "                    curr_etmip.perform_trace()\n",
    "                    end_time = time()\n",
    "                    print('Successfully computed ET-MIp MAX covariance for: {}'.format(p_id))\n",
    "                    # Compute statistics for the final scores of the ET-MIp model\n",
    "                    protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                        predictor=curr_etmip, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                        unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=curr_etmip.scorer.position_size,\n",
    "                        rank_type=curr_etmip.scorer.rank_type, file_prefix='ET-MIp_MAX_Scores_', plots=True)\n",
    "                    # Score Prediction Clustering\n",
    "                    z_score_fn = os.path.join(protein_dir, 'ET-MIp_MAX_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                    z_score_plot_fn = os.path.join(protein_dir, 'ET-MIp_MAX_Scores_Dist-Any_{}_ZScores.png')\n",
    "                    z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - curr_etmip.coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                    biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                    protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                    plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                    z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - curr_etmip.coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                    unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                    protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                    plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                    # Record execution times\n",
    "                    protein_df['Init Time'] = init_time - start_time\n",
    "                    protein_df['Import Time'] = import_time - init_time\n",
    "                    protein_df['Dist Tree Time'] = dist_tree_time - import_time\n",
    "                    protein_df['Trace Time'] = end_time - dist_tree_time\n",
    "                    protein_df['Total Time'] = end_time - start_time\n",
    "                    # Record static data for this protein\n",
    "                    protein_df['Protein'] = p_id\n",
    "                    protein_df['Method'] = 'ET-MIp_MAX'\n",
    "                    protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                    protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                    temp_data = os.path.join(protein_dir, 'unique_node_data')\n",
    "                    for temp_fn in os.listdir(temp_data):\n",
    "                        if not temp_fn.endswith(\"_pair_rank_filtered_average_product_corrected_mutual_information_score.npz\"):\n",
    "                            os.remove(os.path.join(temp_data, temp_fn))\n",
    "                    print('Metrics meastured for ET-MIp MAX covariance for: {}'.format(p_id))\n",
    "                    counts['success'] += 1\n",
    "                except ValueError:\n",
    "                    print('Could not compute ET-MIp MAX covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "                        p_id, curr_etmip.original_aln.seq_length, curr_etmip.original_aln.size))\n",
    "                    counts['value'] += 1\n",
    "                    continue\n",
    "                except AttributeError:\n",
    "                    print('Could not compute ET-MIp MAX covariance for: {} no alignment'.format(p_id))\n",
    "                    counts['attribute'] += 1\n",
    "                    continue\n",
    "            if etmip_method_df is None:\n",
    "                etmip_method_df = protein_df\n",
    "            else:\n",
    "                etmip_method_df = etmip_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        etmip_method_df.to_csv(etmip_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = etmip_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(etmip_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCA##\n",
    "Scoring the the covariation of the proteins using a DCA julia implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DCAWrapper import DCAWrapper\n",
    "from utils import compute_rank_and_coverage\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    dca_out_dir = os.path.join(small_set_out_dir, 'DCA')\n",
    "    if not os.path.isdir(dca_out_dir):\n",
    "        os.makedirs(dca_out_dir)\n",
    "    dca_method_fn = os.path.join(dca_out_dir, 'DCA_Method_Data.csv')\n",
    "    if os.path.isfile(dca_method_fn):\n",
    "        dca_method_df = pd.read_csv(dca_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:\n",
    "        dca_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "        for p_id in generator.protein_data:\n",
    "            print('Attempting to calculate DCA covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(dca_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "            else:\n",
    "                try:\n",
    "                    curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id,\n",
    "                                            polymer_type='Protein')\n",
    "                    curr_aln.import_alignment()\n",
    "                    # Since the DCA implementation used here does not provide a way to specify the query sequence we remove the gaps\n",
    "                    # from the query sequences so positions will be referenced correctly for that sequence (and unnecessary\n",
    "                    # computations can be avoided).\n",
    "                    curr_aln = curr_aln.remove_gaps()\n",
    "                    new_aln_fn = os.path.join(protein_dir, '{}_no_gap.fasta'.format(p_id))\n",
    "                    curr_aln.write_out_alignment(new_aln_fn)\n",
    "                    curr_aln.file_name = new_aln_fn\n",
    "                    curr_dca = DCAWrapper(alignment=curr_aln)\n",
    "                    curr_dca.calculate_scores(out_dir=protein_dir, delete_file=False)\n",
    "                    # Compute statistics for the final scores of the ET-MIp model\n",
    "                    protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                        predictor=curr_dca, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                        unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=2, rank_type='max', file_prefix='DCA_Scores_', plots=True)\n",
    "                    # Score Prediction Clustering\n",
    "                    _, dca_coverage  = compute_rank_and_coverage(seq_length=curr_dca.alignment.seq_length, scores=curr_dca.scores, pos_size=2,\n",
    "                        rank_type='max')\n",
    "                    z_score_fn = os.path.join(protein_dir, 'DCA_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                    z_score_plot_fn = os.path.join(protein_dir, 'DCA_Scores_Dist-Any_{}_ZScores.png')\n",
    "                    z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - dca_coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                    biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                    protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                    plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                    z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - dca_coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                    unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                    protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                    plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                    # Record execution times\n",
    "                    protein_df['Init Time'] = None\n",
    "                    protein_df['Import Time'] = None\n",
    "                    protein_df['Dist Tree Time'] = None\n",
    "                    protein_df['Trace Time'] = None\n",
    "                    protein_df['Total Time'] = None\n",
    "                    # Record static data for this protein\n",
    "                    protein_df['Protein'] = p_id\n",
    "                    protein_df['Method'] = 'DCA'\n",
    "                    protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                    protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                    print('Successfully computed DCA covariance for: {}'.format(p_id))\n",
    "                    counts['success'] += 1\n",
    "                except ValueError:\n",
    "                    print('Could not compute DCA covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "                        p_id, curr_aln.seq_length, curr_aln.size))\n",
    "                    counts['value'] += 1\n",
    "                    continue\n",
    "                except AttributeError:\n",
    "                    print('Could not compute DCA covariance for: {} no alignment'.format(p_id))\n",
    "                    counts['attribute'] += 1\n",
    "                    continue\n",
    "            if dca_method_df is None:\n",
    "                dca_method_df = protein_df\n",
    "            else:\n",
    "                dca_method_df = dca_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        dca_method_df.to_csv(dca_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = dca_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(dca_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVCouplings##\n",
    "Scoring the the covariation of the proteins using the EVCouplings method standard protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/pandas/core/frame.py:7116: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "from EVCouplingsWrapper import EVCouplingsWrapper\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    evc_standard_out_dir = os.path.join(small_set_out_dir, 'EVCouplings_Standard')\n",
    "    if not os.path.isdir(evc_standard_out_dir):\n",
    "        os.makedirs(evc_standard_out_dir)\n",
    "    evc_standard_method_fn = os.path.join(evc_standard_out_dir, 'EVCouplings_Standard_Method_Data.csv')\n",
    "    if os.path.isfile(evc_standard_method_fn):\n",
    "        evc_standard_method_df = pd.read_csv(evc_standard_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:\n",
    "        evc_standard_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "        for p_id in generator.protein_data:\n",
    "            print('Attempting to calculate EV couplings standard protocol covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(evc_standard_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "            else:\n",
    "                try:\n",
    "                    curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id,\n",
    "                                            polymer_type='Protein')\n",
    "                    curr_aln.import_alignment()\n",
    "                    curr_evc = EVCouplingsWrapper(alignment=curr_aln, protocol='standard')\n",
    "                    curr_evc.calculate_scores(out_dir=protein_dir, cores=10, delete_files=True)\n",
    "                    # Compute statistics for the final scores of the ET-MIp model\n",
    "                    protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                        predictor=curr_evc, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                        unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=2,\n",
    "                        rank_type='max', file_prefix='EVC_Standard_Scores_', plots=True)\n",
    "                    # Score Prediction Clustering\n",
    "                    _, evc_standard_coverage  = compute_rank_and_coverage(seq_length=curr_evc.alignment.seq_length, scores=curr_evc.scores, pos_size=2,\n",
    "                        rank_type='max')\n",
    "                    z_score_fn = os.path.join(protein_dir, 'EVC_Standard_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                    z_score_plot_fn = os.path.join(protein_dir, 'EVC_Standard_Scores_Dist-Any_{}_ZScores.png')\n",
    "                    z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - evc_standard_coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                    biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                    protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                    plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                    z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - evc_standard_coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                    unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                    protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                    plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                    # Record execution times\n",
    "                    protein_df['Init Time'] = None\n",
    "                    protein_df['Import Time'] = None\n",
    "                    protein_df['Dist Tree Time'] = None\n",
    "                    protein_df['Trace Time'] = None\n",
    "                    protein_df['Total Time'] = None\n",
    "                    # Record static data for this protein\n",
    "                    protein_df['Protein'] = p_id\n",
    "                    protein_df['Method'] = 'EVC Standard'\n",
    "                    protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                    protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                    print('Successfully computed EV couplings standard protocol covariance for: {}'.format(p_id))\n",
    "                    counts['success'] += 1\n",
    "                except ValueError:\n",
    "                    print('Could not compute EV couplings standard protocol covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "                        p_id, curr_aln.seq_length, curr_aln.size))\n",
    "                    counts['value'] += 1\n",
    "                    continue\n",
    "                except AttributeError:\n",
    "                    print('Could not compute EV couplings standard protocol covariance for: {} no alignment'.format(p_id))\n",
    "                    counts['attribute'] += 1\n",
    "                    continue\n",
    "            if evc_standard_method_df is None:\n",
    "                evc_standard_method_df = protein_df\n",
    "            else:\n",
    "                evc_standard_method_df = evc_standard_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        evc_standard_method_df.to_csv(evc_standard_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = evc_standard_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(evc_standard_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring the covariation of the proteins using the EVCouplings method mean field protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(small_comparison_fn):\n",
    "    evc_mf_out_dir = os.path.join(small_set_out_dir, 'EVCouplings_Mean_Field')\n",
    "    if not os.path.isdir(evc_mf_out_dir):\n",
    "        os.makedirs(evc_mf_out_dir)\n",
    "    evc_mf_method_fn = os.path.join(evc_mf_out_dir, 'EVCouplings_Mean_Field_Method_Data.csv')\n",
    "    if os.path.isfile(evc_mf_method_fn):\n",
    "        evc_mf_method_df = pd.read_csv(evc_mf_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:\n",
    "        evc_mf_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "        for p_id in generator.protein_data:\n",
    "            print('Attempting to calculate EV couplings covariance for: {}'.format(p_id))\n",
    "            try:\n",
    "                protein_dir = os.path.join(evc_mf_out_dir, p_id)\n",
    "                if not os.path.isdir(protein_dir):\n",
    "                    os.makedirs(protein_dir)\n",
    "                curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id,\n",
    "                                        polymer_type='Protein')\n",
    "                curr_aln.import_alignment()\n",
    "                curr_evc = EVCouplingsWrapper(alignment=curr_aln, protocol='mean_field')\n",
    "                curr_evc.calculate_scores(out_dir=protein_dir, cores=10, delete_files=True)\n",
    "                # Compute statistics for the final scores of the ET-MIp model\n",
    "                protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                    predictor=curr_evc, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                    unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=2, rank_type='max',\n",
    "                    file_prefix='EVC_Standard_Scores_', plots=True)\n",
    "                # Score Prediction Clustering\n",
    "                _, evc_mf_coverage  = compute_rank_and_coverage(seq_length=curr_evc.alignment.seq_length, scores=curr_evc.scores, pos_size=2,\n",
    "                    rank_type='max')\n",
    "                z_score_fn = os.path.join(protein_dir, 'EVC_Mean_Field_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                z_score_plot_fn = os.path.join(protein_dir, 'EVC_Mean_Field_Scores_Dist-Any_{}_ZScores.png')\n",
    "                z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                    1.0 - evc_mf_coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                    w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                    1.0 - evc_mf_coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                    w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                # Record execution times\n",
    "                protein_df['Init Time'] = None\n",
    "                protein_df['Import Time'] = None\n",
    "                protein_df['Dist Tree Time'] = None\n",
    "                protein_df['Trace Time'] = None\n",
    "                protein_df['Total Time'] = None\n",
    "                # Record static data for this protein\n",
    "                protein_df['Protein'] = p_id\n",
    "                protein_df['Method'] = 'EVC Mean Field'\n",
    "                protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                print('Successfully computed EV couplings covariance for: {}'.format(p_id))\n",
    "                counts['success'] += 1\n",
    "            except ValueError:\n",
    "                print('Could not compute EV couplings covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "                    p_id, curr_aln.seq_length, curr_aln.size))\n",
    "                counts['value'] += 1\n",
    "                continue\n",
    "            except AttributeError:\n",
    "                print('Could not compute EV couplings covariance for: {} no alignment'.format(p_id))\n",
    "                counts['attribute'] += 1\n",
    "                continue\n",
    "            if evc_mf_method_df is None:\n",
    "                evc_mf_method_df = protein_df\n",
    "            else:\n",
    "                evc_mf_method_df = evc_mf_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        evc_mf_method_df.to_csv(evc_mf_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = evc_mf_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(evc_mf_method_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out final comparison data so it can be loaded later for generating figures.\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    small_comparison_df['Protein Length'] = small_comparison_df['Protein'].apply(lambda x: generator.protein_data[x]['Length'])\n",
    "    small_comparison_df.to_csv(small_comparison_fn, sep='\\t', header=True, index=False, columns=output_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Execution Time for ET-MIp and cET-MIp\n",
    "The time to compute the trace for the full phylogenetic tree and the trace constrained to a subset of the top levels should take significantly less time to compute, here we evaluate if that is in fact the case or not.\n",
    "\n",
    "## Data Cleaning\n",
    "At least one protein in this data set has a very small alignment and could not be evaluated by cET-MIp because the tree was too small to each the levels set for other proteins. Here we remove those proteins.\n",
    "\n",
    "In addition since this analysis focuses on times and there are many other types of data (some of which cause redundancies in the time data), we will use this opportunity to subset the data and drop duplicates.\n",
    "\n",
    "Finally, for some it will be more informative to view execution time in terms of minutes or hours, as opposed to the originally reported seconds, so we will add columns for these units as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_method_groups = small_comparison_df[['Protein', 'Method']].drop_duplicates().groupby('Protein').count()\n",
    "method_max = protein_method_groups['Method'].max()\n",
    "proteins_to_keep = protein_method_groups.index[protein_method_groups['Method'] == method_max]\n",
    "comparable_method_proteins = small_comparison_df[small_comparison_df['Protein'].isin(proteins_to_keep)]\n",
    "time_columns = ['Protein', 'Protein Length', 'Alignment Size', 'Method', 'Init Time', 'Import Time', 'Dist Tree Time',\n",
    "                'Trace Time', 'Total Time']\n",
    "time_subset_df = comparable_method_proteins.loc[comparable_method_proteins['Method'].isin(['ET-MIp', 'cET-MIp']), time_columns]\n",
    "time_subset_df['Total Time (min)'] = time_subset_df['Total Time'].apply(lambda x: x / 60.0)\n",
    "time_subset_df['Total Time (hr)'] = time_subset_df['Total Time (min)'].apply(lambda x: x / 60.0)\n",
    "time_columns += ['Total Time (min)', 'Total Time (hr)']\n",
    "time_subset_df = time_subset_df.drop_duplicates(subset=None, inplace=False, keep='first')\n",
    "time_subset_df.to_csv(os.path.join(small_set_out_dir, 'Small_Time_Comaprison_Data.csv'), sep='\\t', header=True, index=False,\n",
    "                      columns=time_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Comparison\n",
    "Now that only comparable proteins are present in the data we compare the runtime of individual proteins by method, ordered by their length and the size of their alignemnts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Displayed by protein length order\n",
    "protein_length_order = comparable_method_proteins.sort_values('Protein Length')['Protein'].unique()\n",
    "protein_length_time_plot = sns.barplot(x='Protein', y='Total Time', hue='Method', order=protein_length_order,\n",
    "                                       hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_length_time_plot.set_xticklabels(protein_length_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_length_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Length_Time_Comparison_Sec.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "protein_length_time_plot = sns.barplot(x='Protein', y='Total Time (min)', hue='Method', order=protein_length_order,\n",
    "                                       hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_length_time_plot.set_xticklabels(protein_length_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_length_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Length_Time_Comparison_Min.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "protein_length_time_plot = sns.barplot(x='Protein', y='Total Time (hr)', hue='Method', order=protein_length_order,\n",
    "                                       hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_length_time_plot.set_xticklabels(protein_length_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_length_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Length_Time_Comparison_Hr.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Displayed by alignment size order\n",
    "protein_alignment_order = comparable_method_proteins.sort_values('Alignment Size')['Protein'].unique()\n",
    "protein_alignment_time_plot = sns.barplot(x='Protein', y='Total Time', hue='Method', order=protein_alignment_order,\n",
    "                                          hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_alignment_time_plot.set_xticklabels(protein_alignment_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_alignment_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Alignment_Time_Comparison_Sec.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "protein_alignment_time_plot = sns.barplot(x='Protein', y='Total Time (min)', hue='Method', order=protein_alignment_order,\n",
    "                                          hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_alignment_time_plot.set_xticklabels(protein_alignment_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_alignment_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Alignment_Time_Comparison_Min.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "protein_alignment_time_plot = sns.barplot(x='Protein', y='Total Time (hr)', hue='Method', order=protein_alignment_order,\n",
    "                                          hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_alignment_time_plot.set_xticklabels(protein_alignment_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_alignment_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Alignment_Time_Comparison_Hr.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall comparison of time by method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of ET-MIp and cET-MIp total computation time (sec).\n",
    "protein_method_comp_plot = sns.boxplot(x='Method', y='Total Time', order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_method_comp_plot.set_xticklabels(protein_method_comp_plot.get_xticklabels(), rotation=90)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_Time_Comparison_Sec.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Comparison of ET-MIp and cET-MIp total computation time (sec).\n",
    "protein_method_comp_plot = sns.boxplot(x='Method', y='Total Time (min)', order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_method_comp_plot.set_xticklabels(protein_method_comp_plot.get_xticklabels(), rotation=90)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_Time_Comparison_Min.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Comparison of ET-MIp and cET-MIp total computation time (sec).\n",
    "protein_method_comp_plot = sns.boxplot(x='Method', y='Total Time (hr)', order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_method_comp_plot.set_xticklabels(protein_method_comp_plot.get_xticklabels(), rotation=90)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_Time_Comparison_Hr.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Statistical comparison\n",
    "from scipy.stats import wilcoxon\n",
    "et_mip_sub_df = time_subset_df[time_subset_df['Method'] == 'ET-MIp']\n",
    "cet_mip_sub_df = time_subset_df[time_subset_df['Method'] == 'cET-MIp']\n",
    "sec_stat, sec_p_val = wilcoxon(x=et_mip_sub_df['Total Time'], y=cet_mip_sub_df['Total Time'], zero_method='wilcox')\n",
    "min_stat, min_p_val = wilcoxon(x=et_mip_sub_df['Total Time (min)'], y=cet_mip_sub_df['Total Time (min)'], zero_method='wilcox')\n",
    "hr_stat, hr_p_val = wilcoxon(x=et_mip_sub_df['Total Time (hr)'], y=cet_mip_sub_df['Total Time (hr)'], zero_method='wilcox')\n",
    "time_statistics = {'Time Unit': ['sec', 'min', 'hr'], 'Statistic': [sec_stat, min_stat, hr_stat], 'P-Value': [sec_p_val, min_p_val, hr_p_val]}\n",
    "pd.DataFrame(time_statistics).to_csv(os.path.join(small_set_out_dir, 'Small_Time_Comaprison_Statistics.csv'), sep='\\t', header=True,\n",
    "                                     index=False, columns=['Time Unit', 'Statistic', 'P-Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method Comparison\n",
    "We now begin comparing methods based on their ability to predict the structural contacts in the proteins in this test set. There is an important consideration in the case of sequence separation and different measures by which to compare the methods.\n",
    "\n",
    "### Data Cleaning\n",
    "These data need an additional cleaning step beyond what was performed for the timing comparison. Since there are multiple categories of sequence separation and some proteins may not have any True Positive contacts for a category the scoring for that protein is incomplete. We will remove all such proteins from the comparison, performing the clean up separate for each metric of success. Another contributing factor which necessitates this kind of cleaning is assessment of the top K predictions for a protein or best L/K predictions which for poor predictions may not include any predictions of True Positives.\n",
    "\n",
    "### Sequence Separation\n",
    "One important consideration for the difficulty of prediction and interest in predictions is the distance between the residues for which coupling was predicted. As has been documented in the literature, especially in the CASP competitions, there are several categories of prediction:\n",
    "* Neighbors (1 - 5 residues apart) - This is the least interesting category of predictions. It is highly likely that residues this close together will show covariance signal. Predicting two residues are in contact that are this close together is trivial and uninformative.\n",
    "* Short (6 - 12 residues apart) - This is also not a very interesting type of prediction. Residues this close in proximity can be more easily modeled by alogrithms which focus on 2D protein structure modeling (identifying beta sheets, alpha helices, etc.).\n",
    "* Medium (13 - 24 residues apart) - This is a more interesting type of prediction. The resiudes in this range of separation are on the edge of the 2D protein structure prediction range.\n",
    "* Long (24 and more residues apart) - The most interesting category of predictions. Resiudes this far apart are not easily modeled by 2D protein structure modeling systems. They are also very useful for 3D and 4D protein structure prediction becausae they provide constraints on potential protein (similar to NMR data) folds which makes protein folding a more tractable problem for modelers.\n",
    "* Any/All - All categories can be considered at once, this provides a summary value, but is often skewed by one particularly good category of predictions.\n",
    "\n",
    "### Metrics of Success\n",
    "* AUROC - This measures the True Positive Rate vs the False Positive Rate of prediction, it can be considered a measure of the accuracy of the measure. This can be strongly influenced by the class imbalance which is present when predicting structural contacts since there are many fewer contacts than non-contacts. The True Positive case is if the C-beta of two amino acids is within 8.0 Angstroms of one another (as is done in the CASP competitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_columns = ['Protein', 'Method', 'Sequence_Separation', 'AUROC']\n",
    "protein_auroc_groups = comparable_method_proteins[auroc_columns].drop_duplicates().groupby('Protein')['AUROC'].apply(\n",
    "    lambda x: not x.isnull().any())\n",
    "complete_proteins = protein_auroc_groups.index[protein_auroc_groups.values]\n",
    "comparable_auroc_proteins = small_comparison_df[small_comparison_df['Protein'].isin(complete_proteins)]\n",
    "auroc_protein_length_order = [x for x in protein_length_order if x in complete_proteins]\n",
    "auroc_protein_alignment_order = [x for x in protein_alignment_order if x in complete_proteins]\n",
    "auroc_subset_df = comparable_auroc_proteins.loc[:, auroc_columns].drop_duplicates()\n",
    "# Plot the methods vs AUROC per protein ordered by protein length\n",
    "auroc_subset_df.to_csv(os.path.join(small_set_out_dir, 'Small_AUROC_Comaprison_Data.csv'), sep='\\t', header=True, index=False,\n",
    "                       columns=auroc_columns)\n",
    "protein_order_auroc_plot = sns.catplot(x=\"Protein\", y=\"AUROC\", hue=\"Method\", row=\"Sequence_Separation\", data=auroc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auroc_protein_length_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "protein_order_auroc_plot.set_xticklabels(auroc_protein_length_order, rotation=90)\n",
    "protein_order_auroc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUROC_Comparison_Protein_Length_Order.png'),\n",
    "                                 bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUROC per protein ordered by protein alignment size\n",
    "alignment_order_auroc_plot = sns.catplot(x=\"Protein\", y=\"AUROC\", hue=\"Method\", row=\"Sequence_Separation\", data=auroc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auroc_protein_alignment_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "alignment_order_auroc_plot.set_xticklabels(auroc_protein_alignment_order, rotation=90)\n",
    "alignment_order_auroc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUROC_Comparison_Alignment_Size_Order.png'),\n",
    "                                   bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUROC grouped together to see overall trends\n",
    "overall_auroc_plot = sns.boxplot(x=\"Sequence_Separation\", y=\"AUROC\", hue=\"Method\", data=auroc_subset_df,\n",
    "                                 order=sequence_separation_order, hue_order=method_order)\n",
    "overall_auroc_plot.set_xticklabels(sequence_separation_order, rotation=90)\n",
    "overall_auroc_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUROC_Comparison.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Compute statistics comparing methods at each sequence separation\n",
    "auroc_statistics = {'Sequence Separation': [], 'Method 1': [], 'Method 2': [], 'Statistic': [], 'P-Value': []}\n",
    "for sep in sequence_separation_order:\n",
    "    sep_auroc_subset_df = auroc_subset_df.loc[auroc_subset_df['Sequence_Separation'] == sep, :]\n",
    "    for i in range(len(method_order)):\n",
    "        m1_sep_auroc_subset_df = sep_auroc_subset_df.loc[sep_auroc_subset_df['Method'] == method_order[i], :]\n",
    "        for j in range(i + 1, len(method_order)):\n",
    "            m2_sep_auroc_subset_df = sep_auroc_subset_df.loc[sep_auroc_subset_df['Method'] == method_order[j], :]\n",
    "            stat, p_val = wilcoxon(x=m1_sep_auroc_subset_df['AUROC'], y=m2_sep_auroc_subset_df['AUROC'], zero_method='wilcox')\n",
    "            auroc_statistics['Sequence Separation'].append(sep)\n",
    "            auroc_statistics['Method 1'].append(method_order[i])\n",
    "            auroc_statistics['Method 2'].append(method_order[j])\n",
    "            auroc_statistics['Statistic'].append(stat)\n",
    "            auroc_statistics['P-Value'].append(p_val)\n",
    "pd.DataFrame(auroc_statistics).to_csv(os.path.join(small_set_out_dir, 'Small_AUROC_Comaprison_Statistics.csv'), sep='\\t', header=True,\n",
    "                                      index=False, columns=['Sequence Separation', 'Method 1', 'Method 2', 'Statistic', 'P-Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics of Success (Continued)\n",
    "* AUPRC - This measures the Precision vs the Recall of the predictions, it can be considered a measure of the accuracy of the measure. This is less strongly influenced by the class imbalance which is present when predicting structural contacts since there are many fewer contacts than non-contacts. The True Positive case is if the C-beta of two amino acids is within 8.0 Angstroms of one another (as is done in the CASP competitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "auprc_columns = ['Protein', 'Method', 'Sequence_Separation', 'AUPRC']\n",
    "protein_auprc_groups = comparable_method_proteins[auprc_columns].drop_duplicates().groupby('Protein')['AUPRC'].apply(\n",
    "    lambda x: not x.isnull().any())\n",
    "complete_proteins = protein_auprc_groups.index[protein_auprc_groups.values]\n",
    "comparable_auprc_proteins = small_comparison_df[small_comparison_df['Protein'].isin(complete_proteins)]\n",
    "auprc_protein_length_order = [x for x in protein_length_order if x in complete_proteins]\n",
    "auprc_protein_alignment_order = [x for x in protein_alignment_order if x in complete_proteins]\n",
    "auprc_subset_df = comparable_auprc_proteins.loc[:, auprc_columns].drop_duplicates()\n",
    "# Plot the methods vs AUPRC per protein ordered by protein length\n",
    "auprc_subset_df.to_csv(os.path.join(small_set_out_dir, 'Small_AUPRC_Comaprison_Data.csv'), sep='\\t', header=True, index=False,\n",
    "                       columns=auprc_columns)\n",
    "protein_order_auprc_plot = sns.catplot(x=\"Protein\", y=\"AUPRC\", hue=\"Method\", row=\"Sequence_Separation\", data=auprc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auprc_protein_length_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "protein_order_auprc_plot.set_xticklabels(auprc_protein_length_order, rotation=90)\n",
    "protein_order_auprc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUPRC_Comparison_Protein_Length_Order.png'),\n",
    "                                 bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUPRC per protein ordered by protein alignment size\n",
    "alignment_order_auprc_plot = sns.catplot(x=\"Protein\", y=\"AUPRC\", hue=\"Method\", row=\"Sequence_Separation\", data=auprc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auprc_protein_alignment_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "alignment_order_auprc_plot.set_xticklabels(auprc_protein_alignment_order, rotation=90)\n",
    "alignment_order_auprc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUPRC_Comparison_Alignment_Size_Order.png'),\n",
    "                                   bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUPRC grouped together to see overall trends\n",
    "overall_auprc_plot = sns.boxplot(x=\"Sequence_Separation\", y=\"AUPRC\", hue=\"Method\", data=auprc_subset_df,\n",
    "                                 order=sequence_separation_order, hue_order=method_order)\n",
    "overall_auprc_plot.set_xticklabels(sequence_separation_order, rotation=90)\n",
    "overall_auprc_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUPRC_Comparison.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Compute statistics comparing methods at each sequence separation\n",
    "auprc_statistics = {'Sequence Separation': [], 'Method 1': [], 'Method 2': [], 'Statistic': [], 'P-Value': []}\n",
    "for sep in sequence_separation_order:\n",
    "    sep_auprc_subset_df = auprc_subset_df.loc[auprc_subset_df['Sequence_Separation'] == sep, :]\n",
    "    for i in range(len(method_order)):\n",
    "        m1_sep_auprc_subset_df = sep_auprc_subset_df.loc[sep_auprc_subset_df['Method'] == method_order[i], :]\n",
    "        for j in range(i + 1, len(method_order)):\n",
    "            m2_sep_auprc_subset_df = sep_auprc_subset_df.loc[sep_auprc_subset_df['Method'] == method_order[j], :]\n",
    "            stat, p_val = wilcoxon(x=m1_sep_auprc_subset_df['AUPRC'], y=m2_sep_auprc_subset_df['AUPRC'], zero_method='wilcox')\n",
    "            auprc_statistics['Sequence Separation'].append(sep)\n",
    "            auprc_statistics['Method 1'].append(method_order[i])\n",
    "            auprc_statistics['Method 2'].append(method_order[j])\n",
    "            auprc_statistics['Statistic'].append(stat)\n",
    "            auprc_statistics['P-Value'].append(p_val)\n",
    "pd.DataFrame(auprc_statistics).to_csv(os.path.join(small_set_out_dir, 'Small_AUPRC_Comaprison_Statistics.csv'), sep='\\t', header=True,\n",
    "                                      index=False, columns=['Sequence Separation', 'Method 1', 'Method 2', 'Statistic', 'P-Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Precision at K - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Recall at K - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* F1 at K - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Structural Cluster Weighting Z-Score - "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (PyET3)",
   "language": "python",
   "name": "pyet3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
