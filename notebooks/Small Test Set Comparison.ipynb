{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Test Set #\n",
    "## Goal ##\n",
    "The goal of this test set is to perform proof of concept testing on a small number of proteins with a wide range of sizes and available homologs, orthologs, and paralogs. By doing so it should be possible to test the best parameterization for this tool as well as identifying the strengths and weaknesses of the tool using various measurments as end points.\n",
    "## Warning ##\n",
    "Before attempting to use this notebook make sure that your .env file has been properly setup to reflect the correct locations of command line tools and the location of files and directories needed for execution.\n",
    "### Initial Import###\n",
    "This first cell performs the necessary imports required to begin this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "try:\n",
    "    dotenv_path = find_dotenv(raise_error_if_not_found=True)\n",
    "except IOError:\n",
    "    dotenv_path = find_dotenv(raise_error_if_not_found=True, usecwd=True)\n",
    "load_dotenv(dotenv_path)\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ.get('PROJECT_PATH'), 'src'))\n",
    "sys.path.append(os.path.join(os.environ.get('PROJECT_PATH'), 'src', 'SupportingClasses'))\n",
    "input_dir = os.environ.get('INPUT_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set Construction ##\n",
    "The first task required to test the data set is to download the required data and construct any necessary input files for all down stream analyses.\n",
    "In this case that means:\n",
    "* Downloading PDB files for the proteins in our small test set.\n",
    "* Extracting a query sequence from each PDB file.\n",
    "* Searching for paralogs, homologs, and orthologs in a custom BLAST database built by filtering the Uniref90 database.\n",
    "* Filtering the hits from the BLAST search to meet minimum and maximum length requirements, as well as minimum and maximum identity requirements.\n",
    "* Building alignments using CLUSTALW in both the fasta and msf formats since some of the tools which will be used for comparison need different formats.\n",
    "* Filtering the alignment for maximum identity similarity between seqeunces.\n",
    "* Re-aligning the filtered sequences using CLUSTALW.\n",
    "This is all handeled by the DataSetGenerator class found in the src/SupportingClasses folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing protein list\n",
      "Downloading structures and parsing in query sequences\n",
      "Unique Sequences Found: 23!\n",
      "BLASTing query sequences\n",
      "Filtering BLAST hits, aligning, filtering by identity, and re-aligning\n",
      "   Protein_ID Chain Accession  BLAST_Hits  Filtered_BLAST  Filtered_Alignment  \\\n",
      "20       2rh1     A      None        2500              35                  35   \n",
      "7        1c0k     A      None        2500              54                  54   \n",
      "12       7hvp     A      None         128              60                  59   \n",
      "10       2b59     B      None         327              79                  73   \n",
      "3        206l     A      None        1193             102                  93   \n",
      "11       1bol     A      None        2500             158                 154   \n",
      "17       1jwl     A      None        2500             234                 231   \n",
      "0        3q05     A      None         939             468                 316   \n",
      "21       2z0e     A      None        2106             393                 351   \n",
      "6        4lli     A      None        2500             715                 435   \n",
      "8        2ysd     A      None        2500            1772                 624   \n",
      "15       1h1v     G      None        2500             815                 676   \n",
      "18       2zxe     A      None        2500             894                 798   \n",
      "9        1c17     A      None        1671             850                 813   \n",
      "1        1a26     A      None        2500            1143                 902   \n",
      "14       135l     A      None        1911             998                 946   \n",
      "5        3b6v     A      None        2500            2184                1358   \n",
      "19       1hck     A      None        2500            2470                1657   \n",
      "16       3tnu     A      None        2500            2488                1835   \n",
      "2        2wer     A      None        2500            2445                1957   \n",
      "13       1axb     A      None        2500            2153                2140   \n",
      "4        4ycu     A      None        2500            2458                2356   \n",
      "22       2iop     A      None        2500            2479                2473   \n",
      "\n",
      "    Length  Total_Size  \n",
      "20     442     15470.0  \n",
      "7      363     19602.0  \n",
      "12      97      5723.0  \n",
      "10     156     11388.0  \n",
      "3      162     15066.0  \n",
      "11     222     34188.0  \n",
      "17     329     75999.0  \n",
      "0      234     73944.0  \n",
      "21     315    110565.0  \n",
      "6      377    163995.0  \n",
      "8       57     35568.0  \n",
      "15     327    221052.0  \n",
      "18     992    791616.0  \n",
      "9       79     64227.0  \n",
      "1      351    316602.0  \n",
      "14     129    122034.0  \n",
      "5      306    415548.0  \n",
      "19     294    487158.0  \n",
      "16      90    165150.0  \n",
      "2      214    418798.0  \n",
      "13     263    562820.0  \n",
      "4      505   1189780.0  \n",
      "22     618   1528314.0  \n",
      "It took 0.11632449626922607 min to generate the data set.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from DataSetGenerator import DataSetGenerator\n",
    "protein_list_dir = os.path.join(input_dir, 'ProteinLists')\n",
    "if not os.path.isdir(protein_list_dir):\n",
    "    os.makedirs(protein_list_dir)\n",
    "small_list_fn = os.path.join(protein_list_dir, 'SmallDataSet.txt')\n",
    "if not os.path.isfile(small_list_fn):\n",
    "    proteins_of_interest = ['2ysdA', '1c17A', '3tnuA', '7hvpA', '135lA', '206lA', '2werA', '1bolA', '3q05A', '1axbA',\n",
    "                            '2rh1A', '1hckA', '3b6vA', '2z0eA', '1jwlA', '1a26A', '1c0kA', '4lliA', '4ycuA', '2iopA',\n",
    "                            '2zxeA', '2b59B', '1h1vG']\n",
    "    with open(small_list_fn, 'w') as small_list_handle:\n",
    "        for p_id in proteins_of_interest:\n",
    "            small_list_handle.write('{}\\n'.format(p_id))\n",
    "generator = DataSetGenerator(input_dir)\n",
    "start = time()\n",
    "summary = generator.build_pdb_alignment_dataset(protein_list_fn=os.path.basename(small_list_fn), processes=10,\n",
    "                                                database='customuniref90.fasta', max_target_seqs=2500, remote=False,\n",
    "                                                sources=['PDB'], verbose=False)\n",
    "summary['Chain'] = summary['Protein_ID'].apply(lambda x: generator.protein_data[x]['Chain'])\n",
    "summary['Accession'] = summary['Protein_ID'].apply(lambda x: generator.protein_data[x]['Accession'])\n",
    "summary['Length'] = summary['Protein_ID'].apply(lambda x: generator.protein_data[x]['Length'])\n",
    "summary['Total_Size'] = summary.apply(lambda x: float(x['Length']) * float(x['Filtered_Alignment']), axis=1)\n",
    "summary.sort_values(by=['Filtered_Alignment', 'Length'], axis=0, inplace=True)\n",
    "summary_columns = ['Protein_ID', 'Chain', 'Accession', 'BLAST_Hits', 'Filtered_BLAST',\n",
    "                   'Filtered_Alignment', 'Length', 'Total_Size']\n",
    "print(summary[summary_columns])\n",
    "end = time()\n",
    "print('It took {} min to generate the data set.'.format((end - start) / 60.0))\n",
    "summary.to_csv(os.path.join(input_dir, 'small_data_set_summary.tsv'), sep='\\t', index=False, header=True,\n",
    "               columns=summary_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a location to store the output of this method comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.environ.get('OUTPUT_PATH')\n",
    "small_set_out_dir = os.path.join(output_dir, 'SmallTestSet')\n",
    "if not os.path.isdir(small_set_out_dir):\n",
    "    os.makedirs(small_set_out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Scoring For Each Method\n",
    "To reduce memory load during prediction and evaluation, the scoring objects needed to compute the metrics used to compare methods will be created ahead of time so they are available to each method when it computes its predictions for a given protein. This will ensure that results do not need to be kept in memory while waiting for all other results to be computed, only the metrics measured for each method will be recorded.\n",
    "\n",
    "# Generating Values For Comparision#\n",
    "To determine the effectiveness of the new method and implementation the covariation of the same proteins will be computed using the previous Evolutionary Trace covariation method (ET-MIp) and other methods in the field.\n",
    "\n",
    "## ET-MIp##\n",
    "Scoring the the covariation of the proteins using the previous Evolutionary Trace covariation method (ET-MIp).\n",
    "\n",
    "## ET-MIp (Continued)\n",
    "The previous implementation is not able to run for alignments of the size used here. Instead we use the new implementation with the same parameterization used by the previous implementation (Distance Model - blosum62 similarity, Tree - ET UPGMA variant, Scoring Metric - filtered average product corrected mutual information, Ranks - all).\n",
    "\n",
    "## cET-MIp\n",
    "This segment the ET-MIp method, when constrained to an arbitrary set of nodes (1, 2, 3, 5, 7, 10, 25) at the top of the phylogenetic tree.\n",
    "\n",
    "## ET-MIp with Group Maximiziation ##\n",
    "This cell generates data for and tests the effect of maximizing the group score when moving from a parent node to child nodes.\n",
    "\n",
    "## DCA##\n",
    "Scoring the the covariation of the proteins using a DCA julia implementation.\n",
    "\n",
    "## EVCouplings##\n",
    "Scoring the the covariation of the proteins using the EVCouplings method standard protocol.\n",
    "\n",
    "Scoring the covariation of the proteins using the EVCouplings method mean field protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.08315808375676473 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11066.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 11103.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11145.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.004109783967336019 min\n",
      "Removing gaps took 0.08719699382781983 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11066.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 11103.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11145.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.003514440854390462 min\n",
      "Mapping query sequence and pdb took 0.09292073249816894 min\n",
      "Constructing internal representation took 0.014908262093861898 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.26224231719970703 min\n",
      "Removing gaps took 0.08462390502293905 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11066.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 11103.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11145.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.0035752773284912108 min\n",
      "Mapping query sequence and pdb took 0.08997145493825277 min\n",
      "Constructing internal representation took 0.014203826586405436 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.27409444252649945 min\n",
      "Attempting to calculate DCA covariance for: 2zxe\n",
      "Attempting to calculate EVC Standard covariance for: 2zxe\n",
      "Attempting to calculate ET-MIp covariance for: 2zxe\n",
      "Attempting to calculate cET-MIp covariance for: 2zxe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?characterizations/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.08548869291941324 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:53<00:00,  3.03s/characterizations]\n",
      "100%|██████████| 32/32 [00:03<00:00, 10.58group/s]\n",
      "100%|██████████| 7/7 [00:00<00:00,  5.28rank/s]\n",
      "100%|█████████▉| 491095/491536 [05:33<00:00, 1547.55variation/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to file in 5.689047300815583 min\n",
      "519.9398577213287\n",
      "Successfully computed cET-MIp covariance for: 2zxe\n",
      "Constructing internal representation took 0.01453322172164917 min\n",
      "Computing the distance matrix based on the PDB file took 0.2640402634938558 min\n",
      "Compute SCW Z-Score took 2.4320512771606446 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/pandas/core/indexing.py:1404: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/pandas/core/frame.py:7116: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics meastured for cET-MIp covariance for: 2zxe\n",
      "Attempting to calculate ET-MMEA covariance for: 2zxe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/798 [00:00<?, ?sequences/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.08862967491149902 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 798/798 [00:01<00:00, 631.35sequences/s]\n",
      "100%|██████████| 318003/318003 [04:34<00:00, 1159.66distances/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing tree took: 0.1188251535097758 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1595 [00:00<?, ?characterizations/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 69.16111445426941 seconds to identify matches and mismatches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 1414/1595 [5:24:21<8:31:35, 169.59s/characterizations]  "
     ]
    }
   ],
   "source": [
    "# Import the necessary packages to calculate and evaluate covariation predictions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from SeqAlignment import SeqAlignment\n",
    "from PDBReference import PDBReference\n",
    "from utils import compute_rank_and_coverage\n",
    "from ContactScorer import ContactScorer, plot_z_scores\n",
    "from DCAWrapper import DCAWrapper\n",
    "from EvolutionaryTrace import EvolutionaryTrace\n",
    "from EVCouplingsWrapper import EVCouplingsWrapper\n",
    "# Define the order of proteins, method, and separations for experiments and plotting\n",
    "protein_order = list(summary['Protein_ID'])\n",
    "method_order = ['DCA', 'EVC Standard', 'EVC Mean Field', 'ET-MIp', 'cET-MIp', 'ET-MMEA']\n",
    "sequence_separation_order = ['Any', 'Neighbors', 'Short', 'Medium', 'Long']\n",
    "# Define the predictor, settings, and rank type for each method to be tested\n",
    "general_et_settings = {'polymer_type': 'Protein', 'et_distance': True, 'distance_model': 'blosum62', 'tree_building_method': 'et',\n",
    "                 'tree_building_options': {}, 'position_type': 'pair', 'gap_correction': None,\n",
    "                 'output_files': {'original_aln', 'non_gap_aln', 'tree', 'scores'}, 'processors': 10, 'low_memory': True}\n",
    "method_dict = {'DCA': {'Predictor': DCAWrapper, 'Settings': {}, 'RankType':'max', 'Scoring Params': {}},\n",
    "               'EVC Standard': {'Predictor': EVCouplingsWrapper, 'Settings': {'protocol': 'standard'}, 'RankType':'max', 'Scoring Params': {'cores': 10}},\n",
    "               'EVC Mean Field': {'Predictor': EVCouplingsWrapper, 'Settings': {'protocol': 'mean_field'}, 'Scoring Params': {'cores': 10}},\n",
    "               'ET-MIp': {'Predictor': EvolutionaryTrace, 'RankType':'max', 'Scoring Params': {},\n",
    "                          'Settings': {'ranks': None, 'scoring_metric': 'filtered_average_product_corrected_mutual_information'}},\n",
    "               'cET-MIp': {'Predictor': EvolutionaryTrace, 'RankType':'max', 'Scoring Params': {},\n",
    "                           'Settings': {'ranks': [1, 2, 3, 5, 7, 10, 25], 'scoring_metric': 'filtered_average_product_corrected_mutual_information'}},\n",
    "               'ET-MMEA': {'Predictor': EvolutionaryTrace, 'RankType':'max', 'Scoring Params': {},\n",
    "                           'Settings': {'ranks': None, 'scoring_metric': 'match_mismatch_entropy_angle'}}}\n",
    "method_dict['ET-MIp']['Settings'].update(general_et_settings)\n",
    "method_dict['cET-MIp']['Settings'].update(general_et_settings)\n",
    "method_dict['ET-MMEA']['Settings'].update(general_et_settings)\n",
    "# Define the overall dataframe for evaluations, including its path and columns\n",
    "small_comparison_df = None\n",
    "small_comparison_fn = os.path.join(small_set_out_dir, 'Small_Comparision_Data.csv')\n",
    "output_columns = ['Protein', 'Protein Length', 'Alignment Size', 'Method', 'Distance', 'Total Time', \n",
    "                  'Sequence_Separation', 'AUROC', 'AUPRC',\n",
    "                  'Top K Predictions', 'Precision', 'Recall', 'F1 Score',\n",
    "                  'Biased Z-Score at 10%', 'Biased Z-Score at 30%', 'Max Biased Z-Score', 'AUC Biased Z-Score',\n",
    "                  'Unbiased Z-Score at 10%', 'Biased Z-Score at 30%', 'Max Unbiased Z-Score', 'AUC Unbiased Z-Score']\n",
    "if os.path.isfile(small_comparison_fn):\n",
    "    # If the full evaluation has already been completed load it\n",
    "    small_comparison_df = pd.read_csv(small_comparison_fn, sep='\\t', header=0, index_col=False)\n",
    "else:\n",
    "    # If not perform experiments for each protein\n",
    "    for p_id in summary['Protein_ID']:\n",
    "        # Define the protein result directory and dataframe path\n",
    "        protein_dir = os.path.join(small_set_out_dir, p_id)\n",
    "        if not os.path.isdir(protein_dir):\n",
    "            os.makedirs(protein_dir)\n",
    "        protein_df_fn =  os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "        if os.path.isfile(protein_df_fn):\n",
    "            # If this protein has already been evalauted load the evaluation\n",
    "            protein_df = pd.read_csv(protein_df_fn, sep='\\t', header=0, index_col=False)\n",
    "        else:\n",
    "            # Initialize the variable for the dataframe\n",
    "            protein_df = None\n",
    "            # Import alignment and remove gaps\n",
    "            full_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id)\n",
    "            full_aln.import_alignment()\n",
    "            non_gap_aln = full_aln.remove_gaps()\n",
    "            # Import structure\n",
    "            pdb_structure = PDBReference(pdb_file=generator.protein_data[p_id]['PDB'])\n",
    "            pdb_structure.import_pdb(structure_id=p_id)\n",
    "            # Initialize Beta Carbon distance scorer\n",
    "            contact_scorer_cb = ContactScorer(query=p_id, seq_alignment=non_gap_aln,\n",
    "                                              pdb_reference=pdb_structure, cutoff=8.0)\n",
    "            contact_scorer_cb.best_chain = generator.protein_data[p_id]['Chain']\n",
    "            contact_scorer_cb.fit()\n",
    "            contact_scorer_cb.measure_distance(method='CB')\n",
    "            # Initialize distance scorer minimizing distance between any atoms\n",
    "            contact_scorer_any = ContactScorer(query=p_id, seq_alignment=non_gap_aln,\n",
    "                                               pdb_reference=pdb_structure, cutoff=8.0)\n",
    "            contact_scorer_any.best_chain = generator.protein_data[p_id]['Chain']\n",
    "            contact_scorer_any.fit()\n",
    "            contact_scorer_any.measure_distance(method='Any')\n",
    "            # Initialize z-scoring subproblems\n",
    "            biased_w2_ave = None\n",
    "            unbiased_w2_ave = None\n",
    "            # Identify settings for this protein\n",
    "            protein_settings = {'query': p_id, 'aln_file': generator.protein_data[p_id]['Final_FA_Aln']}\n",
    "            # Then perform experiments for each method\n",
    "            for method in method_order:\n",
    "                if p_id == '2zxe' and method == 'EVC Mean Field':\n",
    "                    continue\n",
    "                # Set the result directory for this method\n",
    "                method_dir = os.path.join(protein_dir, method)\n",
    "                if not os.path.isdir(method_dir):\n",
    "                    os.makedirs(method_dir)\n",
    "                print('Attempting to calculate {} covariance for: {}'.format(method, p_id))\n",
    "                # Define the path for the evaluation data for this experiment\n",
    "                curr_fn = os.path.join(method_dir, '{}_{}_Method_Data.csv'.format(p_id, method))\n",
    "                if os.path.isfile(curr_fn):\n",
    "                    # If it has already been performed, load the data\n",
    "                    curr_df = pd.read_csv(curr_fn, sep='\\t', header=0, index_col=False)\n",
    "                else:\n",
    "                    # Otherwise perform the experiment, beginning with compiling the compelte settings for this predictor\n",
    "                    curr_settings = {'out_dir': method_dir}\n",
    "                    curr_settings.update(protein_settings)\n",
    "                    curr_settings.update(method_dict[method]['Settings'])\n",
    "                    predictor = method_dict[method]['Predictor'](**curr_settings)\n",
    "                    total_time = predictor.calculate_scores(method_dict[method]['Scoring Params'])\n",
    "                    print('Successfully computed {} covariance for: {}'.format(method, p_id))\n",
    "                    # Compute statistics for the final scores of the ET-MIp model\n",
    "                    curr_df, _, _ = contact_scorer_cb.evaluate_predictor(\n",
    "                        predictor=predictor, verbosity=2, out_dir=method_dir, dist='CB', biased_w2_ave=None,\n",
    "                        unbiased_w2_ave=None, processes=10, threshold=0.5, file_prefix='{}_Scores_'.format(method), plots=True)\n",
    "                    # Score Prediction Clustering\n",
    "                    contact_scorer_any.map_predictions_to_pdb(ranks=predictor.rankings, predictions=predictor.scores, coverages=predictor.coverages,\n",
    "                                                              threshold=0.5)\n",
    "                    z_score_fn = os.path.join(method_dir, '{}_Scores_Dist-Any_{}_ZScores.tsv'.format(method, p_id))\n",
    "                    z_score_plot_fn = os.path.join(method_dir, '{}_Scores_Dist-Any_{}_ZScores.png'.format(method, p_id))\n",
    "                    z_score_biased, biased_w2_ave, biased_scw_z_auc = contact_scorer_any.score_clustering_of_contact_predictions(\n",
    "                        bias=True, file_path=z_score_fn.format('Biased'), w2_ave_sub=biased_w2_ave, processes=10)\n",
    "                    biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                    curr_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                    curr_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(contact_scorer_any.query_structure.seq[contact_scorer_any.best_chain])) * 0.10][0]\n",
    "                    curr_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(contact_scorer_any.query_structure.seq[contact_scorer_any.best_chain])) * 0.30][0]\n",
    "                    curr_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                    plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                    z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = contact_scorer_any.score_clustering_of_contact_predictions(\n",
    "                        bias=False, file_path=z_score_fn.format('Unbiased'), w2_ave_sub=unbiased_w2_ave, processes=10)\n",
    "                    unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                    curr_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                    curr_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(contact_scorer_any.query_structure.seq[contact_scorer_any.best_chain])) * 0.10][0]\n",
    "                    curr_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(contact_scorer_any.query_structure.seq[contact_scorer_any.best_chain])) * 0.30][0]\n",
    "                    curr_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                    plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                    # Record execution times\n",
    "                    curr_df['Total Time'] = total_time\n",
    "                    # Record static data for this protein\n",
    "                    curr_df['Protein'] = p_id\n",
    "                    curr_df['Method'] = method\n",
    "                    curr_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                    curr_df.to_csv(curr_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                    temp_data = os.path.join(method_dir, 'unique_node_data')\n",
    "                    if os.path.isdir(temp_data):\n",
    "                        for temp_fn in os.listdir(temp_data):\n",
    "                            if not (temp_fn.endswith(\"_pair_rank_filtered_average_product_corrected_mutual_information_score.npz\") or\n",
    "                                    temp_fn.endswith(\"_pair_rank_match_mismatch_entropy_angle_score.npz\")):\n",
    "                                os.remove(os.path.join(temp_data, temp_fn))\n",
    "                    print('Metrics meastured for {} covariance for: {}'.format(method, p_id))\n",
    "                # Set the dataframe for this protein, or update it with additional evaluation data\n",
    "                if protein_df is None:\n",
    "                    protein_df = curr_df\n",
    "                else:\n",
    "                    protein_df = protein_df.append(curr_df)\n",
    "            # Write the evaluation data for this protein to file\n",
    "            protein_df.to_csv(protein_df_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "        # Set the dataframe for this protein, or update it with additional evaluation data\n",
    "        if small_comparison_df is None:\n",
    "            small_comparison_df = protein_df\n",
    "        else:\n",
    "            small_comparison_df = small_comparison_df.append(protein_df)\n",
    "    # Write out final comparison data so it can be loaded later for generating figures.\n",
    "    small_comparison_df['Protein Length'] = small_comparison_df['Protein'].apply(lambda x: generator.protein_data[x]['Length'])\n",
    "    small_comparison_df.to_csv(small_comparison_fn, sep='\\t', header=True, index=False, columns=output_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Execution Time for ET-MIp and cET-MIp\n",
    "The time to compute the trace for the full phylogenetic tree and the trace constrained to a subset of the top levels should take significantly less time to compute, here we evaluate if that is in fact the case or not.\n",
    "\n",
    "## Data Cleaning\n",
    "At least one protein in this data set has a very small alignment and could not be evaluated by cET-MIp because the tree was too small to each the levels set for other proteins. Here we remove those proteins.\n",
    "\n",
    "In addition since this analysis focuses on times and there are many other types of data (some of which cause redundancies in the time data), we will use this opportunity to subset the data and drop duplicates.\n",
    "\n",
    "Finally, for some it will be more informative to view execution time in terms of minutes or hours, as opposed to the originally reported seconds, so we will add columns for these units as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_method_groups = small_comparison_df[['Protein', 'Method']].drop_duplicates().groupby('Protein').count()\n",
    "method_max = protein_method_groups['Method'].max()\n",
    "proteins_to_keep = protein_method_groups.index[protein_method_groups['Method'] == method_max]\n",
    "comparable_method_proteins = small_comparison_df[small_comparison_df['Protein'].isin(proteins_to_keep)]\n",
    "time_columns = ['Protein', 'Protein Length', 'Alignment Size', 'Method', 'Init Time', 'Import Time', 'Dist Tree Time',\n",
    "                'Trace Time', 'Total Time']\n",
    "time_subset_df = comparable_method_proteins.loc[comparable_method_proteins['Method'].isin(['ET-MIp', 'cET-MIp']), time_columns]\n",
    "time_subset_df['Total Time (min)'] = time_subset_df['Total Time'].apply(lambda x: x / 60.0)\n",
    "time_subset_df['Total Time (hr)'] = time_subset_df['Total Time (min)'].apply(lambda x: x / 60.0)\n",
    "time_columns += ['Total Time (min)', 'Total Time (hr)']\n",
    "time_subset_df = time_subset_df.drop_duplicates(subset=None, inplace=False, keep='first')\n",
    "time_subset_df.to_csv(os.path.join(small_set_out_dir, 'Small_Time_Comaprison_Data.csv'), sep='\\t', header=True, index=False,\n",
    "                      columns=time_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Comparison\n",
    "Now that only comparable proteins are present in the data we compare the runtime of individual proteins by method, ordered by their length and the size of their alignemnts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Displayed by protein length order\n",
    "protein_length_order = comparable_method_proteins.sort_values('Protein Length')['Protein'].unique()\n",
    "protein_length_time_plot = sns.barplot(x='Protein', y='Total Time', hue='Method', order=protein_length_order,\n",
    "                                       hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_length_time_plot.set_xticklabels(protein_length_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_length_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Length_Time_Comparison_Sec.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "protein_length_time_plot = sns.barplot(x='Protein', y='Total Time (min)', hue='Method', order=protein_length_order,\n",
    "                                       hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_length_time_plot.set_xticklabels(protein_length_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_length_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Length_Time_Comparison_Min.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "protein_length_time_plot = sns.barplot(x='Protein', y='Total Time (hr)', hue='Method', order=protein_length_order,\n",
    "                                       hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_length_time_plot.set_xticklabels(protein_length_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_length_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Length_Time_Comparison_Hr.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Displayed by alignment size order\n",
    "protein_alignment_order = comparable_method_proteins.sort_values('Alignment Size')['Protein'].unique()\n",
    "protein_alignment_time_plot = sns.barplot(x='Protein', y='Total Time', hue='Method', order=protein_alignment_order,\n",
    "                                          hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_alignment_time_plot.set_xticklabels(protein_alignment_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_alignment_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Alignment_Time_Comparison_Sec.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "protein_alignment_time_plot = sns.barplot(x='Protein', y='Total Time (min)', hue='Method', order=protein_alignment_order,\n",
    "                                          hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_alignment_time_plot.set_xticklabels(protein_alignment_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_alignment_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Alignment_Time_Comparison_Min.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "protein_alignment_time_plot = sns.barplot(x='Protein', y='Total Time (hr)', hue='Method', order=protein_alignment_order,\n",
    "                                          hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_alignment_time_plot.set_xticklabels(protein_alignment_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_alignment_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Alignment_Time_Comparison_Hr.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall comparison of time by method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of ET-MIp and cET-MIp total computation time (sec).\n",
    "protein_method_comp_plot = sns.boxplot(x='Method', y='Total Time', order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_method_comp_plot.set_xticklabels(protein_method_comp_plot.get_xticklabels(), rotation=90)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_Time_Comparison_Sec.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Comparison of ET-MIp and cET-MIp total computation time (sec).\n",
    "protein_method_comp_plot = sns.boxplot(x='Method', y='Total Time (min)', order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_method_comp_plot.set_xticklabels(protein_method_comp_plot.get_xticklabels(), rotation=90)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_Time_Comparison_Min.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Comparison of ET-MIp and cET-MIp total computation time (sec).\n",
    "protein_method_comp_plot = sns.boxplot(x='Method', y='Total Time (hr)', order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_method_comp_plot.set_xticklabels(protein_method_comp_plot.get_xticklabels(), rotation=90)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_Time_Comparison_Hr.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Statistical comparison\n",
    "from scipy.stats import wilcoxon\n",
    "et_mip_sub_df = time_subset_df[time_subset_df['Method'] == 'ET-MIp']\n",
    "cet_mip_sub_df = time_subset_df[time_subset_df['Method'] == 'cET-MIp']\n",
    "sec_stat, sec_p_val = wilcoxon(x=et_mip_sub_df['Total Time'], y=cet_mip_sub_df['Total Time'], zero_method='wilcox')\n",
    "min_stat, min_p_val = wilcoxon(x=et_mip_sub_df['Total Time (min)'], y=cet_mip_sub_df['Total Time (min)'], zero_method='wilcox')\n",
    "hr_stat, hr_p_val = wilcoxon(x=et_mip_sub_df['Total Time (hr)'], y=cet_mip_sub_df['Total Time (hr)'], zero_method='wilcox')\n",
    "time_statistics = {'Time Unit': ['sec', 'min', 'hr'], 'Statistic': [sec_stat, min_stat, hr_stat], 'P-Value': [sec_p_val, min_p_val, hr_p_val]}\n",
    "pd.DataFrame(time_statistics).to_csv(os.path.join(small_set_out_dir, 'Small_Time_Comaprison_Statistics.csv'), sep='\\t', header=True,\n",
    "                                     index=False, columns=['Time Unit', 'Statistic', 'P-Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method Comparison\n",
    "We now begin comparing methods based on their ability to predict the structural contacts in the proteins in this test set. There is an important consideration in the case of sequence separation and different measures by which to compare the methods.\n",
    "\n",
    "### Data Cleaning\n",
    "These data need an additional cleaning step beyond what was performed for the timing comparison. Since there are multiple categories of sequence separation and some proteins may not have any True Positive contacts for a category the scoring for that protein is incomplete. We will remove all such proteins from the comparison, performing the clean up separate for each metric of success. Another contributing factor which necessitates this kind of cleaning is assessment of the top K predictions for a protein or best L/K predictions which for poor predictions may not include any predictions of True Positives.\n",
    "\n",
    "### Sequence Separation\n",
    "One important consideration for the difficulty of prediction and interest in predictions is the distance between the residues for which coupling was predicted. As has been documented in the literature, especially in the CASP competitions, there are several categories of prediction:\n",
    "* Neighbors (1 - 5 residues apart) - This is the least interesting category of predictions. It is highly likely that residues this close together will show covariance signal. Predicting two residues are in contact that are this close together is trivial and uninformative.\n",
    "* Short (6 - 12 residues apart) - This is also not a very interesting type of prediction. Residues this close in proximity can be more easily modeled by alogrithms which focus on 2D protein structure modeling (identifying beta sheets, alpha helices, etc.).\n",
    "* Medium (13 - 24 residues apart) - This is a more interesting type of prediction. The resiudes in this range of separation are on the edge of the 2D protein structure prediction range.\n",
    "* Long (24 and more residues apart) - The most interesting category of predictions. Resiudes this far apart are not easily modeled by 2D protein structure modeling systems. They are also very useful for 3D and 4D protein structure prediction becausae they provide constraints on potential protein (similar to NMR data) folds which makes protein folding a more tractable problem for modelers.\n",
    "* Any/All - All categories can be considered at once, this provides a summary value, but is often skewed by one particularly good category of predictions.\n",
    "\n",
    "### Metrics of Success\n",
    "* AUROC - This measures the True Positive Rate vs the False Positive Rate of prediction, it can be considered a measure of the accuracy of the measure. This can be strongly influenced by the class imbalance which is present when predicting structural contacts since there are many fewer contacts than non-contacts. The True Positive case is if the C-beta of two amino acids is within 8.0 Angstroms of one another (as is done in the CASP competitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_columns = ['Protein', 'Method', 'Sequence_Separation', 'AUROC']\n",
    "protein_auroc_groups = comparable_method_proteins[auroc_columns].drop_duplicates().groupby('Protein')['AUROC'].apply(\n",
    "    lambda x: not x.isnull().any())\n",
    "complete_proteins = protein_auroc_groups.index[protein_auroc_groups.values]\n",
    "comparable_auroc_proteins = small_comparison_df[small_comparison_df['Protein'].isin(complete_proteins)]\n",
    "auroc_protein_length_order = [x for x in protein_length_order if x in complete_proteins]\n",
    "auroc_protein_alignment_order = [x for x in protein_alignment_order if x in complete_proteins]\n",
    "auroc_subset_df = comparable_auroc_proteins.loc[:, auroc_columns].drop_duplicates()\n",
    "# Plot the methods vs AUROC per protein ordered by protein length\n",
    "auroc_subset_df.to_csv(os.path.join(small_set_out_dir, 'Small_AUROC_Comaprison_Data.csv'), sep='\\t', header=True, index=False,\n",
    "                       columns=auroc_columns)\n",
    "protein_order_auroc_plot = sns.catplot(x=\"Protein\", y=\"AUROC\", hue=\"Method\", row=\"Sequence_Separation\", data=auroc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auroc_protein_length_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "protein_order_auroc_plot.set_xticklabels(auroc_protein_length_order, rotation=90)\n",
    "protein_order_auroc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUROC_Comparison_Protein_Length_Order.png'),\n",
    "                                 bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUROC per protein ordered by protein alignment size\n",
    "alignment_order_auroc_plot = sns.catplot(x=\"Protein\", y=\"AUROC\", hue=\"Method\", row=\"Sequence_Separation\", data=auroc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auroc_protein_alignment_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "alignment_order_auroc_plot.set_xticklabels(auroc_protein_alignment_order, rotation=90)\n",
    "alignment_order_auroc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUROC_Comparison_Alignment_Size_Order.png'),\n",
    "                                   bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUROC grouped together to see overall trends\n",
    "overall_auroc_plot = sns.boxplot(x=\"Sequence_Separation\", y=\"AUROC\", hue=\"Method\", data=auroc_subset_df,\n",
    "                                 order=sequence_separation_order, hue_order=method_order)\n",
    "overall_auroc_plot.set_xticklabels(sequence_separation_order, rotation=90)\n",
    "overall_auroc_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUROC_Comparison.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Compute statistics comparing methods at each sequence separation\n",
    "auroc_statistics = {'Sequence Separation': [], 'Method 1': [], 'Method 2': [], 'Statistic': [], 'P-Value': []}\n",
    "for sep in sequence_separation_order:\n",
    "    sep_auroc_subset_df = auroc_subset_df.loc[auroc_subset_df['Sequence_Separation'] == sep, :]\n",
    "    for i in range(len(method_order)):\n",
    "        m1_sep_auroc_subset_df = sep_auroc_subset_df.loc[sep_auroc_subset_df['Method'] == method_order[i], :]\n",
    "        for j in range(i + 1, len(method_order)):\n",
    "            m2_sep_auroc_subset_df = sep_auroc_subset_df.loc[sep_auroc_subset_df['Method'] == method_order[j], :]\n",
    "            stat, p_val = wilcoxon(x=m1_sep_auroc_subset_df['AUROC'], y=m2_sep_auroc_subset_df['AUROC'], zero_method='wilcox')\n",
    "            auroc_statistics['Sequence Separation'].append(sep)\n",
    "            auroc_statistics['Method 1'].append(method_order[i])\n",
    "            auroc_statistics['Method 2'].append(method_order[j])\n",
    "            auroc_statistics['Statistic'].append(stat)\n",
    "            auroc_statistics['P-Value'].append(p_val)\n",
    "pd.DataFrame(auroc_statistics).to_csv(os.path.join(small_set_out_dir, 'Small_AUROC_Comaprison_Statistics.csv'), sep='\\t', header=True,\n",
    "                                      index=False, columns=['Sequence Separation', 'Method 1', 'Method 2', 'Statistic', 'P-Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics of Success (Continued)\n",
    "* AUPRC - This measures the Precision vs the Recall of the predictions, it can be considered a measure of the accuracy of the measure. This is less strongly influenced by the class imbalance which is present when predicting structural contacts since there are many fewer contacts than non-contacts. The True Positive case is if the C-beta of two amino acids is within 8.0 Angstroms of one another (as is done in the CASP competitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "auprc_columns = ['Protein', 'Method', 'Sequence_Separation', 'AUPRC']\n",
    "protein_auprc_groups = comparable_method_proteins[auprc_columns].drop_duplicates().groupby('Protein')['AUPRC'].apply(\n",
    "    lambda x: not x.isnull().any())\n",
    "complete_proteins = protein_auprc_groups.index[protein_auprc_groups.values]\n",
    "comparable_auprc_proteins = small_comparison_df[small_comparison_df['Protein'].isin(complete_proteins)]\n",
    "auprc_protein_length_order = [x for x in protein_length_order if x in complete_proteins]\n",
    "auprc_protein_alignment_order = [x for x in protein_alignment_order if x in complete_proteins]\n",
    "auprc_subset_df = comparable_auprc_proteins.loc[:, auprc_columns].drop_duplicates()\n",
    "# Plot the methods vs AUPRC per protein ordered by protein length\n",
    "auprc_subset_df.to_csv(os.path.join(small_set_out_dir, 'Small_AUPRC_Comaprison_Data.csv'), sep='\\t', header=True, index=False,\n",
    "                       columns=auprc_columns)\n",
    "protein_order_auprc_plot = sns.catplot(x=\"Protein\", y=\"AUPRC\", hue=\"Method\", row=\"Sequence_Separation\", data=auprc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auprc_protein_length_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "protein_order_auprc_plot.set_xticklabels(auprc_protein_length_order, rotation=90)\n",
    "protein_order_auprc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUPRC_Comparison_Protein_Length_Order.png'),\n",
    "                                 bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUPRC per protein ordered by protein alignment size\n",
    "alignment_order_auprc_plot = sns.catplot(x=\"Protein\", y=\"AUPRC\", hue=\"Method\", row=\"Sequence_Separation\", data=auprc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auprc_protein_alignment_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "alignment_order_auprc_plot.set_xticklabels(auprc_protein_alignment_order, rotation=90)\n",
    "alignment_order_auprc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUPRC_Comparison_Alignment_Size_Order.png'),\n",
    "                                   bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUPRC grouped together to see overall trends\n",
    "overall_auprc_plot = sns.boxplot(x=\"Sequence_Separation\", y=\"AUPRC\", hue=\"Method\", data=auprc_subset_df,\n",
    "                                 order=sequence_separation_order, hue_order=method_order)\n",
    "overall_auprc_plot.set_xticklabels(sequence_separation_order, rotation=90)\n",
    "overall_auprc_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUPRC_Comparison.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Compute statistics comparing methods at each sequence separation\n",
    "auprc_statistics = {'Sequence Separation': [], 'Method 1': [], 'Method 2': [], 'Statistic': [], 'P-Value': []}\n",
    "for sep in sequence_separation_order:\n",
    "    sep_auprc_subset_df = auprc_subset_df.loc[auprc_subset_df['Sequence_Separation'] == sep, :]\n",
    "    for i in range(len(method_order)):\n",
    "        m1_sep_auprc_subset_df = sep_auprc_subset_df.loc[sep_auprc_subset_df['Method'] == method_order[i], :]\n",
    "        for j in range(i + 1, len(method_order)):\n",
    "            m2_sep_auprc_subset_df = sep_auprc_subset_df.loc[sep_auprc_subset_df['Method'] == method_order[j], :]\n",
    "            stat, p_val = wilcoxon(x=m1_sep_auprc_subset_df['AUPRC'], y=m2_sep_auprc_subset_df['AUPRC'], zero_method='wilcox')\n",
    "            auprc_statistics['Sequence Separation'].append(sep)\n",
    "            auprc_statistics['Method 1'].append(method_order[i])\n",
    "            auprc_statistics['Method 2'].append(method_order[j])\n",
    "            auprc_statistics['Statistic'].append(stat)\n",
    "            auprc_statistics['P-Value'].append(p_val)\n",
    "pd.DataFrame(auprc_statistics).to_csv(os.path.join(small_set_out_dir, 'Small_AUPRC_Comaprison_Statistics.csv'), sep='\\t', header=True,\n",
    "                                      index=False, columns=['Sequence Separation', 'Method 1', 'Method 2', 'Statistic', 'P-Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Precision at K - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Recall at K - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* F1 at K - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Structural Cluster Weighting Z-Score - "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (PyET3)",
   "language": "python",
   "name": "pyet3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
