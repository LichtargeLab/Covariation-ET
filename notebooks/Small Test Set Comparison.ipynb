{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Test Set #\n",
    "## Goal ##\n",
    "The goal of this test set is to perform proof of concept testing on a small number of proteins with a wide range of sizes and available homologs, orthologs, and paralogs. By doing so it should be possible to test the best parameterization for this tool as well as identifying the strengths and weaknesses of the tool using various measurments as end points.\n",
    "## Warning ##\n",
    "Before attempting to use this notebook make sure that your .env file has been properly setup to reflect the correct locations of command line tools and the location of files and directories needed for execution.\n",
    "### Initial Import###\n",
    "This first cell performs the necessary imports required to begin this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "try:\n",
    "    dotenv_path = find_dotenv(raise_error_if_not_found=True)\n",
    "except IOError:\n",
    "    dotenv_path = find_dotenv(raise_error_if_not_found=True, usecwd=True)\n",
    "load_dotenv(dotenv_path)\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ.get('PROJECT_PATH'), 'src'))\n",
    "sys.path.append(os.path.join(os.environ.get('PROJECT_PATH'), 'src', 'SupportingClasses'))\n",
    "input_dir = os.environ.get('INPUT_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set Construction ##\n",
    "The first task required to test the data set is to download the required data and construct any necessary input files for all down stream analyses.\n",
    "In this case that means:\n",
    "* Downloading PDB files for the proteins in our small test set.\n",
    "* Extracting a query sequence from each PDB file.\n",
    "* Searching for paralogs, homologs, and orthologs in a custom BLAST database built by filtering the Uniref90 database.\n",
    "* Filtering the hits from the BLAST search to meet minimum and maximum length requirements, as well as minimum and maximum identity requirements.\n",
    "* Building alignments using CLUSTALW in both the fasta and msf formats since some of the tools which will be used for comparison need different formats.\n",
    "* Filtering the alignment for maximum identity similarity between seqeunces.\n",
    "* Re-aligning the filtered sequences using CLUSTALW.\n",
    "This is all handeled by the DataSetGenerator class found in the src/SupportingClasses folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing protein list\n",
      "Downloading structures and parsing in query sequences\n",
      "Unique Sequences Found: 23!\n",
      "BLASTing query sequences\n",
      "Filtering BLAST hits, aligning, filtering by identity, and re-aligning\n",
      "   Protein_ID Chain     Accession  BLAST_Hits  Filtered_BLAST  \\\n",
      "9        2b59     B    CIPA_CLOTM        1606               4   \n",
      "5        7hvp     A     POL_HV1A2        2500              33   \n",
      "20       1c0k     A    OXDA_RHOTO        2500              51   \n",
      "15       206l     A      LYS_BPT4        1039             131   \n",
      "13       1bol     A    RNRH_RHINI        2500             131   \n",
      "7        3q05     A     P53_HUMAN         932             306   \n",
      "16       1jwl     A    LACI_ECOLI        2500             228   \n",
      "21       1a26     A   PARP1_CHICK        2500             267   \n",
      "1        2ysd     A   MAGI1_HUMAN        2500             412   \n",
      "17       2z0e     A   ATG4B_HUMAN        2111             360   \n",
      "4        4lli     A   MYO5A_HUMAN        2500             441   \n",
      "19       2rh1     A   ADRB2_HUMAN        2500             416   \n",
      "22       3b6v     A   KIF3C_HUMAN        2500             481   \n",
      "10       1h1v     G    GELS_HUMAN        2500             654   \n",
      "12       2zxe     A  Q4H132_SQUAC        2500             880   \n",
      "0        1c17     A    ATPL_ECOLI        1671             850   \n",
      "3        135l     A    LYSC_MELGA        1913             853   \n",
      "8        2wer     A   HSP82_YEAST        2500            1327   \n",
      "14       3tnu     A   K1C14_HUMAN        2500            1681   \n",
      "6        1hck     A    CDK2_HUMAN        2500            2468   \n",
      "18       1axb     A    BLAT_ECOLI        2500            2102   \n",
      "2        4ycu     A     SYK_HUMAN        2500            2421   \n",
      "11       2iop     A    HTPG_ECOLI        2500            2478   \n",
      "\n",
      "    Filtered_Alignment  Length  Total_Size  \n",
      "9                    4    1853      7412.0  \n",
      "5                   33    1437     47421.0  \n",
      "20                  51     368     18768.0  \n",
      "15                  92     164     15088.0  \n",
      "13                 127     238     30226.0  \n",
      "7                  210     393     82530.0  \n",
      "16                 226     360     81360.0  \n",
      "21                 261    1011    263871.0  \n",
      "1                  318    1491    474138.0  \n",
      "17                 344     393    135192.0  \n",
      "4                  352    1855    652960.0  \n",
      "19                 399     413    164787.0  \n",
      "22                 441     793    349713.0  \n",
      "10                 599     782    468418.0  \n",
      "12                 795    1028    817260.0  \n",
      "0                  813      79     64227.0  \n",
      "3                  818     147    120246.0  \n",
      "8                 1207     709    855763.0  \n",
      "14                1518     472    716496.0  \n",
      "6                 1681     298    500938.0  \n",
      "18                2087     286    596882.0  \n",
      "2                 2347     597   1401159.0  \n",
      "11                2472     624   1542528.0  \n",
      "It took 0.16632944742838543 min to generate the data set.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from DataSetGenerator import DataSetGenerator\n",
    "protein_list_dir = os.path.join(input_dir, 'ProteinLists')\n",
    "if not os.path.isdir(protein_list_dir):\n",
    "    os.makedirs(protein_list_dir)\n",
    "small_list_fn = os.path.join(protein_list_dir, 'SmallDataSet.txt')\n",
    "if not os.path.isfile(small_list_fn):\n",
    "    proteins_of_interest = ['2ysdA', '1c17A', '3tnuA', '7hvpA', '135lA', '206lA', '2werA', '1bolA', '3q05A', '1axbA',\n",
    "                            '2rh1A', '1hckA', '3b6vA', '2z0eA', '1jwlA', '1a26A', '1c0kA', '4lliA', '4ycuA', '2iopA',\n",
    "                            '2zxeA', '2b59B', '1h1vG']\n",
    "    with open(small_list_fn, 'w') as small_list_handle:\n",
    "        for p_id in proteins_of_interest:\n",
    "            small_list_handle.write('{}\\n'.format(p_id))\n",
    "generator = DataSetGenerator(input_dir)\n",
    "start = time()\n",
    "summary = generator.build_pdb_alignment_dataset(protein_list_fn=os.path.basename(small_list_fn), processes=10,\n",
    "                                                database='customuniref90.fasta', max_target_seqs=2500, remote=False,\n",
    "                                                verbose=False)\n",
    "summary['Chain'] = summary['Protein_ID'].apply(lambda x: generator.protein_data[x]['Chain'])\n",
    "summary['Accession'] = summary['Protein_ID'].apply(lambda x: generator.protein_data[x]['Accession'])\n",
    "summary['Length'] = summary['Protein_ID'].apply(lambda x: generator.protein_data[x]['Length'])\n",
    "summary['Total_Size'] = summary.apply(lambda x: float(x['Length']) * float(x['Filtered_Alignment']), axis=1)\n",
    "summary.sort_values(by=['Filtered_Alignment', 'Length'], axis=0, inplace=True)\n",
    "summary_columns = ['Protein_ID', 'Chain', 'Accession', 'BLAST_Hits', 'Filtered_BLAST',\n",
    "                   'Filtered_Alignment', 'Length', 'Total_Size']\n",
    "print(summary[summary_columns])\n",
    "end = time()\n",
    "print('It took {} min to generate the data set.'.format((end - start) / 60.0))\n",
    "summary.to_csv(os.path.join(input_dir, 'small_data_set_summary.tsv'), sep='\\t', index=False, header=True,\n",
    "               columns=summary_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a location to store the output of this method comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.environ.get('OUTPUT_PATH')\n",
    "small_set_out_dir = os.path.join(output_dir, 'SmallTestSet')\n",
    "if not os.path.isdir(small_set_out_dir):\n",
    "    os.makedirs(small_set_out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Scoring For Each Method\n",
    "To reduce memory load during prediction and evaluation, the scoring objects needed to compute the metrics used to compare methods will be created ahead of time so they are available to each method when it computes its predictions for a given protein. This will ensure that results do not need to be kept in memory while waiting for all other results to be computed, only the metrics measured for each method will be recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.00040810108184814454 min\n",
      "Importing the PDB file took 0.0029550949732462567 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2960.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3114.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2960.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3114.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.0005920926729838053 min\n",
      "Importing the PDB file took 0.0014386137326558432 min\n",
      "Mapping query sequence and pdb took 0.0025120178858439126 min\n",
      "Computing the distance matrix based on the PDB file took 0.0029610554377237958 min\n",
      "Removing gaps took 0.0005215525627136231 min\n",
      "Importing the PDB file took 0.0013111114501953125 min\n",
      "Mapping query sequence and pdb took 0.0024066805839538575 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2960.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3114.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.00402217706044515 min\n",
      "Removing gaps took 0.0008041739463806152 min\n",
      "Importing the PDB file took 0.001248776912689209 min\n",
      "Removing gaps took 0.0008612235387166341 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2100.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 2138.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 2191.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2100.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 2138.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 2191.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.0006717840830485026 min\n",
      "Mapping query sequence and pdb took 0.0018079121907552083 min\n",
      "Computing the distance matrix based on the PDB file took 0.0012967427571614583 min\n",
      "Removing gaps took 0.0007571895917256673 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2100.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 2138.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 2191.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.0016282161076863607 min\n",
      "Mapping query sequence and pdb took 0.0026790658632914227 min\n",
      "Computing the distance matrix based on the PDB file took 0.00202560822168986 min\n",
      "Removing gaps took 0.0008410453796386719 min\n",
      "Importing the PDB file took 0.0020082831382751466 min\n",
      "Removing gaps took 0.0006177385648091634 min\n",
      "Importing the PDB file took 0.0016821980476379394 min\n",
      "Mapping query sequence and pdb took 0.002474025885264079 min\n",
      "Computing the distance matrix based on the PDB file took 0.01726288398106893 min\n",
      "Removing gaps took 0.0005861759185791015 min\n",
      "Importing the PDB file took 0.0022502779960632325 min\n",
      "Mapping query sequence and pdb took 0.0029920061429341634 min\n",
      "Computing the distance matrix based on the PDB file took 0.015199518203735352 min\n",
      "Removing gaps took 0.000313111146291097 min\n",
      "Importing the PDB file took 0.0007047812143961588 min\n",
      "Removing gaps took 0.0003086407979329427 min\n",
      "Importing the PDB file took 0.00034815470377604166 min\n",
      "Mapping query sequence and pdb took 0.0007182757059733073 min\n",
      "Computing the distance matrix based on the PDB file took 0.0030464847882588704 min\n",
      "Removing gaps took 0.0004445354143778483 min\n",
      "Importing the PDB file took 0.00034833749135335286 min\n",
      "Mapping query sequence and pdb took 0.0008573333422342936 min\n",
      "Computing the distance matrix based on the PDB file took 0.002993452548980713 min\n",
      "Removing gaps took 0.0011127034823099772 min\n",
      "Importing the PDB file took 0.0021686434745788576 min\n",
      "Removing gaps took 0.0010068297386169433 min\n",
      "Importing the PDB file took 0.000381922721862793 min\n",
      "Mapping query sequence and pdb took 0.0014896988868713379 min\n",
      "Computing the distance matrix based on the PDB file took 0.005642414093017578 min\n",
      "Removing gaps took 0.0009427348772684733 min\n",
      "Importing the PDB file took 0.00037039915720621743 min\n",
      "Mapping query sequence and pdb took 0.001408092180887858 min\n",
      "Computing the distance matrix based on the PDB file took 0.006170380115509033 min\n",
      "Removing gaps took 0.006087386608123779 min\n",
      "Importing the PDB file took 0.0020949920018513996 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 9163.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 9164.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 9165.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 9166.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 9167.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 9201.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 9267.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 9314.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain K is discontinuous at line 9321.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain L is discontinuous at line 9325.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.005238882700602214 min\n",
      "Importing the PDB file took 0.0027441898981730144 min\n",
      "Mapping query sequence and pdb took 0.008429086208343506 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 9163.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 9164.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 9165.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 9166.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 9167.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 9201.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 9267.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 9314.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain K is discontinuous at line 9321.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain L is discontinuous at line 9325.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.006136651833852132 min\n",
      "Removing gaps took 0.005414235591888428 min\n",
      "Importing the PDB file took 0.0027650038401285807 min\n",
      "Mapping query sequence and pdb took 0.008622888724009197 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 9163.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 9164.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 9165.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 9166.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 9167.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 9201.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 9267.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 9314.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain K is discontinuous at line 9321.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain L is discontinuous at line 9325.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.007420738538106282 min\n",
      "Removing gaps took 0.002460193634033203 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 8081.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 8101.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 8121.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.0020055333773295087 min\n",
      "Removing gaps took 0.003102584679921468 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 8081.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 8101.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 8121.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.0015887618064880371 min\n",
      "Mapping query sequence and pdb took 0.004878489176432291 min\n",
      "Computing the distance matrix based on the PDB file took 0.012115057309468586 min\n",
      "Removing gaps took 0.0030904213587443032 min\n",
      "Importing the PDB file took 0.0015345056851704916 min\n",
      "Mapping query sequence and pdb took 0.0048231045405069985 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 8081.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 8101.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 8121.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.013928079605102539 min\n",
      "Removing gaps took 0.01654237906138102 min\n",
      "Importing the PDB file took 0.0010261972745259603 min\n",
      "Removing gaps took 0.01667482058207194 min\n",
      "Importing the PDB file took 0.0006369948387145996 min\n",
      "Mapping query sequence and pdb took 0.01790359417597453 min\n",
      "Computing the distance matrix based on the PDB file took 0.0135992964108785 min\n",
      "Removing gaps took 0.015516177813212077 min\n",
      "Importing the PDB file took 0.0006197730700174968 min\n",
      "Mapping query sequence and pdb took 0.016702409585316977 min\n",
      "Computing the distance matrix based on the PDB file took 0.0164287805557251 min\n",
      "Removing gaps took 0.026801021893819173 min\n",
      "Importing the PDB file took 0.005480766296386719 min\n",
      "Removing gaps took 0.026091845830281575 min\n",
      "Importing the PDB file took 0.004432189464569092 min\n",
      "Mapping query sequence and pdb took 0.04291700124740601 min\n",
      "Computing the distance matrix based on the PDB file took 0.0003768324851989746 min\n",
      "Removing gaps took 0.02652555306752523 min\n",
      "Importing the PDB file took 0.004426654179890951 min\n",
      "Mapping query sequence and pdb took 0.0433367133140564 min\n",
      "Computing the distance matrix based on the PDB file took 0.0005028764406840007 min\n",
      "Removing gaps took 0.0097703218460083 min\n",
      "Importing the PDB file took 0.001156322161356608 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 3897.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4034.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.009690157572428386 min\n",
      "Importing the PDB file took 0.0008085449536641439 min\n",
      "Mapping query sequence and pdb took 0.01080549160639445 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 3897.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4034.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.013539222876230876 min\n",
      "Removing gaps took 0.0096137801806132 min\n",
      "Importing the PDB file took 0.000773477554321289 min\n",
      "Mapping query sequence and pdb took 0.010704509417215983 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 3897.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4034.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.012912603219350179 min\n",
      "Removing gaps took 0.05212547381718954 min\n",
      "Importing the PDB file took 0.0017905155817667642 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6531.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 6714.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.052713127930959065 min\n",
      "Importing the PDB file took 0.0014315048853556316 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6531.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 6714.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping query sequence and pdb took 0.05706042448679606 min\n",
      "Computing the distance matrix based on the PDB file took 0.01618785858154297 min\n",
      "Removing gaps took 0.05081588824590047 min\n",
      "Importing the PDB file took 0.0013565421104431152 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6531.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 6714.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping query sequence and pdb took 0.055082090695699054 min\n",
      "Computing the distance matrix based on the PDB file took 0.019417003790537516 min\n",
      "Removing gaps took 0.009499796231587728 min\n",
      "Importing the PDB file took 0.0015480399131774902 min\n",
      "Removing gaps took 0.00931399663289388 min\n",
      "Importing the PDB file took 0.0008538285891215007 min\n",
      "Mapping query sequence and pdb took 0.018233350912729897 min\n",
      "Computing the distance matrix based on the PDB file took 0.021357421080271402 min\n",
      "Removing gaps took 0.009117523829142252 min\n",
      "Importing the PDB file took 0.0008279204368591309 min\n",
      "Mapping query sequence and pdb took 0.018087502320607504 min\n",
      "Computing the distance matrix based on the PDB file took 0.021988725662231444 min\n",
      "Removing gaps took 0.027496095498402914 min\n",
      "Importing the PDB file took 0.001483309268951416 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5418.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/Atom.py:189: PDBConstructionWarning: Used element 'U' for Atom (name=UNK) with given element 'X'\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5449.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5482.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5486.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.030768632888793945 min\n",
      "Importing the PDB file took 0.0010478814442952474 min\n",
      "Mapping query sequence and pdb took 0.03289890686670939 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5418.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/Atom.py:189: PDBConstructionWarning: Used element 'U' for Atom (name=UNK) with given element 'X'\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5449.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5482.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5486.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.010174997647603353 min\n",
      "Removing gaps took 0.028402650356292726 min\n",
      "Importing the PDB file took 0.00103528102238973 min\n",
      "Mapping query sequence and pdb took 0.030061777432759604 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5418.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/Atom.py:189: PDBConstructionWarning: Used element 'U' for Atom (name=UNK) with given element 'X'\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5449.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5482.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5486.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.012347022692362467 min\n",
      "Removing gaps took 0.046332287788391116 min\n",
      "Importing the PDB file took 0.0016238768895467123 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6161.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 6193.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6197.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 6393.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.04246002038319906 min\n",
      "Importing the PDB file took 0.001286907990773519 min\n",
      "Mapping query sequence and pdb took 0.04440484046936035 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6161.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 6193.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6197.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 6393.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.01140980323155721 min\n",
      "Removing gaps took 0.0428015391031901 min\n",
      "Importing the PDB file took 0.0012775699297587076 min\n",
      "Mapping query sequence and pdb took 0.0447906772295634 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6161.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 6193.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6197.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 6393.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.0129135529200236 min\n",
      "Removing gaps took 0.0848992387453715 min\n",
      "Importing the PDB file took 0.0025701642036437987 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11066.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 11103.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11145.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.08556890885035197 min\n",
      "Importing the PDB file took 0.0021897594134012857 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11066.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 11103.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11145.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping query sequence and pdb took 0.08970083793004353 min\n",
      "Computing the distance matrix based on the PDB file took 0.11183563868204753 min\n",
      "Removing gaps took 0.0857035756111145 min\n",
      "Importing the PDB file took 0.0021821260452270508 min\n",
      "Mapping query sequence and pdb took 0.08982928991317748 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11066.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 11103.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11145.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.11220600207646687 min\n",
      "Removing gaps took 0.0042406121889750166 min\n",
      "Importing the PDB file took 0.003572078545888265 min\n",
      "Removing gaps took 0.004219349225362142 min\n",
      "Importing the PDB file took 0.003180090586344401 min\n",
      "Mapping query sequence and pdb took 0.007545757293701172 min\n",
      "Computing the distance matrix based on the PDB file took 0.0007024010022481283 min\n",
      "Removing gaps took 0.002185229460398356 min\n",
      "Importing the PDB file took 0.003153971831003825 min\n",
      "Mapping query sequence and pdb took 0.007818988958994548 min\n",
      "Computing the distance matrix based on the PDB file took 0.0009917338689168294 min\n",
      "Removing gaps took 0.014275777339935302 min\n",
      "Importing the PDB file took 0.0005586425463358561 min\n",
      "Removing gaps took 0.011546754837036132 min\n",
      "Importing the PDB file took 0.00027225414911905926 min\n",
      "Mapping query sequence and pdb took 0.012006103992462158 min\n",
      "Computing the distance matrix based on the PDB file took 0.0019278287887573241 min\n",
      "Removing gaps took 0.011593163013458252 min\n",
      "Importing the PDB file took 0.000271300474802653 min\n",
      "Mapping query sequence and pdb took 0.012057304382324219 min\n",
      "Computing the distance matrix based on the PDB file took 0.0019068002700805664 min\n",
      "Removing gaps took 0.10209368467330933 min\n",
      "Importing the PDB file took 0.001240368684132894 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 4201.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4226.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 4251.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4395.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.10059206485748291 min\n",
      "Importing the PDB file took 0.0008927226066589355 min\n",
      "Mapping query sequence and pdb took 0.10268610715866089 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 4201.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4226.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 4251.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4395.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.004586756229400635 min\n",
      "Removing gaps took 0.1005159298578898 min\n",
      "Importing the PDB file took 0.0030982335408528644 min\n",
      "Mapping query sequence and pdb took 0.10489243666330973 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 4201.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4226.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 4251.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 4395.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.006357665856679281 min\n",
      "Removing gaps took 0.07042027314503987 min\n",
      "Importing the PDB file took 0.0011283198992411295 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 3478.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3488.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.07048648993174235 min\n",
      "Importing the PDB file took 0.0005630016326904297 min\n",
      "Mapping query sequence and pdb took 0.07213631073633829 min\n",
      "Computing the distance matrix based on the PDB file took 0.0007193406422932942 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 3478.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3488.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.07063308954238892 min\n",
      "Importing the PDB file took 0.0005658984184265137 min\n",
      "Mapping query sequence and pdb took 0.07208762963612875 min\n",
      "Computing the distance matrix based on the PDB file took 0.0009574254353841145 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 3478.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3488.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.06768288612365722 min\n",
      "Importing the PDB file took 0.0008033355077107748 min\n",
      "Removing gaps took 0.07069494326909383 min\n",
      "Importing the PDB file took 0.0005538304646809896 min\n",
      "Mapping query sequence and pdb took 0.07229482730229696 min\n",
      "Computing the distance matrix based on the PDB file took 0.009499577681223552 min\n",
      "Removing gaps took 0.06852363348007202 min\n",
      "Importing the PDB file took 0.0005452195803324381 min\n",
      "Mapping query sequence and pdb took 0.07017403443654378 min\n",
      "Computing the distance matrix based on the PDB file took 0.009795443216959635 min\n",
      "Removing gaps took 0.047313690185546875 min\n",
      "Importing the PDB file took 0.000951850414276123 min\n",
      "Removing gaps took 0.0453234593073527 min\n",
      "Importing the PDB file took 0.00047654310862223307 min\n",
      "Mapping query sequence and pdb took 0.04654147227605184 min\n",
      "Computing the distance matrix based on the PDB file took 0.006908794244130452 min\n",
      "Removing gaps took 0.04769770701726277 min\n",
      "Importing the PDB file took 0.00047408342361450196 min\n",
      "Mapping query sequence and pdb took 0.04877531925837199 min\n",
      "Computing the distance matrix based on the PDB file took 0.008735473950703938 min\n",
      "Removing gaps took 0.15910107692082723 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 17206.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 17292.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 17378.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 18052.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 18724.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.004469144344329834 min\n",
      "Removing gaps took 0.1601968765258789 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 17206.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 17292.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 17378.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 18052.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 18724.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.006264722347259522 min\n",
      "Mapping query sequence and pdb took 0.168387770652771 min\n",
      "Computing the distance matrix based on the PDB file took 0.027894926071166993 min\n",
      "Removing gaps took 0.15968736012776694 min\n",
      "Importing the PDB file took 0.0032224416732788085 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 17206.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 17292.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 17378.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 18052.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 18724.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping query sequence and pdb took 0.16484851042429607 min\n",
      "Computing the distance matrix based on the PDB file took 0.03382241725921631 min\n",
      "Removing gaps took 0.10231130520502726 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 20520.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 20547.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 20574.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 20601.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.007267216841379802 min\n",
      "Removing gaps took 0.1058316946029663 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 20520.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 20547.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 20574.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 20601.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.0040301322937011715 min\n",
      "Mapping query sequence and pdb took 0.1111327568689982 min\n",
      "Computing the distance matrix based on the PDB file took 0.041872306664784746 min\n",
      "Removing gaps took 0.10257659355799358 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 20520.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 20547.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 20574.\n",
      "  PDBConstructionWarning)\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 20601.\n",
      "  PDBConstructionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the PDB file took 0.0070395231246948246 min\n",
      "Mapping query sequence and pdb took 0.11093360980351766 min\n",
      "Computing the distance matrix based on the PDB file took 0.04497403303782145 min\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from SeqAlignment import SeqAlignment\n",
    "from PDBReference import PDBReference\n",
    "from ContactScorer import ContactScorer, plot_z_scores\n",
    "protein_order = list(summary['Protein_ID'])\n",
    "method_order = ['DCA', 'EVC Standard', 'EVC Mean Field', 'ET-MIp', 'cET-MIp', 'ET-MIp_MAX']\n",
    "sequence_separation_order = ['Any', 'Neighbors', 'Short', 'Medium', 'Long']\n",
    "protein_scorers = {}\n",
    "small_comparison_df = None\n",
    "small_comparison_fn = os.path.join(small_set_out_dir, 'Small_Comparision_Data.csv')\n",
    "if os.path.isfile(small_comparison_fn):\n",
    "    small_comparison_df = pd.read_csv(small_comparison_fn, sep='\\t', header=0, index_col=False)\n",
    "else:\n",
    "    for p_id in summary['Protein_ID']:\n",
    "        protein_scorers[p_id] = {}\n",
    "        # Import alignment and remove gaps\n",
    "        full_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id)\n",
    "        full_aln.import_alignment()\n",
    "        non_gap_aln = full_aln.remove_gaps()\n",
    "        # Import structure\n",
    "        pdb_structure = PDBReference(pdb_file=generator.protein_data[p_id]['PDB'])\n",
    "        pdb_structure.import_pdb(structure_id=p_id)\n",
    "        protein_scorers[p_id]['Structure'] = pdb_structure\n",
    "        # Initialize Beta Carbon distance scorer\n",
    "        contact_scorer_cb = ContactScorer(query=p_id, seq_alignment=non_gap_aln,\n",
    "                                          pdb_reference=pdb_structure, cutoff=8.0)\n",
    "        contact_scorer_cb.best_chain = generator.protein_data[p_id]['Chain']\n",
    "        contact_scorer_cb.fit()\n",
    "        contact_scorer_cb.measure_distance(method='CB')\n",
    "        protein_scorers[p_id]['Scorer_CB'] = contact_scorer_cb\n",
    "        # Initialize distance scorer minimizing distance between any atoms\n",
    "        contact_scorer_any = ContactScorer(query=p_id, seq_alignment=non_gap_aln,\n",
    "                                           pdb_reference=pdb_structure, cutoff=8.0)\n",
    "        contact_scorer_any.best_chain = generator.protein_data[p_id]['Chain']\n",
    "        contact_scorer_any.fit()\n",
    "        contact_scorer_any.measure_distance(method='Any')\n",
    "        protein_scorers[p_id]['Scorer_Any'] = contact_scorer_any\n",
    "        # Initialize z-scoring subproblems\n",
    "        protein_scorers[p_id]['biased_w2_ave'] = None\n",
    "        protein_scorers[p_id]['unbiased_w2_ave'] = None\n",
    "output_columns = ['Protein', 'Protein Length', 'Alignment Size', 'Method', 'Distance', 'Init Time', 'Import Time', 'Dist Tree Time', 'Trace Time', 'Total Time', \n",
    "                  'Sequence_Separation', 'AUROC', 'AUPRC', 'AUTPRFDRC',\n",
    "                  'Top K Predictions', 'Precision', 'Recall', 'F1 Score',\n",
    "                  'Biased Z-Score at 10%', 'Biased Z-Score at 30%', 'Max Biased Z-Score', 'AUC Biased Z-Score',\n",
    "                  'Unbiased Z-Score at 10%', 'Biased Z-Score at 30%', 'Max Unbiased Z-Score', 'AUC Unbiased Z-Score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Values For Comparision#\n",
    "To determine the effectiveness of the new method and implementation the covariation of the same proteins will be computed using the previous Evolutionary Trace covariation method (ET-MIp) and other methods in the field.\n",
    "\n",
    "## ET-MIp##\n",
    "Scoring the the covariation of the proteins using the previous Evolutionary Trace covariation method (ET-MIp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from ETMIPWrapper import ETMIPWrapper\n",
    "# etmip_out_dir = os.path.join(small_set_out_dir, 'ET-MIp')\n",
    "# if not os.path.isdir(etmip_out_dir):\n",
    "#     os.makedirs(etmip_out_dir)\n",
    "# etmip_scores = {}\n",
    "# counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "# for p_id in generator.protein_data:\n",
    "#     print('Attempting to calculate ET-MIp covariance for: {}'.format(p_id))\n",
    "#     try:\n",
    "#         protein_out_dir = os.path.join(etmip_out_dir, p_id)\n",
    "#         if not os.path.isdir(protein_out_dir):\n",
    "#             os.makedirs(protein_out_dir)\n",
    "#         curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id, polymer_type='Protein')\n",
    "#         curr_aln.import_alignment()\n",
    "#         curr_etmip = ETMIPWrapper(alignment=curr_aln)\n",
    "#         curr_etmip.calculate_scores(out_dir=protein_out_dir, delete_files=False)\n",
    "#         etmip_scores[p_id] = curr_etmip\n",
    "#         print('Successfully computed ET-MIp covariance for: {}'.format(p_id))\n",
    "#         counts['success'] += 1\n",
    "#     except ValueError:\n",
    "#         print('Could not compute ET-MIp covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "#             p_id, curr_aln.seq_length, curr_aln.size))\n",
    "#         counts['value'] += 1\n",
    "#     except AttributeError:\n",
    "#         print('Could not compute ET-MIp covariance for: {} no alignment'.format(p_id))\n",
    "#         counts['attribute'] += 1\n",
    "# print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "#                                                                      counts['attribute']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ET-MIp (Continued)\n",
    "The previous implementation is not able to run for alignments of the size used here. Instead we use the new implementation with the same parameterization used by the previous implementation (Distance Model - blosum62 similarity, Tree - ET UPGMA variant, Scoring Metric - filtered average product corrected mutual information, Ranks - all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EvolutionaryTrace import EvolutionaryTrace\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    etmip_out_dir = os.path.join(small_set_out_dir, 'ET-MIp')\n",
    "    if not os.path.isdir(etmip_out_dir):\n",
    "        os.makedirs(etmip_out_dir)\n",
    "    etmip_method_fn = os.path.join(etmip_out_dir, 'ET-MIp_Method_Data.csv')\n",
    "    if os.path.isfile(etmip_method_fn):\n",
    "        etmip_method_df = pd.read_csv(etmip_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:    \n",
    "        etmip_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "        for p_id in summary['Protein_ID']:\n",
    "            print('Attempting to calculate ET-MIp covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(etmip_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "            else:\n",
    "                try:\n",
    "\n",
    "                    start_time = time()\n",
    "                    curr_etmip = EvolutionaryTrace(query_id=p_id, polymer_type='Protein',\n",
    "                                                   aln_fn=generator.protein_data[p_id]['Final_FA_Aln'], et_distance=True,\n",
    "                                                   distance_model='blosum62', tree_building_method='et', tree_building_options={},\n",
    "                                                   ranks=None, position_type='pair',\n",
    "                                                   scoring_metric='filtered_average_product_corrected_mutual_information',\n",
    "                                                   gap_correction=None, maximize=False, out_dir=protein_dir,\n",
    "                                                   output_files={'original_aln', 'non_gap_aln', 'tree', 'scores'},\n",
    "                                                   processors=10, low_memory=True)\n",
    "                    init_time = time()\n",
    "                    curr_etmip.import_and_process_aln()\n",
    "                    import_time = time()\n",
    "                    curr_etmip.compute_distance_matrix_tree_and_assignments()\n",
    "                    dist_tree_time = time()\n",
    "                    curr_etmip.perform_trace()\n",
    "                    end_time = time()\n",
    "                    print('Successfully computed ET-MIp covariance for: {}'.format(p_id))\n",
    "                    # Compute statistics for the final scores of the ET-MIp model\n",
    "                    protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                        predictor=curr_etmip, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                        unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=curr_etmip.scorer.position_size,\n",
    "                        rank_type=curr_etmip.scorer.rank_type, file_prefix='ET-MIp_Scores_', plots=True)\n",
    "                    # Score Prediction Clustering\n",
    "                    z_score_fn = os.path.join(protein_dir, 'ET-MIp_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                    z_score_plot_fn = os.path.join(protein_dir, 'ET-MIp_Scores_Dist-Any_{}_ZScores.png')\n",
    "                    z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - curr_etmip.coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                    biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                    protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                    plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                    z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - curr_etmip.coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                    unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                    protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                    plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                    # Record execution times\n",
    "                    protein_df['Init Time'] = init_time - start_time\n",
    "                    protein_df['Import Time'] = import_time - init_time\n",
    "                    protein_df['Dist Tree Time'] = dist_tree_time - import_time\n",
    "                    protein_df['Trace Time'] = end_time - dist_tree_time\n",
    "                    protein_df['Total Time'] = end_time - start_time\n",
    "                    # Record static data for this protein\n",
    "                    protein_df['Protein'] = p_id\n",
    "                    protein_df['Method'] = 'ET-MIp'\n",
    "                    protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                    protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                    temp_data = os.path.join(protein_dir, 'unique_node_data')\n",
    "                    for temp_fn in os.listdir(temp_data):\n",
    "                        if not temp_fn.endswith(\"_pair_rank_filtered_average_product_corrected_mutual_information_score.npz\"):\n",
    "                            os.remove(os.path.join(temp_data, temp_fn))\n",
    "                    print('Metrics meastured for ET-MIp covariance for: {}'.format(p_id))\n",
    "                    counts['success'] += 1\n",
    "                except ValueError:\n",
    "                    print('Could not compute ET-MIp covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "                        p_id, curr_etmip.original_aln.seq_length, curr_etmip.original_aln.size))\n",
    "                    counts['value'] += 1\n",
    "                    continue\n",
    "                except AttributeError:\n",
    "                    print('Could not compute ET-MIp covariance for: {} no alignment'.format(p_id))\n",
    "                    counts['attribute'] += 1\n",
    "                    continue\n",
    "            if etmip_method_df is None:\n",
    "                etmip_method_df = protein_df\n",
    "            else:\n",
    "                etmip_method_df = etmip_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        etmip_method_df.to_csv(etmip_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = etmip_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(etmip_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cET-MIp\n",
    "This segment the ET-MIp method, when constrained to an arbitrary set of nodes (1, 2, 3, 5, 7, 10, 25) at the top of the phylogenetic tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(small_comparison_fn):\n",
    "    cetmip_out_dir = os.path.join(small_set_out_dir, 'cET-MIp')\n",
    "    if not os.path.isdir(cetmip_out_dir):\n",
    "        os.makedirs(cetmip_out_dir)\n",
    "    cetmip_method_fn = os.path.join(cetmip_out_dir, 'cET-MIp_Method_Data.csv')\n",
    "    if os.path.isfile(cetmip_method_fn):\n",
    "        cetmip_method_df = pd.read_csv(cetmip_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:\n",
    "        cetmip_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0, 'key': 0}\n",
    "        for p_id in summary['Protein_ID']:\n",
    "            print('Attempting to calculate cET-MIp covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(cetmip_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "            else:\n",
    "                try:\n",
    "                    start_time = time()\n",
    "                    curr_cetmip = EvolutionaryTrace(query_id=p_id, polymer_type='Protein',\n",
    "                                                   aln_fn=generator.protein_data[p_id]['Final_FA_Aln'], et_distance=True,\n",
    "                                                   distance_model='blosum62', tree_building_method='et', tree_building_options={},\n",
    "                                                   ranks=[1, 2, 3, 5, 7, 10, 25], position_type='pair',\n",
    "                                                   scoring_metric='filtered_average_product_corrected_mutual_information',\n",
    "                                                   gap_correction=None, maximize=False, out_dir=protein_dir,\n",
    "                                                   output_files={'original_aln', 'non_gap_aln', 'tree', 'scores'},\n",
    "                                                   processors=10, low_memory=True)\n",
    "                    init_time = time()\n",
    "                    curr_cetmip.import_and_process_aln()\n",
    "                    import_time = time()\n",
    "                    curr_cetmip.compute_distance_matrix_tree_and_assignments()\n",
    "                    dist_tree_time = time()\n",
    "                    curr_cetmip.perform_trace()\n",
    "                    end_time = time()\n",
    "                    # Compute statistics for the final scores of the ET-MIp model\n",
    "                    protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                        predictor=curr_cetmip, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                        unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=curr_cetmip.scorer.position_size,\n",
    "                        rank_type=curr_cetmip.scorer.rank_type, file_prefix='cET-MIp_Scores_', plots=True)\n",
    "                    # Score Prediction Clustering\n",
    "                    z_score_fn = os.path.join(protein_dir, 'cET-MIp_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                    z_score_plot_fn = os.path.join(protein_dir, 'cET-MIp_Scores_Dist-Any_{}_ZScores.png')\n",
    "                    z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - curr_cetmip.coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                    biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                    protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                    plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                    z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - curr_cetmip.coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                    unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                    protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                    plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                    # Record execution times\n",
    "                    protein_df['Init Time'] = init_time - start_time\n",
    "                    protein_df['Import Time'] = import_time - init_time\n",
    "                    protein_df['Dist Tree Time'] = dist_tree_time - import_time\n",
    "                    protein_df['Trace Time'] = end_time - dist_tree_time\n",
    "                    protein_df['Total Time'] = end_time - start_time\n",
    "                    # Record static data for this protein\n",
    "                    protein_df['Protein'] = p_id\n",
    "                    protein_df['Method'] = 'cET-MIp'\n",
    "                    protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                    protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                    temp_data = os.path.join(protein_dir, 'unique_node_data')\n",
    "                    for temp_fn in os.listdir(temp_data):\n",
    "                        if not temp_fn.endswith(\"_pair_rank_filtered_average_product_corrected_mutual_information_score.npz\"):\n",
    "                            os.remove(os.path.join(temp_data, temp_fn))\n",
    "                    print('Successfully computed cET-MIp covariance for: {}'.format(p_id))\n",
    "                    counts['success'] += 1\n",
    "                except ValueError:\n",
    "                    print('Could not compute cET-MIp covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "                        p_id, curr_cetmip.original_aln.seq_length, curr_etmip.original_aln.size))\n",
    "                    counts['value'] += 1\n",
    "                    continue\n",
    "                except AttributeError:\n",
    "                    print('Could not compute cET-MIp covariance for: {} no alignment'.format(p_id))\n",
    "                    counts['attribute'] += 1\n",
    "                    continue\n",
    "                except KeyError:\n",
    "                    print('Could not compute cET-MIp covariance for: {} not enough sequences'.format('p_ied'))\n",
    "                    counts['key'] += 1\n",
    "                    continue\n",
    "            if cetmip_method_df is None:\n",
    "                cetmip_method_df = protein_df\n",
    "            else:\n",
    "                cetmip_method_df = cetmip_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        cetmip_method_df.to_csv(cetmip_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = cetmip_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(cetmip_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ET-MIp with Group Maximiziation ###\n",
    "This cell generates data for and tests the effect of maximizing the group score when moving from a parent node to child nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 2b59\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 7hvp\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 1c0k\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 206l\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 1bol\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 3q05\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 1jwl\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 1a26\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 2ysd\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 2z0e\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 4lli\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 2rh1\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 3b6v\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 1h1v\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 2zxe\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 1c17\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 135l\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 2wer\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 3tnu\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 1hck\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 1axb\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 4ycu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4693/4693 [00:03<00:00, 1306.41characterizations/s]\n",
      "100%|| 4693/4693 [00:03<00:00, 1364.41group/s]\n",
      "  0%|          | 0/2347 [00:00<?, ?rank/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Score MAXIMIZATION Took: 192.91375775337218 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2347/2347 [30:02<00:00,  1.30rank/s] \n",
      "100%|| 177906/177906 [03:00<00:00, 987.55variation/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to file in 3.0754732489585876 min\n",
      "Successfully computed ET-MIp MAX covariance for: 4ycu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/Documents/git/ETMIP/src/SupportingClasses/ContactScorer.py:760: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fdr = fps / fdr_denominator\n",
      "/home/daniel/Documents/git/ETMIP/src/SupportingClasses/ContactScorer.py:760: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fdr = fps / fdr_denominator\n",
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/numpy/lib/function_base.py:4523: RuntimeWarning: invalid value encountered in multiply\n",
      "  ret = (d * (y[slice1] + y[slice2]) / 2.0).sum(axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute SCW Z-Score took 0.3458731174468994 min\n",
      "Compute SCW Z-Score took 0.33072091738382975 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/pandas/core/indexing.py:1404: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics meastured for ET-MIp MAX covariance for: 4ycu\n",
      "Attempting to calculate ET-MIp MAXIMIZED covariance for: 2iop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyET3/lib/python3.6/site-packages/pandas/core/frame.py:7116: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gaps took 0.09433327913284302 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2472/2472 [00:02<00:00, 1051.07sequences/s]\n",
      "100%|| 3054156/3054156 [1:27:27<00:00, 582.01distances/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing tree took: 3.2616514364878335 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4943/4943 [1:08:01<00:00,  1.55s/characterizations]  \n",
      "100%|| 4943/4943 [07:51<00:00,  1.74group/s]  \n",
      "  0%|          | 0/2472 [00:00<?, ?rank/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Score MAXIMIZATION Took: 236.40004972219467 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2472/2472 [36:38<00:00,  1.12rank/s]  \n",
      "100%|| 194376/194376 [03:29<00:00, 929.03variation/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to file in 3.5659597675005594 min\n",
      "Successfully computed ET-MIp MAX covariance for: 2iop\n",
      "Compute SCW Z-Score took 0.5762609799702962 min\n",
      "Compute SCW Z-Score took 0.5886143922805787 min\n",
      "Metrics meastured for ET-MIp MAX covariance for: 2iop\n",
      "2\tSuccesses\n",
      "0\tValue Errors\n",
      "0\tAttribute Errors\n"
     ]
    }
   ],
   "source": [
    "from EvolutionaryTrace import EvolutionaryTrace\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    etmip_out_dir = os.path.join(small_set_out_dir, 'ET-MIp_MAX')\n",
    "    if not os.path.isdir(etmip_out_dir):\n",
    "        os.makedirs(etmip_out_dir)\n",
    "    etmip_method_fn = os.path.join(etmip_out_dir, 'ET-MIp_MAX_Method_Data.csv')\n",
    "    if os.path.isfile(etmip_method_fn):\n",
    "        etmip_method_df = pd.read_csv(etmip_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:    \n",
    "        etmip_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "        for p_id in summary['Protein_ID']:\n",
    "            print('Attempting to calculate ET-MIp MAXIMIZED covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(etmip_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "            else:\n",
    "                try:\n",
    "\n",
    "                    start_time = time()\n",
    "                    curr_etmip = EvolutionaryTrace(query_id=p_id, polymer_type='Protein',\n",
    "                                                   aln_fn=generator.protein_data[p_id]['Final_FA_Aln'], et_distance=True,\n",
    "                                                   distance_model='blosum62', tree_building_method='et', tree_building_options={},\n",
    "                                                   ranks=None, position_type='pair',\n",
    "                                                   scoring_metric='filtered_average_product_corrected_mutual_information',\n",
    "                                                   gap_correction=None, maximize=True, out_dir=protein_dir,\n",
    "                                                   output_files={'original_aln', 'non_gap_aln', 'tree', 'scores'},\n",
    "                                                   processors=10, low_memory=True)\n",
    "                    init_time = time()\n",
    "                    curr_etmip.import_and_process_aln()\n",
    "                    import_time = time()\n",
    "                    curr_etmip.compute_distance_matrix_tree_and_assignments()\n",
    "                    dist_tree_time = time()\n",
    "                    curr_etmip.perform_trace()\n",
    "                    end_time = time()\n",
    "                    print('Successfully computed ET-MIp MAX covariance for: {}'.format(p_id))\n",
    "                    # Compute statistics for the final scores of the ET-MIp model\n",
    "                    protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                        predictor=curr_etmip, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                        unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=curr_etmip.scorer.position_size,\n",
    "                        rank_type=curr_etmip.scorer.rank_type, file_prefix='ET-MIp_MAX_Scores_', plots=True)\n",
    "                    # Score Prediction Clustering\n",
    "                    z_score_fn = os.path.join(protein_dir, 'ET-MIp_MAX_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                    z_score_plot_fn = os.path.join(protein_dir, 'ET-MIp_MAX_Scores_Dist-Any_{}_ZScores.png')\n",
    "                    z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - curr_etmip.coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                    biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                    protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                    plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                    z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - curr_etmip.coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                    unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                    protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                    plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                    # Record execution times\n",
    "                    protein_df['Init Time'] = init_time - start_time\n",
    "                    protein_df['Import Time'] = import_time - init_time\n",
    "                    protein_df['Dist Tree Time'] = dist_tree_time - import_time\n",
    "                    protein_df['Trace Time'] = end_time - dist_tree_time\n",
    "                    protein_df['Total Time'] = end_time - start_time\n",
    "                    # Record static data for this protein\n",
    "                    protein_df['Protein'] = p_id\n",
    "                    protein_df['Method'] = 'ET-MIp_MAX'\n",
    "                    protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                    protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                    temp_data = os.path.join(protein_dir, 'unique_node_data')\n",
    "                    for temp_fn in os.listdir(temp_data):\n",
    "                        if not temp_fn.endswith(\"_pair_rank_filtered_average_product_corrected_mutual_information_score.npz\"):\n",
    "                            os.remove(os.path.join(temp_data, temp_fn))\n",
    "                    print('Metrics meastured for ET-MIp MAX covariance for: {}'.format(p_id))\n",
    "                    counts['success'] += 1\n",
    "                except ValueError:\n",
    "                    print('Could not compute ET-MIp MAX covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "                        p_id, curr_etmip.original_aln.seq_length, curr_etmip.original_aln.size))\n",
    "                    counts['value'] += 1\n",
    "                    continue\n",
    "                except AttributeError:\n",
    "                    print('Could not compute ET-MIp MAX covariance for: {} no alignment'.format(p_id))\n",
    "                    counts['attribute'] += 1\n",
    "                    continue\n",
    "            if etmip_method_df is None:\n",
    "                etmip_method_df = protein_df\n",
    "            else:\n",
    "                etmip_method_df = etmip_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        etmip_method_df.to_csv(etmip_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = etmip_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(etmip_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCA##\n",
    "Scoring the the covariation of the proteins using a DCA julia implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DCAWrapper import DCAWrapper\n",
    "from utils import compute_rank_and_coverage\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    dca_out_dir = os.path.join(small_set_out_dir, 'DCA')\n",
    "    if not os.path.isdir(dca_out_dir):\n",
    "        os.makedirs(dca_out_dir)\n",
    "    dca_method_fn = os.path.join(dca_out_dir, 'DCA_Method_Data.csv')\n",
    "    if olarges.path.isfile(dca_method_fn):\n",
    "        dca_method_df = pd.read_csv(dca_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:\n",
    "        dca_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "        for p_id in generator.protein_data:\n",
    "            print('Attempting to calculate DCA covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(dca_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "            else:\n",
    "                try:\n",
    "                    curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id,\n",
    "                                            polymer_type='Protein')\n",
    "                    curr_aln.import_alignment()\n",
    "                    # Since the DCA implementation used here does not provide a way to specify the query sequence we remove the gaps\n",
    "                    # from the query sequences so positions will be referenced correctly for that sequence (and unnecessary\n",
    "                    # computations can be avoided).\n",
    "                    curr_aln = curr_aln.remove_gaps()\n",
    "                    new_aln_fn = os.path.join(protein_dir, '{}_no_gap.fasta'.format(p_id))\n",
    "                    curr_aln.write_out_alignment(new_aln_fn)\n",
    "                    curr_aln.file_name = new_aln_fn\n",
    "                    curr_dca = DCAWrapper(alignment=curr_aln)\n",
    "                    curr_dca.calculate_scores(out_dir=protein_dir, delete_file=False)\n",
    "                    # Compute statistics for the final scores of the ET-MIp model\n",
    "                    protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                        predictor=curr_dca, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                        unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=2, rank_type='max', file_prefix='DCA_Scores_', plots=True)\n",
    "                    # Score Prediction Clustering\n",
    "                    _, dca_coverage  = compute_rank_and_coverage(seq_length=curr_dca.alignment.seq_length, scores=curr_dca.scores, pos_size=2,\n",
    "                        rank_type='max')\n",
    "                    z_score_fn = os.path.join(protein_dir, 'DCA_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                    z_score_plot_fn = os.path.join(protein_dir, 'DCA_Scores_Dist-Any_{}_ZScores.png')\n",
    "                    z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - dca_coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                    biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                    protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                    plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                    z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - dca_coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                    unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                    protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                    plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                    # Record execution times\n",
    "                    protein_df['Init Time'] = None\n",
    "                    protein_df['Import Time'] = None\n",
    "                    protein_df['Dist Tree Time'] = None\n",
    "                    protein_df['Trace Time'] = None\n",
    "                    protein_df['Total Time'] = None\n",
    "                    # Record static data for this protein\n",
    "                    protein_df['Protein'] = p_id\n",
    "                    protein_df['Method'] = 'DCA'\n",
    "                    protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                    protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                    print('Successfully computed DCA covariance for: {}'.format(p_id))\n",
    "                    counts['success'] += 1\n",
    "                except ValueError:\n",
    "                    print('Could not compute DCA covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "                        p_id, curr_aln.seq_length, curr_aln.size))\n",
    "                    counts['value'] += 1\n",
    "                    continue\n",
    "                except AttributeError:\n",
    "                    print('Could not compute DCA covariance for: {} no alignment'.format(p_id))\n",
    "                    counts['attribute'] += 1\n",
    "                    continue\n",
    "            if dca_method_df is None:\n",
    "                dca_method_df = protein_df\n",
    "            else:\n",
    "                dca_method_df = dca_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        dca_method_df.to_csv(dca_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = dca_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(dca_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVCouplings##\n",
    "Scoring the the covariation of the proteins using the EVCouplings method standard protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EVCouplingsWrapper import EVCouplingsWrapper\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    evc_standard_out_dir = os.path.join(small_set_out_dir, 'EVCouplings_Standard')\n",
    "    if not os.path.isdir(evc_standard_out_dir):\n",
    "        os.makedirs(evc_standard_out_dir)\n",
    "    evc_standard_method_fn = os.path.join(evc_standard_out_dir, 'EVCouplings_Standard_Method_Data.csv')\n",
    "    if os.path.isfile(evc_standard_method_fn):\n",
    "        evc_standard_method_df = pd.read_csv(evc_standard_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:\n",
    "        evc_standard_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "        for p_id in generator.protein_data:\n",
    "            print('Attempting to calculate EV couplings standard protocol covariance for: {}'.format(p_id))\n",
    "            protein_dir = os.path.join(evc_standard_out_dir, p_id)\n",
    "            if not os.path.isdir(protein_dir):\n",
    "                os.makedirs(protein_dir)\n",
    "            protein_fn = os.path.join(protein_dir, '{}_Protein_Data.csv'.format(p_id))\n",
    "            if os.path.isfile(protein_fn):\n",
    "                protein_df = pd.read_csv(protein_fn, sep='\\t', header=0, index_col=False)\n",
    "            else:\n",
    "                try:\n",
    "                    curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id,\n",
    "                                            polymer_type='Protein')\n",
    "                    curr_aln.import_alignment()\n",
    "                    curr_evc = EVCouplingsWrapper(alignment=curr_aln, protocol='standard')\n",
    "                                curr_evc.calculate_scores(out_dir=protein_dir, cores=10, delete_files=True)\n",
    "                    # Compute statistics for the final scores of the ET-MIp model\n",
    "                    protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                        predictor=curr_evc, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                        unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=2,\n",
    "                        rank_type='max', file_prefix='EVC_Standard_Scores_', plots=True)\n",
    "                    # Score Prediction Clustering\n",
    "                    _, evc_standard_coverage  = compute_rank_and_coverage(seq_length=curr_evc.alignment.seq_length, scores=curr_evc.scores, pos_size=2,\n",
    "                        rank_type='max')\n",
    "                    z_score_fn = os.path.join(protein_dir, 'EVC_Standard_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                    z_score_plot_fn = os.path.join(protein_dir, 'EVC_Standard_Scores_Dist-Any_{}_ZScores.png')\n",
    "                    z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - evc_standard_coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                    biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                    protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                    plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                    z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                        1.0 - evc_standard_coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                        w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                    if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                    unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                    protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                    protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                    protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                    protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                    plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                    # Record execution times\n",
    "                    protein_df['Init Time'] = None\n",
    "                    protein_df['Import Time'] = None\n",
    "                    protein_df['Dist Tree Time'] = None\n",
    "                    protein_df['Trace Time'] = None\n",
    "                    protein_df['Total Time'] = None\n",
    "                    # Record static data for this protein\n",
    "                    protein_df['Protein'] = p_id\n",
    "                    protein_df['Method'] = 'EVC Standard'\n",
    "                    protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                    protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                    print('Successfully computed EV couplings standard protocol covariance for: {}'.format(p_id))\n",
    "                    counts['success'] += 1\n",
    "                except ValueError:\n",
    "                    print('Could not compute EV couplings standard protocol covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "                        p_id, curr_aln.seq_length, curr_aln.size))\n",
    "                    counts['value'] += 1\n",
    "                    continue\n",
    "                except AttributeError:\n",
    "                    print('Could not compute EV couplings standard protocol covariance for: {} no alignment'.format(p_id))\n",
    "                    counts['attribute'] += 1\n",
    "                    continue\n",
    "            if evc_standard_method_df is None:\n",
    "                evc_standard_method_df = protein_df\n",
    "            else:\n",
    "                evc_standard_method_df = evc_standard_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        evc_standard_method_df.to_csv(evc_standard_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = evc_standard_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(evc_standard_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring the covariation of the proteins using the EVCouplings method mean field protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(small_comparison_fn):\n",
    "    evc_mf_out_dir = os.path.join(small_set_out_dir, 'EVCouplings_Mean_Field')\n",
    "    if not os.path.isdir(evc_mf_out_dir):\n",
    "        os.makedirs(evc_mf_out_dir)\n",
    "    evc_mf_method_fn = os.path.join(evc_mf_out_dir, 'EVCouplings_Mean_Field_Method_Data.csv')\n",
    "    if os.path.isfile(evc_mf_method_fn):\n",
    "        evc_mf_method_df = pd.read_csv(evc_mf_method_fn, sep='\\t', header=0, index_col=False)\n",
    "    else:\n",
    "        evc_mf_method_df = None\n",
    "        counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "        for p_id in generator.protein_data:\n",
    "            print('Attempting to calculate EV couplings covariance for: {}'.format(p_id))\n",
    "            try:\n",
    "                protein_dir = os.path.join(evc_mf_out_dir, p_id)\n",
    "                if not os.path.isdir(protein_dir):\n",
    "                    os.makedirs(protein_dir)\n",
    "                curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id,\n",
    "                                        polymer_type='Protein')\n",
    "                curr_aln.import_alignment()\n",
    "                curr_evc = EVCouplingsWrapper(alignment=curr_aln, protocol='mean_field')\n",
    "                curr_evc.calculate_scores(out_dir=protein_dir, cores=10, delete_files=True)\n",
    "                # Compute statistics for the final scores of the ET-MIp model\n",
    "                protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "                    predictor=curr_evc, verbosity=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "                    unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=2, rank_type='max',\n",
    "                    file_prefix='EVC_Standard_Scores_', plots=True)\n",
    "                # Score Prediction Clustering\n",
    "                _, evc_mf_coverage  = compute_rank_and_coverage(seq_length=curr_evc.alignment.seq_length, scores=curr_evc.scores, pos_size=2,\n",
    "                    rank_type='max')\n",
    "                z_score_fn = os.path.join(protein_dir, 'EVC_Mean_Field_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "                z_score_plot_fn = os.path.join(protein_dir, 'EVC_Mean_Field_Scores_Dist-Any_{}_ZScores.png')\n",
    "                z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                    1.0 - evc_mf_coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "                    w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "                if protein_scorers[p_id]['biased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['biased_w2_ave'] = biased_w2_ave\n",
    "                biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "                protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "                plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "                z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "                    1.0 - evc_mf_coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "                    w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "                if protein_scorers[p_id]['unbiased_w2_ave'] is None:\n",
    "                        protein_scorers[p_id]['unbiased_w2_ave'] = unbiased_w2_ave\n",
    "                unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "                protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "                protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "                protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "                plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "                # Record execution times\n",
    "                protein_df['Init Time'] = None\n",
    "                protein_df['Import Time'] = None\n",
    "                protein_df['Dist Tree Time'] = None\n",
    "                protein_df['Trace Time'] = None\n",
    "                protein_df['Total Time'] = None\n",
    "                # Record static data for this protein\n",
    "                protein_df['Protein'] = p_id\n",
    "                protein_df['Method'] = 'EVC Mean Field'\n",
    "                protein_df['Alignment Size'] = summary['Filtered_Alignment'].values[summary['Protein_ID'] == p_id][0]\n",
    "                protein_df.to_csv(protein_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "                print('Successfully computed EV couplings covariance for: {}'.format(p_id))\n",
    "                counts['success'] += 1\n",
    "            except ValueError:\n",
    "                print('Could not compute EV couplings covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "                    p_id, curr_aln.seq_length, curr_aln.size))\n",
    "                counts['value'] += 1\n",
    "                continue\n",
    "            except AttributeError:\n",
    "                print('Could not compute EV couplings covariance for: {} no alignment'.format(p_id))\n",
    "                counts['attribute'] += 1\n",
    "                continue\n",
    "            if evc_mf_method_df is None:\n",
    "                evc_mf_method_df = protein_df\n",
    "            else:\n",
    "                evc_mf_method_df = evc_mf_method_df.append(protein_df)\n",
    "        print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                             counts['attribute']))\n",
    "        evc_mf_method_df.to_csv(evc_mf_method_fn, sep='\\t', header=True, index=False, columns=output_columns)\n",
    "    if small_comparison_df is None:\n",
    "        small_comparison_df = evc_mf_method_df\n",
    "    else:\n",
    "        small_comparison_df = small_comparison_df.append(evc_mf_method_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out final comparison data so it can be loaded later for generating figures.\n",
    "if not os.path.isfile(small_comparison_fn):\n",
    "    small_comparison_df['Protein Length'] = small_comparison_df['Protein'].apply(lambda x: generator.protein_data[x]['Length'])\n",
    "    small_comparison_df.to_csv(small_comparison_fn, sep='\\t', header=True, index=False, columns=output_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Execution Time for ET-MIp and cET-MIp\n",
    "The time to compute the trace for the full phylogenetic tree and the trace constrained to a subset of the top levels should take significantly less time to compute, here we evaluate if that is in fact the case or not.\n",
    "\n",
    "## Data Cleaning\n",
    "At least one protein in this data set has a very small alignment and could not be evaluated by cET-MIp because the tree was too small to each the levels set for other proteins. Here we remove those proteins.\n",
    "\n",
    "In addition since this analysis focuses on times and there are many other types of data (some of which cause redundancies in the time data), we will use this opportunity to subset the data and drop duplicates.\n",
    "\n",
    "Finally, for some it will be more informative to view execution time in terms of minutes or hours, as opposed to the originally reported seconds, so we will add columns for these units as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_method_groups = small_comparison_df[['Protein', 'Method']].drop_duplicates().groupby('Protein').count()\n",
    "method_max = protein_method_groups['Method'].max()\n",
    "proteins_to_keep = protein_method_groups.index[protein_method_groups['Method'] == method_max]\n",
    "comparable_method_proteins = small_comparison_df[small_comparison_df['Protein'].isin(proteins_to_keep)]\n",
    "time_columns = ['Protein', 'Protein Length', 'Alignment Size', 'Method', 'Init Time', 'Import Time', 'Dist Tree Time',\n",
    "                'Trace Time', 'Total Time']\n",
    "time_subset_df = comparable_method_proteins.loc[comparable_method_proteins['Method'].isin(['ET-MIp', 'cET-MIp']), time_columns]\n",
    "time_subset_df['Total Time (min)'] = time_subset_df['Total Time'].apply(lambda x: x / 60.0)\n",
    "time_subset_df['Total Time (hr)'] = time_subset_df['Total Time (min)'].apply(lambda x: x / 60.0)\n",
    "time_columns += ['Total Time (min)', 'Total Time (hr)']\n",
    "time_subset_df = time_subset_df.drop_duplicates(subset=None, inplace=False, keep='first')\n",
    "time_subset_df.to_csv(os.path.join(small_set_out_dir, 'Small_Time_Comaprison_Data.csv'), sep='\\t', header=True, index=False,\n",
    "                      columns=time_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Comparison\n",
    "Now that only comparable proteins are present in the data we compare the runtime of individual proteins by method, ordered by their length and the size of their alignemnts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Displayed by protein length order\n",
    "protein_length_order = comparable_method_proteins.sort_values('Protein Length')['Protein'].unique()\n",
    "protein_length_time_plot = sns.barplot(x='Protein', y='Total Time', hue='Method', order=protein_length_order,\n",
    "                                       hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_length_time_plot.set_xticklabels(protein_length_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_length_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Length_Time_Comparison_Sec.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "protein_length_time_plot = sns.barplot(x='Protein', y='Total Time (min)', hue='Method', order=protein_length_order,\n",
    "                                       hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_length_time_plot.set_xticklabels(protein_length_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_length_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Length_Time_Comparison_Min.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "protein_length_time_plot = sns.barplot(x='Protein', y='Total Time (hr)', hue='Method', order=protein_length_order,\n",
    "                                       hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_length_time_plot.set_xticklabels(protein_length_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_length_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Length_Time_Comparison_Hr.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Displayed by alignment size order\n",
    "protein_alignment_order = comparable_method_proteins.sort_values('Alignment Size')['Protein'].unique()\n",
    "protein_alignment_time_plot = sns.barplot(x='Protein', y='Total Time', hue='Method', order=protein_alignment_order,\n",
    "                                          hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_alignment_time_plot.set_xticklabels(protein_alignment_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_alignment_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Alignment_Time_Comparison_Sec.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "protein_alignment_time_plot = sns.barplot(x='Protein', y='Total Time (min)', hue='Method', order=protein_alignment_order,\n",
    "                                          hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_alignment_time_plot.set_xticklabels(protein_alignment_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_alignment_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Alignment_Time_Comparison_Min.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "protein_alignment_time_plot = sns.barplot(x='Protein', y='Total Time (hr)', hue='Method', order=protein_alignment_order,\n",
    "                                          hue_order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_alignment_time_plot.set_xticklabels(protein_alignment_time_plot.get_xticklabels(), rotation=90)\n",
    "protein_alignment_time_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Alignment_Time_Comparison_Hr.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall comparison of time by method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of ET-MIp and cET-MIp total computation time (sec).\n",
    "protein_method_comp_plot = sns.boxplot(x='Method', y='Total Time', order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_method_comp_plot.set_xticklabels(protein_method_comp_plot.get_xticklabels(), rotation=90)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_Time_Comparison_Sec.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Comparison of ET-MIp and cET-MIp total computation time (sec).\n",
    "protein_method_comp_plot = sns.boxplot(x='Method', y='Total Time (min)', order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_method_comp_plot.set_xticklabels(protein_method_comp_plot.get_xticklabels(), rotation=90)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_Time_Comparison_Min.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Comparison of ET-MIp and cET-MIp total computation time (sec).\n",
    "protein_method_comp_plot = sns.boxplot(x='Method', y='Total Time (hr)', order=['ET-MIp', 'cET-MIp'], data=time_subset_df)\n",
    "protein_method_comp_plot.set_xticklabels(protein_method_comp_plot.get_xticklabels(), rotation=90)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_Time_Comparison_Hr.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Statistical comparison\n",
    "from scipy.stats import wilcoxon\n",
    "et_mip_sub_df = time_subset_df[time_subset_df['Method'] == 'ET-MIp']\n",
    "cet_mip_sub_df = time_subset_df[time_subset_df['Method'] == 'cET-MIp']\n",
    "sec_stat, sec_p_val = wilcoxon(x=et_mip_sub_df['Total Time'], y=cet_mip_sub_df['Total Time'], zero_method='wilcox')\n",
    "min_stat, min_p_val = wilcoxon(x=et_mip_sub_df['Total Time (min)'], y=cet_mip_sub_df['Total Time (min)'], zero_method='wilcox')\n",
    "hr_stat, hr_p_val = wilcoxon(x=et_mip_sub_df['Total Time (hr)'], y=cet_mip_sub_df['Total Time (hr)'], zero_method='wilcox')\n",
    "time_statistics = {'Time Unit': ['sec', 'min', 'hr'], 'Statistic': [sec_stat, min_stat, hr_stat], 'P-Value': [sec_p_val, min_p_val, hr_p_val]}\n",
    "pd.DataFrame(time_statistics).to_csv(os.path.join(small_set_out_dir, 'Small_Time_Comaprison_Statistics.csv'), sep='\\t', header=True,\n",
    "                                     index=False, columns=['Time Unit', 'Statistic', 'P-Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method Comparison\n",
    "We now begin comparing methods based on their ability to predict the structural contacts in the proteins in this test set. There is an important consideration in the case of sequence separation and different measures by which to compare the methods.\n",
    "\n",
    "### Data Cleaning\n",
    "These data need an additional cleaning step beyond what was performed for the timing comparison. Since there are multiple categories of sequence separation and some proteins may not have any True Positive contacts for a category the scoring for that protein is incomplete. We will remove all such proteins from the comparison, performing the clean up separate for each metric of success. Another contributing factor which necessitates this kind of cleaning is assessment of the top K predictions for a protein or best L/K predictions which for poor predictions may not include any predictions of True Positives.\n",
    "\n",
    "### Sequence Separation\n",
    "One important consideration for the difficulty of prediction and interest in predictions is the distance between the residues for which coupling was predicted. As has been documented in the literature, especially in the CASP competitions, there are several categories of prediction:\n",
    "* Neighbors (1 - 5 residues apart) - This is the least interesting category of predictions. It is highly likely that residues this close together will show covariance signal. Predicting two residues are in contact that are this close together is trivial and uninformative.\n",
    "* Short (6 - 12 residues apart) - This is also not a very interesting type of prediction. Residues this close in proximity can be more easily modeled by alogrithms which focus on 2D protein structure modeling (identifying beta sheets, alpha helices, etc.).\n",
    "* Medium (13 - 24 residues apart) - This is a more interesting type of prediction. The resiudes in this range of separation are on the edge of the 2D protein structure prediction range.\n",
    "* Long (24 and more residues apart) - The most interesting category of predictions. Resiudes this far apart are not easily modeled by 2D protein structure modeling systems. They are also very useful for 3D and 4D protein structure prediction becausae they provide constraints on potential protein (similar to NMR data) folds which makes protein folding a more tractable problem for modelers.\n",
    "* Any/All - All categories can be considered at once, this provides a summary value, but is often skewed by one particularly good category of predictions.\n",
    "\n",
    "### Metrics of Success\n",
    "* AUROC - This measures the True Positive Rate vs the False Positive Rate of prediction, it can be considered a measure of the accuracy of the measure. This can be strongly influenced by the class imbalance which is present when predicting structural contacts since there are many fewer contacts than non-contacts. The True Positive case is if the C-beta of two amino acids is within 8.0 Angstroms of one another (as is done in the CASP competitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_order = ['DCA', 'EVC Standard', 'EVC Mean Field', 'ET-MIp', 'cET-MIp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_columns = ['Protein', 'Method', 'Sequence_Separation', 'AUROC']\n",
    "protein_auroc_groups = comparable_method_proteins[auroc_columns].drop_duplicates().groupby('Protein')['AUROC'].apply(\n",
    "    lambda x: not x.isnull().any())\n",
    "complete_proteins = protein_auroc_groups.index[protein_auroc_groups.values]\n",
    "comparable_auroc_proteins = small_comparison_df[small_comparison_df['Protein'].isin(complete_proteins)]\n",
    "auroc_protein_length_order = [x for x in protein_length_order if x in complete_proteins]\n",
    "auroc_protein_alignment_order = [x for x in protein_alignment_order if x in complete_proteins]\n",
    "auroc_subset_df = comparable_auroc_proteins.loc[:, auroc_columns].drop_duplicates()\n",
    "# Plot the methods vs AUROC per protein ordered by protein length\n",
    "auroc_subset_df.to_csv(os.path.join(small_set_out_dir, 'Small_AUROC_Comaprison_Data.csv'), sep='\\t', header=True, index=False,\n",
    "                       columns=auroc_columns)\n",
    "protein_order_auroc_plot = sns.catplot(x=\"Protein\", y=\"AUROC\", hue=\"Method\", row=\"Sequence_Separation\", data=auroc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auroc_protein_length_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "protein_order_auroc_plot.set_xticklabels(auroc_protein_length_order, rotation=90)\n",
    "protein_order_auroc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUROC_Comparison_Protein_Length_Order.png'),\n",
    "                                 bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUROC per protein ordered by protein alignment size\n",
    "alignment_order_auroc_plot = sns.catplot(x=\"Protein\", y=\"AUROC\", hue=\"Method\", row=\"Sequence_Separation\", data=auroc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auroc_protein_alignment_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "alignment_order_auroc_plot.set_xticklabels(auroc_protein_alignment_order, rotation=90)\n",
    "alignment_order_auroc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUROC_Comparison_Alignment_Size_Order.png'),\n",
    "                                   bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUROC grouped together to see overall trends\n",
    "overall_auroc_plot = sns.boxplot(x=\"Sequence_Separation\", y=\"AUROC\", hue=\"Method\", data=auroc_subset_df,\n",
    "                                 order=sequence_separation_order, hue_order=method_order)\n",
    "overall_auroc_plot.set_xticklabels(sequence_separation_order, rotation=90)\n",
    "overall_auroc_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUROC_Comparison.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Compute statistics comparing methods at each sequence separation\n",
    "auroc_statistics = {'Sequence Separation': [], 'Method 1': [], 'Method 2': [], 'Statistic': [], 'P-Value': []}\n",
    "for sep in sequence_separation_order:\n",
    "    sep_auroc_subset_df = auroc_subset_df.loc[auroc_subset_df['Sequence_Separation'] == sep, :]\n",
    "    for i in range(len(method_order)):\n",
    "        m1_sep_auroc_subset_df = sep_auroc_subset_df.loc[sep_auroc_subset_df['Method'] == method_order[i], :]\n",
    "        for j in range(i + 1, len(method_order)):\n",
    "            m2_sep_auroc_subset_df = sep_auroc_subset_df.loc[sep_auroc_subset_df['Method'] == method_order[j], :]\n",
    "            stat, p_val = wilcoxon(x=m1_sep_auroc_subset_df['AUROC'], y=m2_sep_auroc_subset_df['AUROC'], zero_method='wilcox')\n",
    "            auroc_statistics['Sequence Separation'].append(sep)\n",
    "            auroc_statistics['Method 1'].append(method_order[i])\n",
    "            auroc_statistics['Method 2'].append(method_order[j])\n",
    "            auroc_statistics['Statistic'].append(stat)\n",
    "            auroc_statistics['P-Value'].append(p_val)\n",
    "pd.DataFrame(auroc_statistics).to_csv(os.path.join(small_set_out_dir, 'Small_AUROC_Comaprison_Statistics.csv'), sep='\\t', header=True,\n",
    "                                      index=False, columns=['Sequence Separation', 'Method 1', 'Method 2', 'Statistic', 'P-Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics of Success (Continued)\n",
    "* AUPRC - This measures the Precision vs the Recall of the predictions, it can be considered a measure of the accuracy of the measure. This is less strongly influenced by the class imbalance which is present when predicting structural contacts since there are many fewer contacts than non-contacts. The True Positive case is if the C-beta of two amino acids is within 8.0 Angstroms of one another (as is done in the CASP competitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "auprc_columns = ['Protein', 'Method', 'Sequence_Separation', 'AUPRC']\n",
    "protein_auprc_groups = comparable_method_proteins[auprc_columns].drop_duplicates().groupby('Protein')['AUPRC'].apply(\n",
    "    lambda x: not x.isnull().any())\n",
    "complete_proteins = protein_auprc_groups.index[protein_auprc_groups.values]\n",
    "comparable_auprc_proteins = small_comparison_df[small_comparison_df['Protein'].isin(complete_proteins)]\n",
    "auprc_protein_length_order = [x for x in protein_length_order if x in complete_proteins]\n",
    "auprc_protein_alignment_order = [x for x in protein_alignment_order if x in complete_proteins]\n",
    "auprc_subset_df = comparable_auprc_proteins.loc[:, auprc_columns].drop_duplicates()\n",
    "# Plot the methods vs AUPRC per protein ordered by protein length\n",
    "auprc_subset_df.to_csv(os.path.join(small_set_out_dir, 'Small_AUPRC_Comaprison_Data.csv'), sep='\\t', header=True, index=False,\n",
    "                       columns=auprc_columns)\n",
    "protein_order_auprc_plot = sns.catplot(x=\"Protein\", y=\"AUPRC\", hue=\"Method\", row=\"Sequence_Separation\", data=auprc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auprc_protein_length_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "protein_order_auprc_plot.set_xticklabels(auprc_protein_length_order, rotation=90)\n",
    "protein_order_auprc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUPRC_Comparison_Protein_Length_Order.png'),\n",
    "                                 bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUPRC per protein ordered by protein alignment size\n",
    "alignment_order_auprc_plot = sns.catplot(x=\"Protein\", y=\"AUPRC\", hue=\"Method\", row=\"Sequence_Separation\", data=auprc_subset_df, kind=\"bar\",\n",
    "                                       ci=None, order=auprc_protein_alignment_order, hue_order=method_order, legend=True, legend_out=True)\n",
    "alignment_order_auprc_plot.set_xticklabels(auprc_protein_alignment_order, rotation=90)\n",
    "alignment_order_auprc_plot.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUPRC_Comparison_Alignment_Size_Order.png'),\n",
    "                                   bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Plot the methods vs AUPRC grouped together to see overall trends\n",
    "overall_auprc_plot = sns.boxplot(x=\"Sequence_Separation\", y=\"AUPRC\", hue=\"Method\", data=auprc_subset_df,\n",
    "                                 order=sequence_separation_order, hue_order=method_order)\n",
    "overall_auprc_plot.set_xticklabels(sequence_separation_order, rotation=90)\n",
    "overall_auprc_plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(small_set_out_dir, 'Protein_Method_AUPRC_Comparison.png'), bbox_inches='tight', transparent=True, dpi=300)\n",
    "plt.close()\n",
    "# Compute statistics comparing methods at each sequence separation\n",
    "auprc_statistics = {'Sequence Separation': [], 'Method 1': [], 'Method 2': [], 'Statistic': [], 'P-Value': []}\n",
    "for sep in sequence_separation_order:\n",
    "    sep_auprc_subset_df = auprc_subset_df.loc[auprc_subset_df['Sequence_Separation'] == sep, :]\n",
    "    for i in range(len(method_order)):\n",
    "        m1_sep_auprc_subset_df = sep_auprc_subset_df.loc[sep_auprc_subset_df['Method'] == method_order[i], :]\n",
    "        for j in range(i + 1, len(method_order)):\n",
    "            m2_sep_auprc_subset_df = sep_auprc_subset_df.loc[sep_auprc_subset_df['Method'] == method_order[j], :]\n",
    "            stat, p_val = wilcoxon(x=m1_sep_auprc_subset_df['AUPRC'], y=m2_sep_auprc_subset_df['AUPRC'], zero_method='wilcox')\n",
    "            auprc_statistics['Sequence Separation'].append(sep)\n",
    "            auprc_statistics['Method 1'].append(method_order[i])\n",
    "            auprc_statistics['Method 2'].append(method_order[j])\n",
    "            auprc_statistics['Statistic'].append(stat)\n",
    "            auprc_statistics['P-Value'].append(p_val)\n",
    "pd.DataFrame(auprc_statistics).to_csv(os.path.join(small_set_out_dir, 'Small_AUPRC_Comaprison_Statistics.csv'), sep='\\t', header=True,\n",
    "                                      index=False, columns=['Sequence Separation', 'Method 1', 'Method 2', 'Statistic', 'P-Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Precision at K - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Recall at K - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* F1 at K - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Structural Cluster Weighting Z-Score - "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (PyET3)",
   "language": "python",
   "name": "pyet3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
