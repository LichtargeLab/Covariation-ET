{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Test Set #\n",
    "## Goal ##\n",
    "The goal of this test set is to perform proof of concept testing on a small number of proteins with a wide range of sizes and available homologs, orthologs, and paralogs. By doing so it should be possible to test the best parameterization for this tool as well as identifying the strengths and weaknesses of the tool using various measurments as end points.\n",
    "## Warning ##\n",
    "Before attempting to use this notebook make sure that your .env file has been properly setup to reflect the correct locations of command line tools and the location of files and directories needed for execution.\n",
    "### Initial Import###\n",
    "This first cell performs the necessary imports required to begin this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "try:\n",
    "    dotenv_path = find_dotenv(raise_error_if_not_found=True)\n",
    "except IOError:\n",
    "    dotenv_path = find_dotenv(raise_error_if_not_found=True, usecwd=True)\n",
    "load_dotenv(dotenv_path)\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ.get('PROJECT_PATH'), 'src'))\n",
    "sys.path.append(os.path.join(os.environ.get('PROJECT_PATH'), 'src', 'SupportingClasses'))\n",
    "input_dir = os.environ.get('INPUT_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set Construction ##\n",
    "The first task required to test the data set is to download the required data and construct any necessary input files for all down stream analyses.\n",
    "In this case that means:\n",
    "* Downloading PDB files for the proteins in our small test set.\n",
    "* Extracting a query sequence from each PDB file.\n",
    "* Searching for paralogs, homologs, and orthologs in a custom BLAST database built by filtering the Uniref90 database.\n",
    "* Filtering the hits from the BLAST search to meet minimum and maximum length requirements, as well as minimum and maximum identity requirements.\n",
    "* Building alignments using CLUSTALW in both the fasta and msf formats since some of the tools which will be used for comparison need different formats.\n",
    "* Filtering the alignment for maximum identity similarity between seqeunces.\n",
    "* Re-aligning the filtered sequences using CLUSTALW.\n",
    "This is all handeled by the DataSetGenerator class found in the src/SupportingClasses folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing protein list\n",
      "Downloading structures and parsing in query sequences\n",
      "Unique Sequences Found: 23!\n",
      "BLASTing query sequences\n",
      "Filtering BLAST hits, aligning, filtering by identity, and re-aligning\n",
      "   Protein_ID     Accession  BLAST_Hits  Filtered_BLAST  Filtered_Alignment  \\\n",
      "18       2b59    CIPA_CLOTM        1606               4                   4   \n",
      "7        206l      LYS_BPT4        1039             131                  92   \n",
      "16       1c0k    OXDA_RHOTO        2500              51                  51   \n",
      "13       1bol    RNRH_RHINI        2500             131                 127   \n",
      "17       7hvp     POL_HV1A2        2500              33                  33   \n",
      "12       1c17    ATPL_ECOLI        1671             850                 813   \n",
      "2        1jwl    LACI_ECOLI        2500             228                 226   \n",
      "1        3q05     P53_HUMAN         932             306                 210   \n",
      "8        135l    LYSC_MELGA        1913             853                 818   \n",
      "4        2z0e   ATG4B_HUMAN        2111             360                 344   \n",
      "10       2rh1   ADRB2_HUMAN        2500             416                 399   \n",
      "9        1a26   PARP1_CHICK        2500             267                 261   \n",
      "22       3b6v   KIF3C_HUMAN        2500             481                 441   \n",
      "3        1h1v    GELS_HUMAN        2500             654                 599   \n",
      "20       2ysd   MAGI1_HUMAN        2500             412                 318   \n",
      "6        1hck    CDK2_HUMAN        2500            2468                1681   \n",
      "14       1axb    BLAT_ECOLI        2500            2102                2087   \n",
      "0        4lli   MYO5A_HUMAN        2500             441                 352   \n",
      "19       3tnu   K1C14_HUMAN        2500            1681                1518   \n",
      "5        2zxe  Q4H132_SQUAC        2500             880                 795   \n",
      "15       2wer   HSP82_YEAST        2500            1327                1207   \n",
      "21       4ycu     SYK_HUMAN        2500            2421                2347   \n",
      "11       2iop    HTPG_ECOLI        2500            2478                2472   \n",
      "\n",
      "    Length  Total_Size  \n",
      "18    1853      7412.0  \n",
      "7      164     15088.0  \n",
      "16     368     18768.0  \n",
      "13     238     30226.0  \n",
      "17    1437     47421.0  \n",
      "12      79     64227.0  \n",
      "2      360     81360.0  \n",
      "1      393     82530.0  \n",
      "8      147    120246.0  \n",
      "4      393    135192.0  \n",
      "10     413    164787.0  \n",
      "9     1011    263871.0  \n",
      "22     793    349713.0  \n",
      "3      782    468418.0  \n",
      "20    1491    474138.0  \n",
      "6      298    500938.0  \n",
      "14     286    596882.0  \n",
      "0     1855    652960.0  \n",
      "19     472    716496.0  \n",
      "5     1028    817260.0  \n",
      "15     709    855763.0  \n",
      "21     597   1401159.0  \n",
      "11     624   1542528.0  \n",
      "It took 0.14518646796544393 min to generate the data set.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from DataSetGenerator import DataSetGenerator\n",
    "protein_list_dir = os.path.join(input_dir, 'ProteinLists')\n",
    "if not os.path.isdir(protein_list_dir):\n",
    "    os.makedirs(protein_list_dir)\n",
    "small_list_fn = os.path.join(protein_list_dir, 'SmallDataSet.txt')\n",
    "if not os.path.isfile(small_list_fn):\n",
    "    proteins_of_interest = ['2ysdA', '1c17A', '3tnuA', '7hvpA', '135lA', '206lA', '2werA', '1bolA', '3q05A', '1axbA',\n",
    "                            '2rh1A', '1hckA', '3b6vA', '2z0eA', '1jwlA', '1a26A', '1c0kA', '4lliA', '4ycuA', '2iopA',\n",
    "                            '2zxeA', '2b59B', '1h1vG']\n",
    "    with open(small_list_fn, 'w') as small_list_handle:\n",
    "        for p_id in proteins_of_interest:\n",
    "            small_list_handle.write('{}\\n'.format(p_id))\n",
    "generator = DataSetGenerator(input_dir)\n",
    "start = time()\n",
    "summary = generator.build_pdb_alignment_dataset(protein_list_fn=os.path.basename(small_list_fn), num_threads=10,\n",
    "                                                database='customuniref90.fasta', max_target_seqs=2500, remote=False,\n",
    "                                                verbose=False)\n",
    "summary['Accession'] = summary['Protein_ID'].apply(lambda x: generator.protein_data[x]['Accession'])\n",
    "summary['Length'] = summary['Protein_ID'].apply(lambda x: generator.protein_data[x]['Length'])\n",
    "summary['Total_Size'] = summary.apply(lambda x: float(x['Length']) * float(x['Filtered_Alignment']), axis=1)\n",
    "summary.sort_values(by=['Filtered_Alignment', 'Length'], axis=0, inplace=True)\n",
    "summary_columns = ['Protein_ID', 'Accession', 'BLAST_Hits', 'Filtered_BLAST', 'Filtered_Alignment', 'Length',\n",
    "                   'Total_Size']\n",
    "print(summary[summary_columns])\n",
    "end = time()\n",
    "print('It took {} min to generate the data set.'.format((end - start) / 60.0))\n",
    "summary.to_csv(os.path.join(input_dir, 'small_data_set_summary.tsv'), sep='\\t', index=False, header=True,\n",
    "               columns=summary_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a location to store the output of this method comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.environ.get('OUTPUT_PATH')\n",
    "small_set_out_dir = os.path.join(output_dir, 'SmallTestSet')\n",
    "if not os.path.isdir(small_set_out_dir):\n",
    "    os.makedirs(small_set_out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Scoring For Each Method\n",
    "To reduce memory load during prediction and evaluation, the scoring objects needed to compute the metrics used to compare methods will be created ahead of time so they are available to each method when it computes its predictions for a given protein. This will ensure that results do not need to be kept in memory while waiting for all other results to be computed, only the metrics measured for each method will be recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SeqAlignment import SeqAlignment\n",
    "from PDBReference import PDBReference\n",
    "from ContactScorer import ContactScorer, plot_z_scores\n",
    "protein_order = list(summary['Protein_ID'])\n",
    "method_order = ['DCA', 'EV Couplings', 'EV Couplings MF', 'ET-MIp', 'cET-MIp']\n",
    "sequence_separation_order = ['Any', 'Neighbors', 'Short', 'Medium', 'Long']\n",
    "protein_scorers = {}\n",
    "for p_id in summary['Protein_ID']:\n",
    "    protein_scorers[p_id] = {}\n",
    "    # Import alignment and remove gaps\n",
    "    full_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id)\n",
    "    full_aln.import_alignment()\n",
    "    non_gap_aln = full_aln.remove_gaps()\n",
    "    # Import structure\n",
    "    pdb_structure = PDBReference(pdb_file=generator.protein_data[p_id]['PDB'])\n",
    "    pdb_structure.import_pdb(structure_id=p_id)\n",
    "    protein_scorers[p_id]['Structure'] = pdb_structure\n",
    "    # Initialize Beta Carbon distance scorer\n",
    "    contact_scorer_cb = ContactScorer(query=p_id, seq_alignment=non_gap_aln,\n",
    "                                      pdb_reference=pdb_structure, cutoff=8.0)\n",
    "    contact_scorer_cb.best_chain = generator.protein_data[p_id]['Chain']\n",
    "    contact_scorer_cb.fit()\n",
    "    contact_scorer_cb.measure_distance(method='CB')\n",
    "    protein_scorers[p_id]['Scorer_CB'] = contatct_scorer_cb\n",
    "    # Initialize distance scorer minimizing distance between any atoms\n",
    "    contact_scorer_any = ContactScorer(query=p_id, seq_alignment=non_gap_aln,\n",
    "                                       pdb_reference=pdb_structure, cutoff=8.0)\n",
    "    contact_scorer_any.best_chain = generator.protein_data[p_id]['Chain']\n",
    "    contact_scorer_any.fit()\n",
    "    contact_scorer_any.measure_distance(method='Any')\n",
    "    protein_scorers[p_id]['Scorer_Any'] = contatct_scorer_any\n",
    "    # Initialize z-scoring subproblems\n",
    "    protein_scorers[p_id]['biased_w2_ave'] = None\n",
    "    protein_scorers[p_id]['unbiased_w2_ave'] = None\n",
    "output_columns = ['Protein', 'Alignment Size', 'Method', 'Distance', 'Init Time', 'Import Time', 'Dist Tree Time', 'Trace Time', 'Total Time', \n",
    "                  'Sequence_Separation', 'AUROC', 'AUPRC', 'AUTPRFDRC',\n",
    "                  'Top K Predictions', 'Precision', 'Recall', 'F1 Score',\n",
    "                  'Top 10% Biased Z-Score', 'Top 20% Biased Z-Score', 'Top 30% Biased Z-Score', 'Max Biased Z-Score', 'AUC Biased Z-Score',\n",
    "                  'Top 10% Unbiased Z-Score', 'Top 20% Unbiased Z-Score', 'Top 30% Unbiased Z-Score', 'Max Unbiased Z-Score', 'AUC Unbiased Z-Score']\n",
    "small_comparison_df = None\n",
    "small_comparision_fn = os.path.join(small_set_out_dir, 'Large_Comparision_Data.csv')\n",
    "if os.path.isfile(small_comparison_fn):\n",
    "    small_comparison_df = pd.read_csv(small_comparision_fn, sep='\\t', header=0, index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Values For Comparision#\n",
    "To determine the effectiveness of the new method and implementation the covariation of the same proteins will be computed using the previous Evolutionary Trace covariation method (ET-MIp) and other methods in the field.\n",
    "\n",
    "## ET-MIp##\n",
    "Scoring the the covariation of the proteins using the previous Evolutionary Trace covariation method (ET-MIp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from ETMIPWrapper import ETMIPWrapper\n",
    "# etmip_out_dir = os.path.join(small_set_out_dir, 'ET-MIp')\n",
    "# if not os.path.isdir(etmip_out_dir):\n",
    "#     os.makedirs(etmip_out_dir)\n",
    "# etmip_scores = {}\n",
    "# counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "# for p_id in generator.protein_data:\n",
    "#     print('Attempting to calculate ET-MIp covariance for: {}'.format(p_id))\n",
    "#     try:\n",
    "#         protein_out_dir = os.path.join(etmip_out_dir, p_id)\n",
    "#         if not os.path.isdir(protein_out_dir):\n",
    "#             os.makedirs(protein_out_dir)\n",
    "#         curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id, polymer_type='Protein')\n",
    "#         curr_aln.import_alignment()\n",
    "#         curr_etmip = ETMIPWrapper(alignment=curr_aln)\n",
    "#         curr_etmip.calculate_scores(out_dir=protein_out_dir, delete_files=False)\n",
    "#         etmip_scores[p_id] = curr_etmip\n",
    "#         print('Successfully computed ET-MIp covariance for: {}'.format(p_id))\n",
    "#         counts['success'] += 1\n",
    "#     except ValueError:\n",
    "#         print('Could not compute ET-MIp covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "#             p_id, curr_aln.seq_length, curr_aln.size))\n",
    "#         counts['value'] += 1\n",
    "#     except AttributeError:\n",
    "#         print('Could not compute ET-MIp covariance for: {} no alignment'.format(p_id))\n",
    "#         counts['attribute'] += 1\n",
    "# print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "#                                                                      counts['attribute']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ET-MIp (Continued)\n",
    "The previous implementation is not able to run for alignments of the size used here. Instead we use the new implementation with the same parameterization used by the previous implementation (Distance Model - blosum62 similarity, Tree - ET UPGMA variant, Scoring Metric - filtered average product corrected mutual information, Ranks - all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EvolutionaryTrace import EvolutionaryTrace\n",
    "etmip_out_dir = os.path.join(small_set_out_dir, 'ET-MIp')\n",
    "if not os.path.isdir(etmip_out_dir):\n",
    "    os.makedirs(etmip_out_dir)\n",
    "etmip_method_df = None\n",
    "counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "for p_id in generator.protein_data:\n",
    "    print('Attempting to calculate ET-MIp covariance for: {}'.format(p_id))\n",
    "    try:\n",
    "        protein_out_dir = os.path.join(etmip_out_dir, p_id)\n",
    "        if not os.path.isdir(protein_out_dir):\n",
    "            os.makedirs(protein_out_dir)\n",
    "        start_time = time()\n",
    "        curr_etmip = EvolutionaryTrace(query_id=p_id, polymer_type='Protein',\n",
    "                                       aln_fn=generator.protein_data[p_id]['Final_FA_Aln'], et_distance=True,\n",
    "                                       distance_model='blosum62', tree_building_method='et', tree_building_options={},\n",
    "                                       ranks=None, position_type='pair',\n",
    "                                       scoring_metric='filtered_average_product_corrected_mutual_information',\n",
    "                                       gap_correction=None, out_dir=protein_dir,\n",
    "                                       output_files={'original_aln', 'non_gap_aln', 'tree', 'scores'},\n",
    "                                       processors=10, low_memory=True)\n",
    "        init_time = time()\n",
    "        curr_etmip.import_and_process_aln()\n",
    "        import_time = time()\n",
    "        curr_etmip.compute_distance_matrix_tree_and_assignments()\n",
    "        dist_tree_time = time()\n",
    "        curr_etmip.perform_trace()\n",
    "        end_time = time()\n",
    "        print('Successfully computed ET-MIp covariance for: {}'.format(p_id))\n",
    "        # Compute statistics for the final scores of the ET-MIp model\n",
    "        protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "            predictor=curr_etmip, verbostiy=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "            unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=curr_etmip.scorer.position_size,\n",
    "            rank_type=curr_etmip.scorer.rank_type, file_prefix='ET-MIp_Scores_', plots=True)\n",
    "        # Score Prediction Clustering\n",
    "        z_score_fn = os.path.join(protein_dir, 'ET-MIp_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "        z_score_plot_fn = os.path.join(protein_dir, 'ET-MIp_Scores_Dist-Any_{}_ZScores.png')\n",
    "        z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "            1.0 - curr_etmip.coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "            w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "        biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "        protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "        protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "        protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "        protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "        plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "        z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "            1.0 - curr_etmip.coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "            w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "        unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "        protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "        protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "        protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "        protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "        plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "        # Record execution times\n",
    "        protein_df['Init Time'] = init_time - start_time\n",
    "        protein_df['Import Time'] = import_time - init_time\n",
    "        protein_df['Dist Tree Time'] = dist_tree_time - import_time\n",
    "        protein_df['Trace Time'] = end_time - dist_tree_time\n",
    "        protein_df['Total Time'] = end_time - start_time\n",
    "        # Record static data for this protein\n",
    "        protein_df['Protein'] = p_id\n",
    "        protein_df['Method'] = 'ET-MIp'\n",
    "        protein_df['Alignment Size'] = generator.protein_data[p_id]['Filtered_Alignment']\n",
    "        if etmip_method_df is None:\n",
    "            etmip_method_df = protein_df\n",
    "        else:\n",
    "            etmip_method_df = etmip_method_df.append(protein_df)\n",
    "        print('Metrics meastured for ET-MIp covariance for: {}'.format(p_id))\n",
    "        counts['success'] += 1\n",
    "    except ValueError:\n",
    "        print('Could not compute ET-MIp covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "            p_id, curr_etmip.original_aln.seq_length, curr_etmip.original_aln.size))\n",
    "        counts['value'] += 1\n",
    "    except AttributeError:\n",
    "        print('Could not compute ET-MIp covariance for: {} no alignment'.format(p_id))\n",
    "        counts['attribute'] += 1\n",
    "print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                     counts['attribute']))\n",
    "if small_comparison_df is None:\n",
    "    small_comparison_df = etmip_method_df\n",
    "else:\n",
    "    small_comparison_df = small_comparison_df.append(etmip_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cET-MIp\n",
    "This segment the ET-MIp method, when constrained to an arbitrary set of nodes (1, 2, 3, 5, 7, 10, 25) at the top of the phylogenetic tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cetmip_out_dir = os.path.join(small_set_out_dir, 'cET-MIp')\n",
    "if not os.path.isdir(cetmip_out_dir):\n",
    "    os.makedirs(cetmip_out_dir)\n",
    "cetmip_method_df = None\n",
    "counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "for p_id in generator.protein_data:\n",
    "    print('Attempting to calculate cET-MIp covariance for: {}'.format(p_id))\n",
    "    try:\n",
    "        protein_out_dir = os.path.join(cetmip_out_dir, p_id)\n",
    "        if not os.path.isdir(protein_out_dir):\n",
    "            os.makedirs(protein_out_dir)\n",
    "        start_time = time()\n",
    "        curr_cetmip = EvolutionaryTrace(query_id=p_id, polymer_type='Protein',\n",
    "                                       aln_fn=generator.protein_data[p_id]['Final_FA_Aln'], et_distance=True,\n",
    "                                       distance_model='blosum62', tree_building_method='et', tree_building_options={},\n",
    "                                       ranks=[1, 2, 3, 5, 7, 10, 25], position_type='pair',\n",
    "                                       scoring_metric='filtered_average_product_corrected_mutual_information',\n",
    "                                       gap_correction=None, out_dir=protein_dir,\n",
    "                                       output_files={'original_aln', 'non_gap_aln', 'tree', 'scores'},\n",
    "                                       processors=10, low_memory=True)\n",
    "        init_time = time()\n",
    "        curr_cetmip.import_and_process_aln()\n",
    "        import_time = time()\n",
    "        curr_cetmip.compute_distance_matrix_tree_and_assignments()\n",
    "        dist_tree_time = time()\n",
    "        curr_cetmip.perform_trace()\n",
    "        end_time = time()\n",
    "        # Compute statistics for the final scores of the ET-MIp model\n",
    "        protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "            predictor=curr_cetmip, verbostiy=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "            unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=curr_etmip.scorer.position_size,\n",
    "            rank_type=curr_etmip.scorer.rank_type, file_prefix='cET-MIp_Scores_', plots=True)\n",
    "        # Score Prediction Clustering\n",
    "        z_score_fn = os.path.join(protein_dir, 'cET-MIp_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "        z_score_plot_fn = os.path.join(protein_dir, 'cET-MIp_Scores_Dist-Any_{}_ZScores.png')\n",
    "        z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "            1.0 - curr_cetmip.coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "            w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "        biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "        protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "        protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "        protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "        protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "        plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "        z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "            1.0 - curr_cetmip.coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "            w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "        unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "        protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "        protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "        protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "        protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "        plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "        # Record execution times\n",
    "        protein_df['Init Time'] = init_time - start_time\n",
    "        protein_df['Import Time'] = import_time - init_time\n",
    "        protein_df['Dist Tree Time'] = dist_tree_time - import_time\n",
    "        protein_df['Trace Time'] = end_time - dist_tree_time\n",
    "        protein_df['Total Time'] = end_time - start_time\n",
    "        # Record static data for this protein\n",
    "        protein_df['Protein'] = p_id\n",
    "        protein_df['Method'] = 'cET-MIp'\n",
    "        protein_df['Alignment Size'] = generator.protein_data[p_id]['Filtered_Alignment']\n",
    "        if cetmip_method_df is None:\n",
    "            cetmip_method_df = protein_df\n",
    "        else:\n",
    "            cetmip_method_df = cetmip_method_df.append(protein_df)\n",
    "        print('Successfully computed cET-MIp covariance for: {}'.format(p_id))\n",
    "        counts['success'] += 1\n",
    "    except ValueError:\n",
    "        print('Could not compute cET-MIp covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "            p_id, curr_cetmip.original_aln.seq_length, curr_etmip.original_aln.size))\n",
    "        counts['value'] += 1\n",
    "    except AttributeError:\n",
    "        print('Could not compute cET-MIp covariance for: {} no alignment'.format(p_id))\n",
    "        counts['attribute'] += 1\n",
    "print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                     counts['attribute']))\n",
    "if small_comparison_df is None:\n",
    "    small_comparison_df = cetmip_method_df\n",
    "else:\n",
    "    small_comparison_df = small_comparison_df.append(cetmip_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCA##\n",
    "Scoring the the covariation of the proteins using a DCA julia implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DCAWrapper import DCAWrapper\n",
    "from utils import compute_rank_and_coverage\n",
    "dca_out_dir = os.path.join(small_set_out_dir, 'DCA')\n",
    "if not os.path.isdir(dca_out_dir):\n",
    "    os.makedirs(dca_out_dir)\n",
    "dca_method_df = None\n",
    "counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "for p_id in generator.protein_data:\n",
    "    print('Attempting to calculate DCA covariance for: {}'.format(p_id))\n",
    "    try:\n",
    "        protein_out_dir = os.path.join(dca_out_dir, p_id)\n",
    "        if not os.path.isdir(protein_out_dir):\n",
    "            os.makedirs(protein_out_dir)\n",
    "        curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id,\n",
    "                                polymer_type='Protein')\n",
    "        curr_aln.import_alignment()\n",
    "        # Since the DCA implementation used here does not provide a way to specify the query sequence we remove the gaps\n",
    "        # from the query sequences so positions will be referenced correctly for that sequence (and unnecessary\n",
    "        # computations can be avoided).\n",
    "        curr_aln = curr_aln.remove_gaps()\n",
    "        new_aln_fn = os.path.join(protein_out_dir, '{}_no_gap.fasta'.format(p_id))\n",
    "        curr_aln.write_out_alignment(new_aln_fn)\n",
    "        curr_aln.file_name = new_aln_fn\n",
    "        curr_dca = DCAWrapper(alignment=curr_aln)\n",
    "        curr_dca.calculate_scores(out_dir=protein_out_dir, delete_file=False)\n",
    "        # Compute statistics for the final scores of the ET-MIp model\n",
    "        protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "            predictor=curr_dca, verbostiy=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "            unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=curr_etmip.scorer.position_size,\n",
    "            rank_type=curr_etmip.scorer.rank_type, file_prefix='DCA_Scores_', plots=True)\n",
    "        # Score Prediction Clustering\n",
    "        _, dca_coverage  = compute_rank_and_coverage(seq_length=curr_dca.alignment.seq_length, scores=curr_dca.scores, pos_size=2,\n",
    "            rank_type='max')\n",
    "        z_score_fn = os.path.join(protein_dir, 'DCA_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "        z_score_plot_fn = os.path.join(protein_dir, 'DCA_Scores_Dist-Any_{}_ZScores.png')\n",
    "        z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "            1.0 - dca_coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "            w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "        biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "        protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "        protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "        protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "        protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "        plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "        z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "            1.0 - dca_coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "            w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "        unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "        protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "        protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "        protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "        protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "        plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "        # Record execution times\n",
    "        protein_df['Init Time'] = None\n",
    "        protein_df['Import Time'] = None\n",
    "        protein_df['Dist Tree Time'] = None\n",
    "        protein_df['Trace Time'] = None\n",
    "        protein_df['Total Time'] = None\n",
    "        # Record static data for this protein\n",
    "        protein_df['Protein'] = p_id\n",
    "        protein_df['Method'] = 'DCA'\n",
    "        protein_df['Alignment Size'] = generator.protein_data[p_id]['Filtered_Alignment']\n",
    "        if dca_method_df is None:\n",
    "            dca_method_df = protein_df\n",
    "        else:\n",
    "            dca_method_df = dca_method_df.append(protein_df)\n",
    "        print('Successfully computed DCA covariance for: {}'.format(p_id))\n",
    "        counts['success'] += 1\n",
    "    except ValueError:\n",
    "        print('Could not compute DCA covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "            p_id, curr_aln.seq_length, curr_aln.size))\n",
    "        counts['value'] += 1\n",
    "    except AttributeError:\n",
    "        print('Could not compute DCA covariance for: {} no alignment'.format(p_id))\n",
    "        counts['attribute'] += 1\n",
    "print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                     counts['attribute']))\n",
    "if small_comparison_df is None:\n",
    "    small_comparison_df = dca_method_df\n",
    "else:\n",
    "    small_comparison_df = small_comparison_df.append(dca_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVCouplings##\n",
    "Scoring the the covariation of the proteins using the EVCouplings method standard protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EVCouplingsWrapper import EVCouplingsWrapper\n",
    "evc_standard_out_dir = os.path.join(small_set_out_dir, 'EVCouplings_Standard')\n",
    "if not os.path.isdir(evc_standard_out_dir):\n",
    "    os.makedirs(evc_standard_out_dir)\n",
    "evc_standard_method_df = None\n",
    "counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "for p_id in generator.protein_data:\n",
    "    print('Attempting to calculate EV couplings standard protocol covariance for: {}'.format(p_id))\n",
    "    try:\n",
    "        protein_out_dir = os.path.join(evc_standard_out_dir, p_id)\n",
    "        if not os.path.isdir(protein_out_dir):\n",
    "            os.makedirs(protein_out_dir)\n",
    "        curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id,\n",
    "                                polymer_type='Protein')\n",
    "        curr_aln.import_alignment()\n",
    "        curr_evc = EVCouplingsWrapper(alignment=curr_aln, protocol='standard')\n",
    "        curr_evc.calculate_scores(out_dir=protein_out_dir, cores=10, delete_files=True)\n",
    "        # Compute statistics for the final scores of the ET-MIp model\n",
    "        protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "            predictor=curr_evc, verbostiy=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "            unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=curr_etmip.scorer.position_size,\n",
    "            rank_type=curr_etmip.scorer.rank_type, file_prefix='EVC_Standard_Scores_', plots=True)\n",
    "        # Score Prediction Clustering\n",
    "        _, evc_standard_coverage  = compute_rank_and_coverage(seq_length=curr_evc.alignment.seq_length, scores=curr_evc.scores, pos_size=2,\n",
    "            rank_type='max')\n",
    "        z_score_fn = os.path.join(protein_dir, 'EVC_Standard_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "        z_score_plot_fn = os.path.join(protein_dir, 'EVC_Standard_Scores_Dist-Any_{}_ZScores.png')\n",
    "        z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "            1.0 - evc_standard_coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "            w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "        biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "        protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "        protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "        protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "        protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "        plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "        z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "            1.0 - evc_standard_coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "            w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "        unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "        protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "        protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "        protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "        protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "        plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "        # Record execution times\n",
    "        protein_df['Init Time'] = None\n",
    "        protein_df['Import Time'] = None\n",
    "        protein_df['Dist Tree Time'] = None\n",
    "        protein_df['Trace Time'] = None\n",
    "        protein_df['Total Time'] = None\n",
    "        # Record static data for this protein\n",
    "        protein_df['Protein'] = p_id\n",
    "        protein_df['Method'] = 'EVC Standard'\n",
    "        protein_df['Alignment Size'] = generator.protein_data[p_id]['Filtered_Alignment']\n",
    "        if evc_standard_method_df is None:\n",
    "            evc_standard_method_df = protein_df\n",
    "        else:\n",
    "            evc_standard_method_df = evc_standrad_method_df.append(protein_df)\n",
    "        print('Successfully computed EV couplings standard protocol covariance for: {}'.format(p_id))\n",
    "        counts['success'] += 1\n",
    "    except ValueError:\n",
    "        print('Could not compute EV couplings standard protocol covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "            p_id, curr_aln.seq_length, curr_aln.size))\n",
    "        counts['value'] += 1\n",
    "    except AttributeError:\n",
    "        print('Could not compute EV couplings standard protocol covariance for: {} no alignment'.format(p_id))\n",
    "        counts['attribute'] += 1\n",
    "print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                     counts['attribute']))\n",
    "if small_comparison_df is None:\n",
    "    small_comparison_df = evc_standard_method_df\n",
    "else:\n",
    "    small_comparison_df = small_comparison_df.append(evc_standard_method_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring the covariation of the proteins using the EVCouplings method mean field protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evc_mf_out_dir = os.path.join(small_set_out_dir, 'EVCouplings_Mean_Field')\n",
    "if not os.path.isdir(evc_mf_out_dir):\n",
    "    os.makedirs(evc_mf_out_dir)\n",
    "evc_mean_field_method_df = None\n",
    "counts = {'success':0, 'value': 0, 'attribute':0}\n",
    "for p_id in generator.protein_data:\n",
    "    print('Attempting to calculate EV couplings covariance for: {}'.format(p_id))\n",
    "    try:\n",
    "        protein_out_dir = os.path.join(evc_mf_out_dir, p_id)\n",
    "        if not os.path.isdir(protein_out_dir):\n",
    "            os.makedirs(protein_out_dir)\n",
    "        curr_aln = SeqAlignment(file_name=generator.protein_data[p_id]['Final_FA_Aln'], query_id=p_id,\n",
    "                                polymer_type='Protein')\n",
    "        curr_aln.import_alignment()\n",
    "        curr_evc = EVCouplingsWrapper(alignment=curr_aln, protocol='mean_field')\n",
    "        curr_evc.calculate_scores(out_dir=protein_out_dir, cores=10, delete_files=True)\n",
    "        # Compute statistics for the final scores of the ET-MIp model\n",
    "        protein_df, _, _ = protein_scorers[p_id]['Scorer_CB'].evaluate_predictor(\n",
    "            predictor=curr_evc, verbostiy=2, out_dir=protein_dir, dist='CB', biased_w2_ave=None,\n",
    "            unbiased_w2_ave=None, processes=10, threshold=0.5, pos_size=curr_etmip.scorer.position_size,\n",
    "            rank_type=curr_etmip.scorer.rank_type, file_prefix='EVC_Standard_Scores_', plots=True)\n",
    "        # Score Prediction Clustering\n",
    "        _, evc_mf_coverage  = compute_rank_and_coverage(seq_length=curr_evc.alignment.seq_length, scores=curr_evc.scores, pos_size=2,\n",
    "            rank_type='max')\n",
    "        z_score_fn = os.path.join(protein_dir, 'EVC_Mean_Field_Scores_Dist-Any_{}_ZScores.tsv')\n",
    "        z_score_plot_fn = os.path.join(protein_dir, 'EVC_Mean_Field_Scores_Dist-Any_{}_ZScores.png')\n",
    "        z_score_biased, biased_w2_ave, biased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "            1.0 - evc_mf_coverage, bias=True, file_path=z_score_fn.format('Biased'),\n",
    "            w2_ave_sub=protein_scorers[p_id]['biased_w2_ave'], processes=10)\n",
    "        biased_z_score_array = np.array(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "        protein_df['Max Biased Z-Score'] = np.nanmax(biased_z_score_array)\n",
    "        protein_df['Biased Z-Score at 10%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "        protein_df['Biased Z-Score at 30%'] = biased_z_score_array[z_score_biased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "        protein_df['AUC Biased Z-Score'] = biased_scw_z_auc\n",
    "        plot_z_scores(z_score_biased, z_score_plot_fn.format('Biased'))\n",
    "        z_score_unbiased, unbiased_w2_ave, unbiased_scw_z_auc = protein_scorers[p_id]['Scorer_Any'].score_clustering_of_contact_predictions(\n",
    "            1.0 - evc_mf_coverage, bias=False, file_path=z_score_fn.format('Unbiased'),\n",
    "            w2_ave_sub=protein_scorers[p_id]['unbiased_w2_ave'], processes=10)\n",
    "        unbiased_z_score_array = np.array(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "        protein_df['Max Unbiased Z-Score'] = np.nanmax(unbiased_z_score_array)\n",
    "        protein_df['Unbiased Z-Score at 10%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.10][0]\n",
    "        protein_df['Unbiased Z-Score at 30%'] = unbiased_z_score_array[z_score_unbiased['Num_Residues'] >= float(len(protein_scorers[p_id]['Scorer_Any'].query_structure.seq[protein_scorers[p_id]['Scorer_Any'].best_chain])) * 0.30][0]\n",
    "        protein_df['AUC Unbiased Z-Score'] = unbiased_scw_z_auc\n",
    "        plot_z_scores(z_score_unbiased, z_score_plot_fn.format('Unbiased'))\n",
    "        # Record execution times\n",
    "        protein_df['Init Time'] = None\n",
    "        protein_df['Import Time'] = None\n",
    "        protein_df['Dist Tree Time'] = None\n",
    "        protein_df['Trace Time'] = None\n",
    "        protein_df['Total Time'] = None\n",
    "        # Record static data for this protein\n",
    "        protein_df['Protein'] = p_id\n",
    "        protein_df['Method'] = 'EVC Mean Field'\n",
    "        protein_df['Alignment Size'] = generator.protein_data[p_id]['Filtered_Alignment']\n",
    "        if evc_mean_field_method_df is None:\n",
    "            evc_mean_field_method_df = protein_df\n",
    "        else:\n",
    "            evc_mean_field_method_df = evc_mean_field_method_df.append(protein_df)\n",
    "        print('Successfully computed EV couplings covariance for: {}'.format(p_id))\n",
    "        counts['success'] += 1\n",
    "    except ValueError:\n",
    "        print('Could not compute EV couplings covariance for: {} with seq_length: {} and size: {}'.format(\n",
    "            p_id, curr_aln.seq_length, curr_aln.size))\n",
    "        counts['value'] += 1\n",
    "    except AttributeError:\n",
    "        print('Could not compute EV couplings covariance for: {} no alignment'.format(p_id))\n",
    "        counts['attribute'] += 1\n",
    "print('{}\\tSuccesses\\n{}\\tValue Errors\\n{}\\tAttribute Errors'.format(counts['success'], counts['value'],\n",
    "                                                                     counts['attribute']))\n",
    "if small_comparison_df is None:\n",
    "    small_comparison_df = evc_mean_field_method_df\n",
    "else:\n",
    "    small_comparison_df = small_comparison_df.append(evc_mean_field_method_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out final comparison data so it can be loaded later for generating figures.\n",
    "small_comparison_df.to_csv(small_comparison_fn, sep='\\t', header=True, index=False, columns=output_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (PyET3)",
   "language": "python",
   "name": "pyet3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
