{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports #\n",
    "Import all packages and project code needed to complete the analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import requests\n",
    "import pandas as pd\n",
    "from time import time, sleep\n",
    "# %matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib import lines\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import wilcoxon\n",
    "import xml.etree.ElementTree as XMLET\n",
    "from Bio import Entrez\n",
    "from Bio.Phylo.TreeConstruction import DistanceMatrix\n",
    "# Load global variables from project file\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "try:\n",
    "    dotenv_path = find_dotenv(raise_error_if_not_found=True)\n",
    "except IOError:\n",
    "    dotenv_path = find_dotenv(raise_error_if_not_found=True, usecwd=True)\n",
    "load_dotenv(dotenv_path)\n",
    "# Add the project path to the python path so the required clases can be imported\n",
    "sys.path.append(os.path.join(os.environ.get('PROJECT_PATH'), 'src'))\n",
    "sys.path.append(os.path.join(os.environ.get('PROJECT_PATH'), 'src', 'SupportingClasses'))\n",
    "# Import lab internal packages\n",
    "from SupportingClasses.SeqAlignment import SeqAlignment\n",
    "from SupportingClasses.PhylogeneticTree import PhylogeneticTree\n",
    "from SupportingClasses.DCAWrapper import DCAWrapper\n",
    "from SupportingClasses.EVCouplingsWrapper import EVCouplingsWrapper\n",
    "from Evaluation.ContactScorer import ContactScorer\n",
    "from Evaluation.SinglePositionScorer import SinglePositionScorer\n",
    "from EvolutionaryTrace import EvolutionaryTrace\n",
    "# from SupportingClasses.DataSetGenerator import parse_uniref_lineage\n",
    "# Set the e-mail variable for Entrez for parsing later on\n",
    "Entrez.email = os.environ.get('EMAIL')\n",
    "output_dir = '/media/daniel/ExtraDrive1/Results/CovET_Final_Results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Trees #\n",
    "For the three proteins analyzed in depth the phylogenetic tree computed for the CovET predictions is loaded and colored either by species or by molecular classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define function to annotate the molecular classifications of GPCRs\n",
    "def get_uniprot_prints_annotations(acc_id):\n",
    "    acc = acc_id.split('_')[-1]\n",
    "    BASE = 'https://www.uniprot.org'\n",
    "    KB_ENDPOINT = '/uniprot/'\n",
    "    payload = {'query': acc, 'format': 'xml'}\n",
    "    result = requests.get(BASE + KB_ENDPOINT, params=payload) \n",
    "    if result.ok:\n",
    "        xml_root = XMLET.fromstring(result.text)\n",
    "        prints_elements = xml_root.findall(\"{http://uniprot.org/uniprot}entry/{http://uniprot.org/uniprot}dbReference[@type='PRINTS']\")\n",
    "        print_annotations = []\n",
    "        for p_e in prints_elements:\n",
    "            print_id = p_e.get('id')\n",
    "            entry_names = p_e.findall(\"{http://uniprot.org/uniprot}property[@type='entry name']\")\n",
    "            for entry_name in entry_names:\n",
    "                print_entry_name = entry_name.get('value')\n",
    "                print_annotations.append((print_id, print_entry_name))\n",
    "    return print_annotations\n",
    "\n",
    "def get_uniparc_prints_annotations(acc_id):\n",
    "    acc = acc_id.split('_')[-1]\n",
    "    BASE = 'https://www.uniprot.org'\n",
    "    KB_ENDPOINT = '/uniparc/'\n",
    "    payload = {'query': acc, 'format': 'xml'}\n",
    "    result = requests.get(BASE + KB_ENDPOINT, params=payload) \n",
    "    if result.ok:\n",
    "        xml_root = XMLET.fromstring(result.text)\n",
    "        prints_elements = xml_root.findall(\"{http://uniprot.org/uniparc}entry/{http://uniprot.org/uniparc}signatureSequenceMatch[@database='PRINTS']\")\n",
    "        print_annotations = []\n",
    "        for p_e in prints_elements:\n",
    "            print_id = p_e.get('id')\n",
    "            entry_names = p_e.findall(\"{http://uniprot.org/uniparc}ipr\")\n",
    "            for entry_name in entry_names:\n",
    "                print_entry_name = entry_name.get('name')\n",
    "                print_annotations.append((print_id, print_entry_name))\n",
    "    return print_annotations\n",
    "\n",
    "# D2R\n",
    "d2r_tree_dir = os.path.join(output_dir, 'Trees', 'D2R')\n",
    "os.makedirs(d2r_tree_dir, exist_ok=True)\n",
    "\n",
    "query = '2ddr'\n",
    "d2r_aln_file_path = '/media/daniel/ExtraDrive1/Results/Allosteric_Data_Set/Domain_Specific_Min_ID_40/Output/ID40/U90/2ddr/ET-MEMER/Non-Gapped_Alignment.fa'\n",
    "d2r_aln = SeqAlignment(file_name=d2r_aln_file_path, query_id=query)\n",
    "d2r_aln.import_alignment()\n",
    "\n",
    "# Attempt to annotate each of the sequences in the alignment\n",
    "d2r_annotations_path = os.path.join(d2r_tree_dir, 'Saved_Classification_Annotations.tsv')\n",
    "\n",
    "if os.path.isfile(d2r_annotations_path):\n",
    "    d2r_annotations_df = pd.read_csv(d2r_annotations_path, header=0, index_col=None, sep='\\t')\n",
    "    d2r_annotations = d2r_annotations_df.to_dict('series')\n",
    "    d2r_annotations = {k: list(v) for k, v in d2r_annotations.items()}\n",
    "    print(f\"Loaded: {len(set(d2r_annotations['Sequence ID']))} ID annotations\")\n",
    "else:\n",
    "    d2r_annotations = {'Sequence ID': [], 'PRINTS ID': [], 'PRINTS Name': []}\n",
    "counter = 0\n",
    "start = time()\n",
    "to_annotate = set(d2r_aln.seq_order) - set(d2r_annotations['Sequence ID'])\n",
    "print(to_annotate)\n",
    "for s_id in to_annotate:\n",
    "    print('SEQ ID: ', s_id)\n",
    "    if counter % 10 == 0:\n",
    "        print(f'Seq ID {counter}: {time() - start}sec')\n",
    "        pd.DataFrame(d2r_annotations).to_csv(d2r_annotations_path, header=True, index=False, sep='\\t')\n",
    "    counter += 1\n",
    "    if s_id == query:\n",
    "        s_id = 'P14416'\n",
    "    requesting = True\n",
    "    while requesting:\n",
    "        try:\n",
    "            curr_annotations = get_uniprot_prints_annotations(s_id)\n",
    "#             print('CURR ANNOTATIONS: ', curr_annotations)\n",
    "            requesting = False\n",
    "        except ConnectionResetError:\n",
    "            sleep(1)\n",
    "        except XMLET.ParseError:\n",
    "            try:\n",
    "                curr_annotations = get_uniparc_prints_annotations(s_id)\n",
    "                requesting = False\n",
    "            except XMLET.ParseError:\n",
    "                curr_annotations = [('UNKNOWN', None)]\n",
    "                requesting = False\n",
    "            except ConnectionResetError:\n",
    "                sleep(1)\n",
    "        for annot in curr_annotations:\n",
    "            if s_id == 'P14416':\n",
    "                s_id = query\n",
    "            d2r_annotations['Sequence ID'].append(s_id)\n",
    "            d2r_annotations['PRINTS ID'].append(annot[0])\n",
    "            d2r_annotations['PRINTS Name'].append(annot[1])\n",
    "        if len(curr_annotations) == 0:\n",
    "            d2r_annotations['Sequence ID'].append(s_id)\n",
    "            d2r_annotations['PRINTS ID'].append('UNKNOWN')\n",
    "            d2r_annotations['PRINTS Name'].append(None)\n",
    "d2r_annotations_df = pd.DataFrame(d2r_annotations)\n",
    "if len(to_annotate) > 0:\n",
    "    d2r_annotations_df.to_csv(d2r_annotations_path, header=True, index=False, sep='\\t')\n",
    "    \n",
    "unannotated_seq_ids = d2r_annotations_df.loc[d2r_annotations_df['PRINTS ID'] == 'UNKNOWN', 'Sequence ID'].unique()\n",
    "unannotated_dict = {x: 'UNKNOWN' for x in unannotated_seq_ids}\n",
    "\n",
    "annotated_seq_ids = d2r_annotations_df.loc[d2r_annotations_df['PRINTS ID'] != 'UNKNOWN', :]\n",
    "annotated_seq_ids['ID Integer'] = annotated_seq_ids['PRINTS ID'].apply(lambda x: int(x[2:]))\n",
    "\n",
    "groups = annotated_seq_ids.sort_values(by='ID Integer').groupby('Sequence ID')\n",
    "annotation_levels = {x: {} for x in range(3)}\n",
    "annotation_counts = {x: {} for x in range(3)}\n",
    "for group in groups.groups.keys():\n",
    "    curr_group = groups.get_group(group)\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            label = curr_group['PRINTS ID'].iloc[i]\n",
    "            annotation_levels[i][group] = label\n",
    "            if label not in annotation_counts[i]:\n",
    "                annotation_counts[i][label] = 1\n",
    "            else:\n",
    "                annotation_counts[i][label] += 1\n",
    "        except IndexError:\n",
    "            pass\n",
    "\n",
    "# Load the tree used in the D2R analyses\n",
    "d2r_tree_file_path = '/media/daniel/ExtraDrive1/Results/Allosteric_Data_Set/Domain_Specific_Min_ID_40/Output/ID40/U90/2ddr/ET-MEMER/2ddr_ET_blosum62_dist_et_tree.nhx'\n",
    "d2r_tree = PhylogeneticTree(tree_building_method='custom', tree_building_args={'tree_path': d2r_tree_file_path})\n",
    "d2r_tree.construct_tree(dm=DistanceMatrix(names=d2r_aln.seq_order))\n",
    "\n",
    "# Render the tree with the leaves colored according to the least specific protein classifications\n",
    "completed_least_specific_annotations, completed_least_specific_annotations_df = d2r_tree.annotate_incomplete_tree(annotation_levels[0])\n",
    "completed_least_specific_annotations_df.to_csv(os.path.join(d2r_tree_dir, 'Least_Specific_Annotation_Completion.tsv'), header=True, index=False, sep='\\t')\n",
    "curr_annotation_counts = {}\n",
    "for seq_id in completed_least_specific_annotations:\n",
    "    label = completed_least_specific_annotations[seq_id]\n",
    "    if label not in curr_annotation_counts:\n",
    "        curr_annotation_counts[label] = 1\n",
    "    else:\n",
    "        curr_annotation_counts[label] += 1\n",
    "_, color_dict1 = d2r_tree.visualize_tree(query='2ddr', out_dir=d2r_tree_dir, id_categories=completed_least_specific_annotations, filename='Least_Specific_Classification.png')\n",
    "color_lists1 = [list(x) for x in list(zip(*list(color_dict1.items())))]\n",
    "pd.DataFrame({'Category': color_lists1[0], 'Colors': color_lists1[1], 'Counts': [curr_annotation_counts[x] for x in color_lists1[0]]}).to_csv(os.path.join(d2r_tree_dir, 'Least_Specific_Coloring.tsv'),\n",
    "                                                                                                                                              header=True, index=False, sep='\\t')\n",
    "# Render the tree with the leaves colored according to the intermediate specificity protein classifications\n",
    "completed_middle_specific_annotations, completed_middle_specific_annotations_df = d2r_tree.annotate_incomplete_tree(annotation_levels[1])\n",
    "completed_middle_specific_annotations_df.to_csv(os.path.join(d2r_tree_dir, 'Middle_Specific_Annotation_Completion.tsv'), header=True, index=False, sep='\\t')\n",
    "curr_annotation_counts = {}\n",
    "for seq_id in completed_middle_specific_annotations:\n",
    "    label = completed_middle_specific_annotations[seq_id]\n",
    "    if label not in curr_annotation_counts:\n",
    "        curr_annotation_counts[label] = 1\n",
    "    else:\n",
    "        curr_annotation_counts[label] += 1\n",
    "_, color_dict2 = d2r_tree.visualize_tree(query='2ddr', out_dir=d2r_tree_dir, id_categories=completed_middle_specific_annotations, filename='Middle_Specific_Classification.png')\n",
    "color_lists2 = [list(x) for x in list(zip(*list(color_dict2.items())))]\n",
    "pd.DataFrame({'Category': color_lists2[0], 'Colors': color_lists2[1], 'Counts': [curr_annotation_counts[x] for x in color_lists2[0]]}).to_csv(os.path.join(d2r_tree_dir, 'Middle_Specific_Coloring.tsv'),\n",
    "                                                                                                                                              header=True, index=False, sep='\\t')\n",
    "# Render the tree with the leaves colored according to the most specific protein classifications\n",
    "completed_most_specific_annotations, completed_most_specific_annotations_df = d2r_tree.annotate_incomplete_tree(annotation_levels[2])\n",
    "completed_most_specific_annotations_df.to_csv(os.path.join(d2r_tree_dir, 'Most_Specific_Annotation_Completion.tsv'), header=True, index=False, sep='\\t')\n",
    "curr_annotation_counts = {}\n",
    "for seq_id in completed_most_specific_annotations:\n",
    "    label = completed_most_specific_annotations[seq_id]\n",
    "    if label not in curr_annotation_counts:\n",
    "        curr_annotation_counts[label] = 1\n",
    "    else:\n",
    "        curr_annotation_counts[label] += 1\n",
    "_, color_dict3 = d2r_tree.visualize_tree(query='2ddr', out_dir=d2r_tree_dir, id_categories=completed_most_specific_annotations, filename='Most_Specific_Classification.png')\n",
    "color_lists3 = [list(x) for x in list(zip(*list(color_dict3.items())))]\n",
    "pd.DataFrame({'Category': color_lists3[0], 'Colors': color_lists3[1], 'Counts': [curr_annotation_counts[x] for x in color_lists3[0]]}).to_csv(os.path.join(d2r_tree_dir, 'Most_Specific_Coloring.tsv'),\n",
    "                                                                                                                                              header=True, index=False, sep='\\t')\n",
    "# Render a legend to go with this tree\n",
    "f = lambda m,c: plt.plot([],[],marker=m, color=c, ls=\"none\")[0]\n",
    "handles = [f(\"s\", color_lists3[1][i]) for i in range(len(color_lists3[0]))]\n",
    "labels = [f'{color_lists3[0][i]}({curr_annotation_counts[color_lists3[0][i]]})' for i in range(len(color_lists3[0]))]\n",
    "legend = plt.legend(handles, loc=3, framealpha=1, frameon=True, ncol=4, edgecolor='black', facecolor='none')\n",
    "for i, l_label in enumerate(legend.get_texts()):\n",
    "    l_label.set_text(labels[i])\n",
    "fig  = legend.figure\n",
    "plt.axis('off')\n",
    "fig.canvas.draw()\n",
    "fig.savefig(os.path.join(d2r_tree_dir, 'Most_Specific_Legend.png'), dpi=500, bbox_inches='tight', tranparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define function to retrieve, lookup, and annotate the lineage of each sequence ID\n",
    "def retrieve_and_parse_lineage_ncbi(lineage_id):\n",
    "    handle = Entrez.efetch(db='taxonomy', rettype='gp', retmode='xml', id=lineage_id)\n",
    "    taxa_set = XMLET.parse(handle).getroot()\n",
    "    extended_lineage = taxa_set.findall(\"Taxon/LineageEx/Taxon\")\n",
    "    taxa_desc = {}\n",
    "    taxa_list = []\n",
    "    for taxon in extended_lineage:\n",
    "        sci_name = taxon.find('ScientificName').text\n",
    "        rank = taxon.find('Rank').text\n",
    "        if rank in taxa_desc:\n",
    "            if isinstance(taxa_desc[rank], tuple):\n",
    "                taxa_desc[rank] = [taxa_desc[rank], (taxa_set.find('Taxon/TaxId'), sci_name)]\n",
    "            elif isinstance(taxa_desc[rank], list):\n",
    "                taxa_desc[rank].append((taxa_set.find('Taxon/TaxId'), sci_name))\n",
    "            else:\n",
    "                raise ValueError('Strange value encountered.')\n",
    "        else:\n",
    "            taxa_desc[rank] = (taxon.find('TaxId').text, sci_name)\n",
    "        taxa_list.append(sci_name)\n",
    "    final_sci_name = taxa_set.find('Taxon/ScientificName')\n",
    "    final_rank = taxa_set.find('Taxon/Rank')\n",
    "    if final_rank in taxa_desc:\n",
    "        if isinstance(taxa_desc[final_rank], tuple):\n",
    "            taxa_desc[final_rank]: [taxa_desc[final_rank], (taxa_set.find('Taxon/TaxId'), final_sci_name)]\n",
    "        elif isinstance(taxa_desc[rank], list):\n",
    "            taxa_desc[rank].append((taxa_set.find('Taxon/TaxId'), sci_name))\n",
    "        else:\n",
    "            raise ValueError('Strange value encountered.')\n",
    "    else:\n",
    "        taxa_desc[final_rank]: (taxa_set.find('Taxon/TaxId'), final_sci_name)\n",
    "    taxa_list.append(final_sci_name)\n",
    "    return taxa_list, taxa_desc\n",
    "\n",
    "def get_uniprot_lineage(acc_id):\n",
    "    acc = acc_id.split('_')[-1]\n",
    "    BASE = 'https://www.uniprot.org'\n",
    "    KB_ENDPOINT = '/uniprot/'\n",
    "    payload = {'query': acc, 'format': 'xml'}\n",
    "    result = requests.get(BASE + KB_ENDPOINT, params=payload) \n",
    "    if result.ok:\n",
    "        xml_root = XMLET.fromstring(result.text)\n",
    "        taxa_elements = xml_root.findall(\"{http://uniprot.org/uniprot}entry/{http://uniprot.org/uniprot}organism/{http://uniprot.org/uniprot}dbReference[@type='NCBI Taxonomy']\")\n",
    "        assert len(taxa_elements) == 1\n",
    "        ncbi_id = taxa_elements[0].get('id')\n",
    "        return retrieve_and_parse_lineage_ncbi(ncbi_id)\n",
    "    else:\n",
    "        raise ConnectionError('Did not get a successful response.')\n",
    "        \n",
    "def get_uniparc_lineage(acc_id):\n",
    "    acc = acc_id.split('_')[-1]\n",
    "    BASE = 'https://www.uniprot.org'\n",
    "    KB_ENDPOINT = '/uniparc/'\n",
    "    payload = {'query': acc, 'format': 'xml'}\n",
    "    result = requests.get(BASE + KB_ENDPOINT, params=payload) \n",
    "    if result.ok:\n",
    "        xml_root = XMLET.fromstring(result.text)\n",
    "        taxa_element = xml_root.find(\"{http://uniprot.org/uniparc}entry/{http://uniprot.org/uniparc}dbReference/{http://uniprot.org/uniparc}property[@type='NCBI_taxonomy_id']\")\n",
    "        ncbi_id = taxa_element.get('value')\n",
    "        return retrieve_and_parse_lineage_ncbi(ncbi_id)\n",
    "    else:\n",
    "        raise ConnectionError('Did not get a successful response.')\n",
    "\n",
    "\n",
    "for protein, query, query_uniprot in [('WW', '1yap', 'UniRef90_P46937'), ('RRM', '2rrm', 'UniRef90_P04147'), ('D2R', '2ddr', 'UniRef90_P14416')]:\n",
    "    print('QUERY: ', query)\n",
    "    tree_dir = os.path.join(output_dir, 'Trees', protein)\n",
    "    os.makedirs(tree_dir, exist_ok=True)\n",
    "\n",
    "    aln_file_path = f'/media/daniel/ExtraDrive1/Results/Allosteric_Data_Set/Domain_Specific_Min_ID_40/Output/ID40/U90/{query}/ET-MEMER/Non-Gapped_Alignment.fa'\n",
    "    aln = SeqAlignment(file_name=aln_file_path, query_id=query)\n",
    "    aln.import_alignment()\n",
    "\n",
    "    # Attempt to annotate each of the sequences in the alignment\n",
    "    annotations_path = os.path.join(tree_dir, 'Saved_Annotations.tsv')\n",
    "\n",
    "\n",
    "    if os.path.isfile(annotations_path):\n",
    "        annotations_df = pd.read_csv(annotations_path, header=0, index_col=None, sep='\\t')\n",
    "        annotations = annotations_df.to_dict('series')\n",
    "        annotations = {k: list(v) for k, v in annotations.items()}\n",
    "        print(f\"Loaded: {len(set(annotations['Sequence ID']))} ID annotations\")\n",
    "    else:\n",
    "        annotations = {'Sequence ID': []}\n",
    "\n",
    "    counter = 0\n",
    "    start = time()\n",
    "    to_annotate = set(aln.seq_order) - set(annotations['Sequence ID'])\n",
    "    max_desc = set(annotations.keys()) - set(['Sequence ID'])\n",
    "    for s_id in to_annotate:\n",
    "        if counter % 10 == 0:\n",
    "            print(f'Seq ID {counter}: {time() - start}sec')\n",
    "            pd.DataFrame(annotations).to_csv(annotations_path, header=True, index=False, sep='\\t')\n",
    "        counter += 1\n",
    "        if s_id == query:\n",
    "            s_id = query_uniprot\n",
    "        try:\n",
    "            _, lin_desc = get_uniprot_lineage(s_id)\n",
    "        except XMLET.ParseError:\n",
    "            try:\n",
    "                _, lin_desc = get_uniparc_lineage(s_id)\n",
    "            except XMLET.ParseError:\n",
    "                lin_desc = {}\n",
    "        curr_desc_levels = set(lin_desc.keys())\n",
    "        missing_levels = curr_desc_levels - max_desc\n",
    "        if len(missing_levels) > 1:\n",
    "            for desc_level in missing_levels:\n",
    "                annotations[desc_level] = [None] * len(annotations['Sequence ID'])\n",
    "            max_desc |= set(curr_desc_levels)\n",
    "        for desc_level in max_desc:\n",
    "            try:\n",
    "                if isinstance(lin_desc[desc_level], tuple):\n",
    "                    annotations[desc_level].append(lin_desc[desc_level][1])\n",
    "                elif isinstance(lin_desc[desc_level], list):\n",
    "                    annotations[desc_level].append(','.join([x[1] for x in lin_desc[desc_level]]))\n",
    "            except KeyError:\n",
    "                annotations[desc_level].append(None)\n",
    "        annotations['Sequence ID'].append(s_id)\n",
    "        if s_id == query_uniprot:\n",
    "            annotations['Sequence ID'].append(query)\n",
    "            for desc_level in max_desc:\n",
    "                annotations[desc_level].append(annotations[desc_level][-1])\n",
    "    print(f'The max number of descriptive levels is: {len(max_desc)}')\n",
    "    annotations_df = pd.DataFrame(annotations)\n",
    "    if len(to_annotate) > 0:\n",
    "        annotations_df.to_csv(annotations_path, header=True, index=False, sep='\\t')\n",
    "\n",
    "    tree_file_path = f'/media/daniel/ExtraDrive1/Results/Allosteric_Data_Set/Domain_Specific_Min_ID_40/Output/ID40/U90/{query}/ET-MEMER/{query}_ET_blosum62_dist_et_tree.nhx'\n",
    "    tree = PhylogeneticTree(tree_building_method='custom', tree_building_args={'tree_path': tree_file_path})\n",
    "    tree.construct_tree(dm=DistanceMatrix(names=aln.seq_order))\n",
    "\n",
    "    percent_complete = 1 - (annotations_df[set(annotations_df.columns) - set(['Sequence ID', 'no rank'])].isna().sum()/len(annotations_df))\n",
    "    columns_to_render = percent_complete.index[percent_complete > 0.75]\n",
    "    final_annotations_df = annotations_df.fillna('UNKNOWN')\n",
    "\n",
    "    annotation_dict = {c: {} for c in columns_to_render}\n",
    "    counts = {c: {} for c in columns_to_render}\n",
    "    for ind in final_annotations_df.index:\n",
    "        row = final_annotations_df.loc[ind, :]\n",
    "    #     print(row)\n",
    "        for col in columns_to_render:\n",
    "            annotation_dict[col][row['Sequence ID']] = 'AMBIGUOUS' if ',' in row[col] else row[col]\n",
    "            if annotation_dict[col][row['Sequence ID']] not in counts[col]:\n",
    "                counts[col][annotation_dict[col][row['Sequence ID']]] = 1\n",
    "            else:\n",
    "                counts[col][annotation_dict[col][row['Sequence ID']]] += 1\n",
    "                \n",
    "#     print(counts)\n",
    "\n",
    "    for taxa_level in columns_to_render:    \n",
    "        _, color_dict = tree.visualize_tree(query=query, out_dir=tree_dir, id_categories=annotation_dict[taxa_level], filename=f'Taxa_Level_{taxa_level}.png')\n",
    "        color_lists = [list(x) for x in list(zip(*list(color_dict.items())))]\n",
    "        pd.DataFrame({'Category': color_lists[0], 'Colors': color_lists[1], 'Counts': [counts[taxa_level][x] for x in color_lists[0]]}).to_csv(os.path.join(tree_dir, f'Taxa_Level_{taxa_level}.tsv'),\n",
    "                                                                                                                                               header=True, index=False, sep='\\t')\n",
    "        if protein in ['RRM', 'WW'] and taxa_level == 'phylum':\n",
    "            # Render a legend to go with this tree\n",
    "            f = lambda m,c: plt.plot([],[],marker=m, color=c, ls=\"none\")[0]\n",
    "            handles = [f(\"s\", color_lists[1][i]) for i in range(len(color_lists[0]))]\n",
    "            labels = [f'{color_lists[0][i]}({counts[taxa_level][color_lists[0][i]]})' for i in range(len(color_lists[0]))]\n",
    "            legend = plt.legend(handles, loc=3, framealpha=1, frameon=True, ncol=4, edgecolor='black', facecolor='none')\n",
    "            for i, l_label in enumerate(legend.get_texts()):\n",
    "                l_label.set_text(labels[i])\n",
    "            fig  = legend.figure\n",
    "            plt.axis('off')\n",
    "            fig.canvas.draw()\n",
    "            fig.savefig(os.path.join(tree_dir, f'Taxa_Level_{taxa_level}_Legend.png'), dpi=500, bbox_inches='tight', tranparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting variables:\n",
    "## For all proteins analyzed in this study\n",
    "Tracking not just the query and PDB but also the location for the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data_set_dir = '/media/daniel/ExtraDrive1/Results/Newest_Covariation/Input'\n",
    "# 2ysd is a duplicate of 1yap but with an alignment based on the structure instead of teh domain reference sequence, it has been removed from my analyses.\n",
    "# 2zxe has not been completed\n",
    "small_data_set = {'1c0k': {'query': '1c0k', 'pdb': '1c0k', 'chain': 'A', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', 'c0', 'pdb1c0k.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '1c0k.fasta')},\n",
    "                  '7hvp': {'query': '7hvp', 'pdb': '7hvp', 'chain': 'A', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', 'hv', 'pdb7hvp.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '7hvp.fasta')},\n",
    "                  '2b59': {'query': '2b59', 'pdb': '2b59', 'chain': 'B', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', 'b5', 'pdb2b59.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '2b59.fasta')},\n",
    "                  '206l': {'query': '206l', 'pdb': '206l', 'chain': 'A', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', '06', 'pdb206l.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '206l.fasta')},\n",
    "                  '1bol': {'query': '1bol', 'pdb': '1bol', 'chain': 'A', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', 'bo', 'pdb1bol.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '1bol.fasta')},\n",
    "                  '1jwl': {'query': '1jwl', 'pdb': '1jwl', 'chain': 'A', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', 'jw', 'pdb1jwl.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '1jwl.fasta')},\n",
    "                  '3q05': {'query': '3q05', 'pdb': '3q05', 'chain': 'A', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', 'q0', 'pdb3q05.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '3q05.fasta')},\n",
    "                  '2z0e': {'query': '2z0e', 'pdb': '2z0e', 'chain': 'A', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', 'z0', 'pdb2z0e.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '2z0e.fasta')},\n",
    "                  '2rh1': {'query': '2rh1', 'pdb': '2rh1', 'chain': 'A', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', 'rh', 'pdb2rh1.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '2rh1.fasta')},\n",
    "                  '4lli': {'query': '4lli', 'pdb': '4lli', 'chain': 'A', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', 'll', 'pdb4lli.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '4lli.fasta')},\n",
    "#                   '2ysd': {'query': '2ysd', 'pdb': '2ysd', 'chain': 'A', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', 'ys', 'pdb2ysd.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '2ysd.fasta')},\n",
    "                  '1h1v': {'query': '1h1v', 'pdb': '1h1v', 'chain': 'G', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', 'h1', 'pdb1h1v.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '1h1v.fasta')},\n",
    "#                   '2zxe': {'query': '2zxe', 'pdb': '2zxe', 'chain': 'A', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', 'zx', 'pdb2zxe.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '2zxe.fasta')},\n",
    "                  '1c17': {'query': '1c17', 'pdb': '1c17', 'chain': 'A', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', 'c1', 'pdb1c17.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '1c17.fasta')},\n",
    "                  '1a26': {'query': '1a26', 'pdb': '1a26', 'chain': 'A', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', 'a2', 'pdb1a26.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '1a26.fasta')},\n",
    "                  '135l': {'query': '135l', 'pdb': '135l', 'chain': 'A', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', '35', 'pdb135l.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '135l.fasta')},\n",
    "                  '3b6v': {'query': '3b6v', 'pdb': '3b6v', 'chain': 'A', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', 'b6', 'pdb3b6v.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '3b6v.fasta')},\n",
    "                  '1hck': {'query': '1hck', 'pdb': '1hck', 'chain': 'A', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', 'hc', 'pdb1hck.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '1hck.fasta')},\n",
    "                  '3tnu': {'query': '3tnu', 'pdb': '3tnu', 'chain': 'A', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', 'tn', 'pdb3tnu.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '3tnu.fasta')},\n",
    "                  '2wer': {'query': '2wer', 'pdb': '2wer', 'chain': 'A', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', 'we', 'pdb2wer.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '2wer.fasta')},\n",
    "                  '1axb': {'query': '1axb', 'pdb': '1axb', 'chain': 'A', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', 'ax', 'pdb1axb.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '1axb.fasta')},\n",
    "                  '4ycu': {'query': '4ycu', 'pdb': '4ycu', 'chain': 'A', 'pdb_path': os.path.join(small_data_set_dir, 'PDB', 'yc', 'pdb4ycu.ent'), 'aln_path': os.path.join(small_data_set_dir, 'Final_Alignments', '4ycu.fasta')}}\n",
    "allosteric_pdb_dir = '/media/daniel/ExtraDrive1/Results/Allosteric_Data_Set/Domain_Specific_Min_ID_40/Data_Sets/Shared/PDBs/'\n",
    "allosteric_data_set = {'2ddr': {'query': '2ddr', 'pdb': '6cm4', 'chain': 'A', 'pdb_path': os.path.join(allosteric_pdb_dir, '6cm4.pdb'),\n",
    "                                'aln_path': '/media/daniel/ExtraDrive1/Results/Allosteric_Data_Set/Output/U90/2ddr/ET-MEMER/Non-Gapped_Alignment.fa'},\n",
    "                       '2rrm': {'query': '2rrm', 'pdb': '4f02', 'chain': 'A', 'pdb_path': os.path.join(allosteric_pdb_dir, '4f02.pdb'),\n",
    "                                'aln_path': '/media/daniel/ExtraDrive1/Results/Allosteric_Data_Set/Output/U90/2rrm/ET-MEMER/Non-Gapped_Alignment.fa'},\n",
    "                       '1yap': {'query': '1yap', 'pdb': '4rex', 'chain': 'A', 'pdb_path': os.path.join(allosteric_pdb_dir, '4rex.pdb'),\n",
    "                                'aln_path': '/media/daniel/ExtraDrive1/Results/Allosteric_Data_Set/Output/U90/1yap/ET-MEMER/Non-Gapped_Alignment.fa'}}\n",
    "all_data = small_data_set.copy()\n",
    "all_data.update(allosteric_data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For all methods applied in this study\n",
    "Tracking the classes need and the parameters needed to execute each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_et_settings = {'polymer_type': 'Protein', 'et_distance': True, 'distance_model': 'blosum62', 'tree_building_method': 'et',\n",
    "                 'tree_building_options': {}, 'position_type': 'pair', 'gap_correction': None,\n",
    "                 'output_files': {'original_aln', 'non_gap_aln', 'tree', 'scores'}, 'processors': 10, 'low_memory': True}\n",
    "method_dict = {'DCA': {'Predictor': DCAWrapper, 'Settings': {}, 'RankType':'max', 'Scoring Params': {}},\n",
    "               'EVC Standard': {'Predictor': EVCouplingsWrapper, 'Settings': {'protocol': 'standard'}, 'RankType':'max', 'Scoring Params': {'cores': 10}},\n",
    "#                'EVC Mean Field': {'Predictor': EVCouplingsWrapper, 'Settings': {'protocol': 'mean_field'}, 'Scoring Params': {'cores': 10}},\n",
    "               'ET-MIp': {'Predictor': EvolutionaryTrace, 'RankType':'max', 'Scoring Params': {},\n",
    "                          'Settings': {'ranks': None, 'scoring_metric': 'filtered_average_product_corrected_mutual_information'}},               \n",
    "               'ET-MCM-': {'Predictor': EvolutionaryTrace, 'RankType':'max', 'Scoring Params': {},\n",
    "                           'Settings': {'ranks': None, 'scoring_metric': 'match_count'}},\n",
    "               'ET-M-MC': {'Predictor': EvolutionaryTrace, 'RankType':'max', 'Scoring Params': {},\n",
    "                           'Settings': {'ranks': None, 'scoring_metric': 'mismatch_count'}},\n",
    "               'ET-MCMCR': {'Predictor': EvolutionaryTrace, 'RankType':'max', 'Scoring Params': {},\n",
    "                            'Settings': {'ranks': None, 'scoring_metric': 'match_mismatch_count_ratio'}},\n",
    "               'ET-MCMCA': {'Predictor': EvolutionaryTrace, 'RankType':'max', 'Scoring Params': {},\n",
    "                            'Settings': {'ranks': None, 'scoring_metric': 'match_mismatch_count_angle'}},\n",
    "               \n",
    "               'ET-MEM-': {'Predictor': EvolutionaryTrace, 'RankType':'max', 'Scoring Params': {},\n",
    "                           'Settings': {'ranks': None, 'scoring_metric': 'match_entropy'}},\n",
    "               'ET-M-ME': {'Predictor': EvolutionaryTrace, 'RankType':'max', 'Scoring Params': {},\n",
    "                           'Settings': {'ranks': None, 'scoring_metric': 'mismatch_entropy'}},\n",
    "               'ET-MEMER': {'Predictor': EvolutionaryTrace, 'RankType':'max', 'Scoring Params': {},\n",
    "                           'Settings': {'ranks': None, 'scoring_metric': 'match_mismatch_entropy_ratio'}},\n",
    "               'ET-MEMEA': {'Predictor': EvolutionaryTrace, 'RankType':'max', 'Scoring Params': {},\n",
    "                           'Settings': {'ranks': None, 'scoring_metric': 'match_mismatch_entropy_angle'}},\n",
    "               \n",
    "               'ET-MDM-': {'Predictor': EvolutionaryTrace, 'RankType':'max', 'Scoring Params': {},\n",
    "                           'Settings': {'ranks': None, 'scoring_metric': 'match_diversity'}},\n",
    "               'ET-M-MD': {'Predictor': EvolutionaryTrace, 'RankType':'max', 'Scoring Params': {},\n",
    "                           'Settings': {'ranks': None, 'scoring_metric': 'mismatch_diversity'}},\n",
    "               'ET-MDMDR': {'Predictor': EvolutionaryTrace, 'RankType':'max', 'Scoring Params': {},\n",
    "                           'Settings': {'ranks': None, 'scoring_metric': 'match_mismatch_diversity_ratio'}},\n",
    "               'ET-MDMDA': {'Predictor': EvolutionaryTrace, 'RankType':'max', 'Scoring Params': {},\n",
    "                           'Settings': {'ranks': None, 'scoring_metric': 'match_mismatch_diversity_angle'}},\n",
    "               \n",
    "               'ET-MDMER': {'Predictor': EvolutionaryTrace, 'RankType':'max', 'Scoring Params': {},\n",
    "                           'Settings': {'ranks': None, 'scoring_metric': 'match_diversity_mismatch_entropy_ratio'}},\n",
    "               'ET-MDMEA': {'Predictor': EvolutionaryTrace, 'RankType':'max', 'Scoring Params': {},\n",
    "                           'Settings': {'ranks': None, 'scoring_metric': 'match_diversity_mismatch_entropy_angle'}},\n",
    "               'rvET': {'Predictor': EvolutionaryTrace, 'RankType':'max', 'Scoring Params': {},\n",
    "                        'Settings': {'ranks': None, 'scoring_metric': 'plain_entropy'}}}\n",
    "method_dict['ET-MIp']['Settings'].update(general_et_settings)\n",
    "\n",
    "method_dict['ET-MCM-']['Settings'].update(general_et_settings)\n",
    "method_dict['ET-M-MC']['Settings'].update(general_et_settings)\n",
    "method_dict['ET-MCMCR']['Settings'].update(general_et_settings)\n",
    "method_dict['ET-MCMCA']['Settings'].update(general_et_settings)\n",
    "\n",
    "method_dict['ET-MEM-']['Settings'].update(general_et_settings)\n",
    "method_dict['ET-M-ME']['Settings'].update(general_et_settings)\n",
    "method_dict['ET-MEMER']['Settings'].update(general_et_settings)\n",
    "method_dict['ET-MEMEA']['Settings'].update(general_et_settings)\n",
    "\n",
    "method_dict['ET-MDM-']['Settings'].update(general_et_settings)\n",
    "method_dict['ET-M-MD']['Settings'].update(general_et_settings)\n",
    "method_dict['ET-MDMDR']['Settings'].update(general_et_settings)\n",
    "method_dict['ET-MDMDA']['Settings'].update(general_et_settings)\n",
    "\n",
    "method_dict['ET-MDMER']['Settings'].update(general_et_settings)\n",
    "method_dict['ET-MDMEA']['Settings'].update(general_et_settings)\n",
    "\n",
    "method_dict['rvET']['Settings'].update(general_et_settings)\n",
    "method_dict['rvET']['Settings']['position_type'] = 'single'\n",
    "method_dict['rvET']['Settings']['gap_correction'] = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For plotting\n",
    "All variables to correctly order variables for plotting and to control plotting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the order of proteins, method, and separations for experiments and plotting\n",
    "full_protein_order = ['1c0k', '7hvp', '2b59', '206l', '1bol', '1jwl', '3q05', '2z0e', '2rh1', '4lli', '1h1v',\n",
    "                      '1c17', '1a26', '135l', '3b6v', '1yap', '1hck', '3tnu', '2wer', '1axb', '4ycu', '2ddr', '2rrm']\n",
    "method_order = ['DCA', 'EVC Standard', 'ET-MIp', 'ET-M-MD']\n",
    "method_labels = ['DCA', 'EVC', 'ET-MIp', 'CovET']\n",
    "et_method_order = ['rvET'] + method_order\n",
    "sequence_separation_order = ['Long', 'Medium', 'Short']\n",
    "# Results directories:\n",
    "small_data_out_dir = '/media/daniel/ExtraDrive1/Results/Newest_Covariation/Output/SmallTestSet'\n",
    "allosteric_data_out_dir = '/media/daniel/ExtraDrive1/Results/Allosteric_Data_Set/Domain_Specific_Min_ID_40/Output/ID40/U90'\n",
    "# Plotting variables\n",
    "mpl.rcParams['axes.linewidth'] = 3\n",
    "mpl.rcParams['xtick.major.width'] = 2\n",
    "mpl.rcParams['ytick.major.width'] = 2\n",
    "box_kwargs = {\n",
    "#     'facecolor': 'none',\n",
    "#     'edgecolor': 'black',\n",
    "    'boxprops':{'facecolor':'none', 'edgecolor':'black'},\n",
    "    'medianprops':{'color':'black'},\n",
    "    'whiskerprops':{'color':'black'},\n",
    "    'capprops':{'color':'black'},\n",
    "    'linewidth': 3,\n",
    "#     'whis': 100 # whis is set arbitrarily high to avoid defining outliers by Seaborn method\n",
    "    'whis': 1.5 # whis is set to the standard 1.5 x the IQR\n",
    "}\n",
    "\n",
    "# 'boxprops':{'facecolor':'none', 'edgecolor':'black'},\n",
    "#     'medianprops':{'color':'black'},\n",
    "#     'whiskerprops':{'color':'black'},\n",
    "#     'capprops':{'color':'black'}\n",
    "\n",
    "def determine_significance_level(p_val):\n",
    "    sig_lablel = None\n",
    "    if p_val < 0.001:\n",
    "        sig_label = '***'\n",
    "    elif p_val < 0.01:\n",
    "        sig_label = '**'\n",
    "    elif p_val < 0.05:\n",
    "        sig_label = '*'\n",
    "    elif p_val >= 0.05:\n",
    "        sig_label = 'ns'\n",
    "    else:\n",
    "        sig_lablel = 'error'\n",
    "    return sig_label\n",
    "\n",
    "def compute_wilcoxon_stats(data_type, df, data_dir):\n",
    "    stat_data_path = os.path.join(data_dir, f'{data_type}_Wilcoxon_Test_Comparison.tsv')\n",
    "    if os.path.isfile(stat_data_path):\n",
    "        stat_data_df = pd.read_csv(stat_data_path, header=0, index_col=None, sep='\\t')\n",
    "    else:\n",
    "        if 'Sequence Separation' in df.columns:\n",
    "            stats_data_dict = {'Method 1': [], 'Method 2': [], 'Sequence Separation': [],'Statistic': [], 'P-Value': [], 'Significance Label': []}\n",
    "            separations = df['Sequence Separation'].unique()\n",
    "            methods = df['Method'].unique()\n",
    "            for sep in separations:\n",
    "                for i in range(len(methods)):\n",
    "                    for j in range(i + 1, len(methods)):\n",
    "                        method1 = methods[i]\n",
    "                        method2 = methods[j]\n",
    "                        stat, p_value = wilcoxon(df.loc[(df['Method'] == method1) & (df['Sequence Separation'] == sep), data_type],\n",
    "                                                 df.loc[(df['Method'] == method2) & (df['Sequence Separation'] == sep), data_type])\n",
    "                        stats_data_dict['Sequence Separation'].append(sep)\n",
    "                        stats_data_dict['Method 1'].append(method1)\n",
    "                        stats_data_dict['Method 2'].append(method2)\n",
    "                        stats_data_dict['Statistic'].append(stat)\n",
    "                        stats_data_dict['P-Value'].append(p_value)\n",
    "                        stats_data_dict['Significance Label'].append(determine_significance_level(p_value))\n",
    "        else:\n",
    "            stats_data_dict = {'Method 1': [], 'Method 2': [],'Statistic': [], 'P-Value': [], 'Significance Label': []}\n",
    "            methods = df['Method'].unique()\n",
    "            for i in range(len(methods)):\n",
    "                for j in range(i + 1, len(methods)):\n",
    "                    method1 = methods[i]\n",
    "                    method2 = methods[j]\n",
    "                    stat, p_value = wilcoxon(df.loc[df['Method'] == method1, data_type],\n",
    "                                             df.loc[df['Method'] == method2, data_type])\n",
    "                    stats_data_dict['Method 1'].append(method1)\n",
    "                    stats_data_dict['Method 2'].append(method2)\n",
    "                    stats_data_dict['Statistic'].append(stat)\n",
    "                    stats_data_dict['P-Value'].append(p_value)\n",
    "                    stats_data_dict['Significance Label'].append(determine_significance_level(p_value))\n",
    "        stat_data_df = pd.DataFrame(stats_data_dict)\n",
    "        stat_data_df.to_csv(stat_data_path, header=True, index=False, sep='\\t')\n",
    "    return stat_data_df\n",
    "\n",
    "def plot_main_methods_box_and_whisker_plots_for_each_separation(metric_of_success, df, stat_df, out_dir, sep, y_min=0.0, y_max=1.0, y_ticks=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "                                                                significance_offset=0.025, significance_interval=0.075, significance_cap=0.02, font_size=32, stat_font_size=24):\n",
    "    if sep is None:\n",
    "        indices = df['Method'].notna()\n",
    "        stat_indices = stat_df['Method 1'].notna()\n",
    "    else:\n",
    "        indices = df[\"Sequence Separation\"] == sep\n",
    "        stat_indices = stat_df[\"Sequence Separation\"] == sep\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(1 + len(method_order), 1 + len(y_ticks)))\n",
    "\n",
    "    main_methods_plot = sns.boxplot(x='Method', y=metric_of_success, order=method_order, data=df.loc[indices,:], ax=ax, **box_kwargs)\n",
    "    sns.swarmplot(x='Method', y=metric_of_success, order=method_order, data=df.loc[indices,:], ax=main_methods_plot, dodge=True,\n",
    "                  hue='DataSet', hue_order=['SmallDataSet', 'AllostericDataSet'], palette={'SmallDataSet': 'dimgrey', 'AllostericDataSet': 'red'})\n",
    "\n",
    "    main_methods_plot.set_xticklabels(method_labels, rotation=90, fontsize=font_size)\n",
    "    main_methods_plot.set_xlabel('Method', fontsize=font_size)\n",
    "\n",
    "    main_methods_plot.set(ylim=(y_min, y_max))\n",
    "    main_methods_plot.set_yticks(y_ticks)\n",
    "    main_methods_plot.set_yticklabels(y_ticks, fontsize=font_size)\n",
    "    main_methods_plot.set_ylabel(main_methods_plot.get_ylabel(), fontsize=font_size)\n",
    "    # Add statistics to plot\n",
    "    max_value = df.loc[indices, metric_of_success].max()\n",
    "    # DCA vs ET-M-MD\n",
    "    dca_et_m_md_label = stat_df.loc[stat_indices & (stat_df['Method 1'] == 'DCA') & (stat_df['Method 2'] == 'ET-M-MD'), 'Significance Label'].values[0]\n",
    "    x1, x2 = 0, 3   # columns 'DCA' and 'ET-M-MD' (first column: 0, see plt.xticks())\n",
    "    y, h, col = max_value + significance_offset, significance_cap, 'k'\n",
    "    line = lines.Line2D([x1, x1, x2, x2], [y, y+h, y+h, y], lw=3, c=col, clip_on=False)\n",
    "    main_methods_plot.add_line(line)\n",
    "\n",
    "    plt.text(x1, y+h, dca_et_m_md_label, ha='center', va='bottom', color=col, fontsize=stat_font_size)\n",
    "    # EVCouplings vs ET-M-MD\n",
    "    evc_et_m_md_label = stat_df.loc[stat_indices & (stat_df['Method 1'] == 'EVC Standard') & (stat_df['Method 2'] == 'ET-M-MD'), 'Significance Label'].values[0]\n",
    "    x1, x2 = 1, 3   # columns 'EVC Standard' and 'ET-M-MD' (first column: 0, see plt.xticks())\n",
    "    y, h, col = max_value + (significance_offset + significance_interval), significance_cap, 'k'\n",
    "    line = lines.Line2D([x1, x1, x2, x2], [y, y+h, y+h, y], lw=3, c=col, clip_on=False)\n",
    "    main_methods_plot.add_line(line)\n",
    "\n",
    "    plt.text(x1, y+h, evc_et_m_md_label, ha='center', va='bottom', color=col, fontsize=stat_font_size)\n",
    "    # ET-MIp vs ET-M-MD\n",
    "    et_mip_et_m_md_label = stat_df.loc[stat_indices & (stat_df['Method 1'] == 'ET-MIp') & (stat_df['Method 2'] == 'ET-M-MD'), 'Significance Label'].values[0]\n",
    "    x1, x2 = 2, 3   # columns 'ET-MIp' and 'ET-M-MD' (first column: 0, see plt.xticks())\n",
    "    y, h, col = max_value + (significance_offset + (2 * significance_interval)), significance_cap, 'k'\n",
    "    line = lines.Line2D([x1, x1, x2, x2], [y, y+h, y+h, y], lw=3, c=col, clip_on=False)\n",
    "    main_methods_plot.add_line(line)\n",
    "\n",
    "    plt.text(x1, y+h, et_mip_et_m_md_label, ha='center', va='bottom', color=col, fontsize=stat_font_size)\n",
    "    # Remove right and top boarders so there is no conflict with significance markers\n",
    "    main_methods_plot.spines['right'].set_visible(False)\n",
    "    main_methods_plot.spines['top'].set_visible(False)\n",
    "    # Remove legend\n",
    "    main_methods_plot.legend_.remove()\n",
    "\n",
    "    main_methods_plot.get_figure().savefig(os.path.join(out_dir, f'{metric_of_success.replace(\" \", \"_\").replace(\"%\", \"\")}_Main_Methods_{\"_\" + sep if sep else \"\"}.png'),\n",
    "                                           bbox_inches='tight', transparent=True, dpi=500)\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate each method according to the different metrics of success:\n",
    "\n",
    "## AUROC\n",
    "This measures the True Positive Rate vs the False Positive Rate of prediction, it can be considered a measure of the accuracy of the measure. This can be strongly influenced by the class imbalance which is present when predicting structural contacts since there are many fewer contacts than non-contacts. The True Positive case is if the C-beta of two amino acids is within 8.0 Angstroms of one another (as is done in the CASP competitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create directory for AUROC results\n",
    "auroc_dir = os.path.join(output_dir, 'AUROC_Analyses')\n",
    "os.makedirs(auroc_dir, exist_ok=True)\n",
    "auroc_data_path = os.path.join(auroc_dir, 'Full_AUROC_Data.tsv')\n",
    "if os.path.isfile(auroc_data_path):\n",
    "    # Load AUROC data\n",
    "    auroc_data_df = pd.read_csv(auroc_data_path, header=0, index_col=None, sep='\\t')\n",
    "    auroc_data_dict = auroc_data_df.to_dict('series')\n",
    "    auroc_data_dict = {k: list(v) for k, v in auroc_data_dict.items()}\n",
    "    print(f\"Loaded: {len(set(auroc_data_dict['Protein']))} AUROCs\")\n",
    "else:\n",
    "    # Create dictionary to hold AUROC data\n",
    "    auroc_data_dict = {'Protein': [], 'DataSet': [], 'Method': [], 'Sequence Separation': [], 'AUROC': []}\n",
    "\n",
    "to_score = [x for x in full_protein_order if x in set(full_protein_order) - set(auroc_data_dict['Protein'])]\n",
    "print(f'{len(to_score)} proteins left to score')\n",
    "for protein in to_score:\n",
    "    for method in method_order:\n",
    "\n",
    "        if protein in small_data_set:\n",
    "            protein_dir = os.path.join(small_data_out_dir, protein)\n",
    "        elif protein in allosteric_data_set:\n",
    "            protein_dir = os.path.join(allosteric_data_out_dir, protein)\n",
    "        else:\n",
    "            raise ValueError('Bad protein: ', protein)\n",
    "\n",
    "        protein_settings = {'query': all_data[protein]['query'], 'aln_file': all_data[protein]['aln_path']}\n",
    "        # Then perform experiments for each method\n",
    "        # Set the result directory for this method\n",
    "        if method in ['ET-MCM-', 'ET-M-MC', 'ET-MCMCR', 'ET-MCMCA', 'ET-MEM-', 'ET-M-ME', 'ET-MEMER', 'ET-MEMEA',\n",
    "                      'ET-MDM-', 'ET-M-MD', 'ET-MDMDR', 'ET-MDMDA', 'ET-MDMER', 'ET-MDMEA']:\n",
    "            method_dir = os.path.join(protein_dir, 'ET-MEMER')\n",
    "        elif method in ['ET-MIp', 'cET-MIp']:\n",
    "            method_dir = os.path.join(protein_dir, 'ET-MIp')\n",
    "        else:\n",
    "            method_dir = os.path.join(protein_dir, method)\n",
    "        assert os.path.isdir(method_dir)\n",
    "        print(f'Attempting to load {method} covariance for: {protein}')\n",
    "        # Otherwise perform the experiment, beginning with compiling the compelte settings for this predictor\n",
    "        curr_settings = {'out_dir': method_dir}\n",
    "        curr_settings.update(protein_settings)\n",
    "        curr_settings.update(method_dict[method]['Settings'])\n",
    "        predictor = method_dict[method]['Predictor'](**curr_settings)\n",
    "        total_time = predictor.calculate_scores(**method_dict[method]['Scoring Params'])\n",
    "        print(f'Successfully loaded {method} covariance for: {protein}')\n",
    "\n",
    "        cb_contact_scorer = ContactScorer(query=all_data[protein]['query'], seq_alignment=os.path.join(method_dir, 'Non-Gapped_Alignment.fa'), pdb_reference=all_data[protein]['pdb_path'], cutoff=8.0, chain=all_data[protein]['chain'])\n",
    "        cb_contact_scorer.fit()\n",
    "        cb_contact_scorer.measure_distance(method='CB')\n",
    "        cb_contact_scorer.map_predictions_to_pdb(ranks=predictor.rankings, predictions=predictor.scores, coverages=predictor.coverages, threshold=0.5)\n",
    "\n",
    "        for sep in sequence_separation_order:\n",
    "            _, _, curr_auroc = cb_contact_scorer.score_auc(category=sep)\n",
    "            auroc_data_dict['Protein'].append(protein)\n",
    "            auroc_data_dict['DataSet'].append('SmallDataSet' if protein in small_data_set else 'AllostericDataSet')\n",
    "            auroc_data_dict['Method'].append(method)\n",
    "            auroc_data_dict['Sequence Separation'].append(sep)\n",
    "            auroc_data_dict['AUROC'].append(curr_auroc)\n",
    "    # After each protein is scored write results to file so they can be loaded if scoring is interrupted\n",
    "    auroc_data_df = pd.DataFrame(auroc_data_dict)\n",
    "    auroc_data_df.to_csv(auroc_data_path, header=True, index=False, sep='\\t')\n",
    "        \n",
    "        \n",
    "auroc_stat_df = compute_wilcoxon_stats('AUROC', auroc_data_df, auroc_dir)\n",
    "for sep in sequence_separation_order:\n",
    "    # Plot box and whisker plots comparing the AUROC for the main methods (DCA, EVCouplings, ET-MIp, and ET-M-MD) to each other at different sequence separations.\n",
    "    # for sep in sequence_separation_order:\n",
    "    plot_main_methods_box_and_whisker_plots_for_each_separation('AUROC', auroc_data_df, auroc_stat_df, auroc_dir, sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUPRC\n",
    "This measures the Precision vs the Recall of the predictions, it can be considered a measure of the accuracy of the measure. This is less strongly influenced by the class imbalance which is present when predicting structural contacts since there are many fewer contacts than non-contacts. The True Positive case is if the C-beta of two amino acids is within 8.0 Angstroms of one another (as is done in the CASP competitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for AUPRC results\n",
    "auprc_dir = os.path.join(output_dir, 'AUPRC_Analyses')\n",
    "os.makedirs(auprc_dir, exist_ok=True)\n",
    "auprc_data_path = os.path.join(auprc_dir, 'Full_AUPRC_Data.tsv')\n",
    "if os.path.isfile(auprc_data_path):\n",
    "    # Load AUPRC data\n",
    "    auprc_data_df = pd.read_csv(auprc_data_path, header=0, index_col=None, sep='\\t')\n",
    "    auprc_data_dict = auprc_data_df.to_dict('series')\n",
    "    auprc_data_dict = {k: list(v) for k, v in auprc_data_dict.items()}\n",
    "    print(f\"Loaded: {len(set(auprc_data_dict['Protein']))} AUPRCs\")\n",
    "else:\n",
    "    # Create dictionary to hold AUPRC data\n",
    "    auprc_data_dict = {'Protein': [], 'DataSet': [], 'Method': [], 'Sequence Separation': [], 'AUPRC': []}\n",
    "\n",
    "to_score = [x for x in full_protein_order if x in set(full_protein_order) - set(auprc_data_dict['Protein'])]\n",
    "print(f'{len(to_score)} proteins left to score')\n",
    "for protein in to_score:\n",
    "    for method in method_order:\n",
    "\n",
    "        if protein in small_data_set:\n",
    "            protein_dir = os.path.join(small_data_out_dir, protein)\n",
    "        elif protein in allosteric_data_set:\n",
    "            protein_dir = os.path.join(allosteric_data_out_dir, protein)\n",
    "        else:\n",
    "            raise ValueError('Bad protein')\n",
    "\n",
    "        protein_settings = {'query': all_data[protein]['query'], 'aln_file': all_data[protein]['aln_path']}\n",
    "        # Then perform experiments for each method\n",
    "        # Set the result directory for this method\n",
    "        if method in ['ET-MCM-', 'ET-M-MC', 'ET-MCMCR', 'ET-MCMCA', 'ET-MEM-', 'ET-M-ME', 'ET-MEMER', 'ET-MEMEA',\n",
    "                      'ET-MDM-', 'ET-M-MD', 'ET-MDMDR', 'ET-MDMDA', 'ET-MDMER', 'ET-MDMEA']:\n",
    "            method_dir = os.path.join(protein_dir, 'ET-MEMER')\n",
    "        elif method in ['ET-MIp', 'cET-MIp']:\n",
    "            method_dir = os.path.join(protein_dir, 'ET-MIp')\n",
    "        else:\n",
    "            method_dir = os.path.join(protein_dir, method)\n",
    "        assert os.path.isdir(method_dir)\n",
    "        print(f'Attempting to load {method} covariance for: {protein}')\n",
    "        # Otherwise perform the experiment, beginning with compiling the compelte settings for this predictor\n",
    "        curr_settings = {'out_dir': method_dir}\n",
    "        curr_settings.update(protein_settings)\n",
    "        curr_settings.update(method_dict[method]['Settings'])\n",
    "        predictor = method_dict[method]['Predictor'](**curr_settings)\n",
    "        total_time = predictor.calculate_scores(**method_dict[method]['Scoring Params'])\n",
    "        print(f'Successfully loaded {method} covariance for: {protein}')\n",
    "\n",
    "        cb_contact_scorer = ContactScorer(query=all_data[protein]['query'], seq_alignment=os.path.join(method_dir, 'Non-Gapped_Alignment.fa'), pdb_reference=all_data[protein]['pdb_path'], cutoff=8.0, chain=all_data[protein]['chain'])\n",
    "        cb_contact_scorer.fit()\n",
    "        cb_contact_scorer.measure_distance(method='CB')\n",
    "        cb_contact_scorer.map_predictions_to_pdb(ranks=predictor.rankings, predictions=predictor.scores, coverages=predictor.coverages, threshold=0.5)\n",
    "\n",
    "        for sep in sequence_separation_order:\n",
    "            _, _, curr_auprc = cb_contact_scorer.score_precision_recall(category=sep)\n",
    "            auprc_data_dict['Protein'].append(protein)\n",
    "            auprc_data_dict['DataSet'].append('SmallDataSet' if protein in small_data_set else 'AllostericDataSet')\n",
    "            auprc_data_dict['Method'].append(method)\n",
    "            auprc_data_dict['Sequence Separation'].append(sep)\n",
    "            auprc_data_dict['AUPRC'].append(curr_auprc)\n",
    "    # After each protein is scored write results to file so they can be loaded if scoring is interrupted\n",
    "    auprc_data_df = pd.DataFrame(auprc_data_dict)\n",
    "    auprc_data_df.to_csv(auprc_data_path, header=True, index=False, sep='\\t')\n",
    "        \n",
    "        \n",
    "auprc_stat_df = compute_wilcoxon_stats('AUPRC', auprc_data_df, auprc_dir)\n",
    "for sep in sequence_separation_order:\n",
    "    # Plot box and whisker plots comparing the AUPRC for the main methods (DCA, EVCouplings, ET-MIp, and ET-M-MD) to each other at different sequence separations.\n",
    "    # for sep in sequence_separation_order:\n",
    "    plot_main_methods_box_and_whisker_plots_for_each_separation('AUPRC', auprc_data_df, auprc_stat_df, auprc_dir, sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection Clustering Weighting Z-Score\n",
    "This measures whether highly ranked residues are randomly distributed over the protein structure or whether they cluster in a meaningful way. In previous work, high clustering z-scores have been shown to correspond with key structural and functional sites. Two types of clustering are explored here; unbiased clustering, which looks just at the position of highly ranked residues on the protein structure, and biased clustering, which weights the spatial clustering by the sequence separation of residues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create directory for SCW Z-Score results\n",
    "scw_dir = os.path.join(output_dir, 'SCW_Z-Score_Analyses')\n",
    "os.makedirs(scw_dir, exist_ok=True)\n",
    "scw_data_path = os.path.join(scw_dir, 'Full_SCW_Z-Score_Data.tsv')\n",
    "if os.path.isfile(scw_data_path):\n",
    "    # Load SCW data\n",
    "    scw_data_df = pd.read_csv(scw_data_path, header=0, index_col=None, sep='\\t')\n",
    "    scw_data_dict = scw_data_df.to_dict('series')\n",
    "    scw_data_dict = {k: list(v) for k, v in scw_data_dict.items()}\n",
    "    print(f\"Loaded: {len(set(scw_data_dict['Protein']))} SCW Z-Scores\")\n",
    "else:\n",
    "    # Create dictionary to hold SCW data\n",
    "    scw_data_dict = {'Protein': [], 'DataSet': [], 'Method': [],\n",
    "                     'Biased SCW Z-Score (2%)': [], 'Biased SCW Z-Score (2.5%)': [], 'Biased SCW Z-Score (4%)': [], 'Biased SCW Z-Score (5%)': [], 'Biased SCW Z-Score (6%)': [], 'Biased SCW Z-Score (7.5%)': [],\n",
    "                     'Biased SCW Z-Score (8%)': [], 'Biased SCW Z-Score (10%)': [], 'Biased SCW Z-Score (15%)': [], 'Biased SCW Z-Score (20%)': [], 'Biased SCW Z-Score (30%)': [],\n",
    "                     'Unbiased SCW Z-Score (2%)': [], 'Unbiased SCW Z-Score (2.5%)': [], 'Unbiased SCW Z-Score (4%)': [], 'Unbiased SCW Z-Score (5%)': [], 'Unbiased SCW Z-Score (6%)': [], 'Unbiased SCW Z-Score (7.5%)': [],\n",
    "                     'Unbiased SCW Z-Score (8%)': [], 'Unbiased SCW Z-Score (10%)': [], 'Unbiased SCW Z-Score (15%)': [], 'Unbiased SCW Z-Score (20%)': [], 'Unbiased SCW Z-Score (30%)': [], #}\n",
    "                     'Average Sequence Separation (2%)': [], 'Average Sequence Separation (2.5%)': [], 'Average Sequence Separation (4%)': [], 'Average Sequence Separation (5%)': [],\n",
    "                     'Average Sequence Separation (6%)': [], 'Average Sequence Separation (7.5%)': [], 'Average Sequence Separation (8%)': [], 'Average Sequence Separation (10%)': [],\n",
    "                     'Average Sequence Separation (15%)': [], 'Average Sequence Separation (20%)': [], 'Average Sequence Separation (30%)': []}\n",
    "\n",
    "to_score = [x for x in full_protein_order if x in set(full_protein_order) - set(scw_data_dict['Protein'])]\n",
    "print(f'{len(to_score)} proteins left to score')\n",
    "for protein in to_score:\n",
    "    unbiased_scw_scorer = None\n",
    "    biased_scw_scorer = None\n",
    "    for method in method_order:\n",
    "\n",
    "        if protein in small_data_set:\n",
    "            protein_dir = os.path.join(small_data_out_dir, protein)\n",
    "        elif protein in allosteric_data_set:\n",
    "            protein_dir = os.path.join(allosteric_data_out_dir, protein)\n",
    "        else:\n",
    "            raise ValueError('Bad protein')\n",
    "\n",
    "        protein_settings = {'query': all_data[protein]['query'], 'aln_file': all_data[protein]['aln_path']}\n",
    "        # Then perform experiments for each method\n",
    "        # Set the result directory for this method\n",
    "        if method in ['ET-MCM-', 'ET-M-MC', 'ET-MCMCR', 'ET-MCMCA', 'ET-MEM-', 'ET-M-ME', 'ET-MEMER', 'ET-MEMEA',\n",
    "                      'ET-MDM-', 'ET-M-MD', 'ET-MDMDR', 'ET-MDMDA', 'ET-MDMER', 'ET-MDMEA']:\n",
    "            method_dir = os.path.join(protein_dir, 'ET-MEMER')\n",
    "        elif method in ['ET-MIp', 'cET-MIp']:\n",
    "            method_dir = os.path.join(protein_dir, 'ET-MIp')\n",
    "        else:\n",
    "            method_dir = os.path.join(protein_dir, method)\n",
    "        assert os.path.isdir(method_dir)\n",
    "        print(f'Attempting to load {method} covariance for: {protein}')\n",
    "        # Otherwise perform the experiment, beginning with compiling the compelte settings for this predictor\n",
    "        curr_settings = {'out_dir': method_dir}\n",
    "        curr_settings.update(protein_settings)\n",
    "        curr_settings.update(method_dict[method]['Settings'])\n",
    "        predictor = method_dict[method]['Predictor'](**curr_settings)\n",
    "        total_time = predictor.calculate_scores(**method_dict[method]['Scoring Params'])\n",
    "        print(f'Successfully loaded {method} covariance for: {protein}')\n",
    "\n",
    "        print('Creating Scorer')\n",
    "        any_contact_scorer = ContactScorer(query=all_data[protein]['query'], seq_alignment=os.path.join(method_dir, 'Non-Gapped_Alignment.fa'), pdb_reference=all_data[protein]['pdb_path'], cutoff=8.0, chain=all_data[protein]['chain'])\n",
    "        print('Fitting Scorer')\n",
    "        any_contact_scorer.fit()\n",
    "        print('Measuring Distance')\n",
    "        any_contact_scorer.measure_distance(method='Any')\n",
    "        print('Mapping Predictions to Scorer')\n",
    "        any_contact_scorer.map_predictions_to_pdb(ranks=predictor.rankings, predictions=predictor.scores, coverages=predictor.coverages, threshold=0.5)\n",
    "\n",
    "        print('Scoring SCW Z-Scores')\n",
    "        z_score_biased, biased_scw_scorer, _ = any_contact_scorer.score_clustering_of_contact_predictions(\n",
    "        biased=True, file_path=os.path.join(scw_dir, f'{protein}_{method}_Biased_SCW_Z-Score.tsv'), scw_scorer=biased_scw_scorer, processes=10)\n",
    "        z_score_unbiased, unbiased_scw_scorer, _ = any_contact_scorer.score_clustering_of_contact_predictions(\n",
    "        biased=False, file_path=os.path.join(scw_dir, f'{protein}_{method}_Unbiased_SCW_Z-Score.tsv'), scw_scorer=unbiased_scw_scorer, processes=10)\n",
    "        for percentile in [2, 2.5, 4, 5, 6, 7.5, 8, 10, 15, 20, 30]:\n",
    "            percentage = percentile / 100.0\n",
    "            try:\n",
    "                top_biased_preds = z_score_biased.loc[z_score_biased['Residue Coverage'] <= percentage, ['Res_i', 'Res_j', 'Z-Score']]\n",
    "                scw_data_dict[f'Biased SCW Z-Score ({percentile}%)'].append(top_biased_preds['Z-Score'].iloc[-1])\n",
    "                top_biased_preds['SeqSep'] = top_biased_preds.apply(lambda x: x['Res_j'] - x['Res_i'], axis=1)\n",
    "                scw_data_dict[f'Average Sequence Separation ({percentile}%)'].append(top_biased_preds['SeqSep'].mean())\n",
    "            except IndexError:\n",
    "                scw_data_dict[f'Biased SCW Z-Score ({percentile}%)'].append(None)\n",
    "                scw_data_dict[f'Average Sequence Separation ({percentile}%)'].append(None)\n",
    "            try:\n",
    "                scw_data_dict[f'Unbiased SCW Z-Score ({percentile}%)'].append(z_score_unbiased.loc[z_score_unbiased['Residue Coverage'] <= percentage, 'Z-Score'].iloc[-1])\n",
    "            except IndexError:\n",
    "                scw_data_dict[f'Unbiased SCW Z-Score ({percentile}%)'].append(None)\n",
    "\n",
    "        scw_data_dict['Protein'].append(protein)\n",
    "        scw_data_dict['DataSet'].append('SmallDataSet' if protein in small_data_set else 'AllostericDataSet')\n",
    "        scw_data_dict['Method'].append(method)\n",
    "    # After each protein is scored write results to file so they can be loaded if scoring is interrupted\n",
    "    scw_data_df = pd.DataFrame(scw_data_dict)\n",
    "    scw_data_df.to_csv(scw_data_path, header=True, index=False, sep='\\t')\n",
    "        \n",
    "        \n",
    "print(scw_data_df[['Biased SCW Z-Score (30%)', 'Unbiased SCW Z-Score (30%)', 'Average Sequence Separation (30%)']].min())\n",
    "print(scw_data_df[['Biased SCW Z-Score (30%)', 'Unbiased SCW Z-Score (30%)', 'Average Sequence Separation (30%)']].max())\n",
    "        \n",
    "biased_scw_stat_df = compute_wilcoxon_stats('Biased SCW Z-Score (30%)', scw_data_df, scw_dir)\n",
    "unbiased_scw_stat_df = compute_wilcoxon_stats('Unbiased SCW Z-Score (30%)', scw_data_df, scw_dir)\n",
    "seq_sep_stat_df = compute_wilcoxon_stats('Average Sequence Separation (30%)', scw_data_df, scw_dir)\n",
    "# Plot box and whisker plots comparing the SCW for the main methods (DCA, EVCouplings, ET-MIp, and ET-M-MD) to each other at different sequence separations.\n",
    "plot_main_methods_box_and_whisker_plots_for_each_separation('Biased SCW Z-Score (30%)', scw_data_df, biased_scw_stat_df, scw_dir, None, y_min=-4, y_max=22, y_ticks=[-4, -2, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22],\n",
    "                                                            significance_offset=0.25, significance_interval=0.75, significance_cap=0.2)\n",
    "plot_main_methods_box_and_whisker_plots_for_each_separation('Unbiased SCW Z-Score (30%)', scw_data_df, unbiased_scw_stat_df, scw_dir, None, y_min=-4, y_max=22, y_ticks=[-4, -2, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22],\n",
    "                                                            significance_offset=0.25, significance_interval=0.75, significance_cap=0.2)\n",
    "plot_main_methods_box_and_whisker_plots_for_each_separation('Average Sequence Separation (30%)', scw_data_df, seq_sep_stat_df, scw_dir, None, y_min=0, y_max=140,\n",
    "                                                            y_ticks=[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140],\n",
    "#                                                             y_ticks=[0, 15, 30, 45, 60, 75, 90, 105, 120, 135, 150],\n",
    "                                                            significance_offset=2.5, significance_interval=7.5, significance_cap=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In depth analysis of rvET overlap, key residue overlap, covariation networks, and allosteric interactions\n",
    "\n",
    "## Visualizating residues from rvET and covariation predictions and measuring their overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create directory for rvET and covariation residue visualization and overlap measurement\n",
    "residue_viz_dir = os.path.join(output_dir, 'Structural_Residue_Visualization')\n",
    "os.makedirs(residue_viz_dir, exist_ok=True)\n",
    "\n",
    "for protein in ['1axb']: # allosteric_data_set:\n",
    "    top_rvET_residues = {}\n",
    "    rvET_overlap_data = {'rvET Residues': [], 'Method': [], 'Covariation Residues': [], 'Coverage Cutoff': [],\n",
    "                         'X (Sample Successes)': [], 'M (Population Size)': [], 'n (Population Successes)': [], 'N (Sample_size)': [], 'Hypergeometric P-Value': []}\n",
    "    for method in et_method_order:\n",
    "\n",
    "        if protein in small_data_set:\n",
    "            protein_dir = os.path.join(small_data_out_dir, protein)\n",
    "        elif protein in allosteric_data_set:\n",
    "            protein_dir = os.path.join(allosteric_data_out_dir, protein)\n",
    "        else:\n",
    "            raise ValueError('Bad protein')\n",
    "\n",
    "        protein_settings = {'query': all_data[protein]['query'], 'aln_file': all_data[protein]['aln_path']}\n",
    "        # Then perform experiments for each method\n",
    "        # Set the result directory for this method\n",
    "        if method in ['ET-MCM-', 'ET-M-MC', 'ET-MCMCR', 'ET-MCMCA', 'ET-MEM-', 'ET-M-ME', 'ET-MEMER', 'ET-MEMEA',\n",
    "                      'ET-MDM-', 'ET-M-MD', 'ET-MDMDR', 'ET-MDMDA', 'ET-MDMER', 'ET-MDMEA']:\n",
    "            method_dir = os.path.join(protein_dir, 'ET-MEMER')\n",
    "        elif method in ['ET-MIp', 'cET-MIp']:\n",
    "            method_dir = os.path.join(protein_dir, 'ET-MIp')\n",
    "        else:\n",
    "            method_dir = os.path.join(protein_dir, method)\n",
    "        print(method_dir)\n",
    "        assert os.path.isdir(method_dir)\n",
    "        print(f'Attempting to load {method} covariance for: {protein}')\n",
    "        # Otherwise perform the experiment, beginning with compiling the compelte settings for this predictor\n",
    "        curr_settings = {'out_dir': method_dir}\n",
    "        curr_settings.update(protein_settings)\n",
    "        curr_settings.update(method_dict[method]['Settings'])\n",
    "        predictor = method_dict[method]['Predictor'](**curr_settings)\n",
    "        total_time = predictor.calculate_scores(**method_dict[method]['Scoring Params'])\n",
    "        print(f'Successfully loaded {method} covariance for: {protein}')\n",
    "\n",
    "        if method == 'rvET':\n",
    "            prediction_scorer = SinglePositionScorer(query=all_data[protein]['query'], seq_alignment=os.path.join(method_dir, 'Non-Gapped_Alignment.fa'), pdb_reference=all_data[protein]['pdb_path'], chain=all_data[protein]['chain'])\n",
    "        else:\n",
    "            prediction_scorer = ContactScorer(query=all_data[protein]['query'], seq_alignment=os.path.join(method_dir, 'Non-Gapped_Alignment.fa'), pdb_reference=all_data[protein]['pdb_path'], cutoff=8.0,\n",
    "                                              chain=all_data[protein]['chain'])\n",
    "        prediction_scorer.fit()\n",
    "        prediction_scorer.measure_distance(method='Any')\n",
    "        prediction_scorer.map_predictions_to_pdb(ranks=predictor.rankings, predictions=predictor.scores, coverages=predictor.coverages, threshold=0.5)\n",
    "\n",
    "        coverage_cutoffs = [0.3, 0.2, 0.15, 0.1]\n",
    "        if protein == '2ddr':\n",
    "            coverage_cutoffs = [0.3, 0.28, 0.26, 0.24, 0.22, 0.2, 0.18, 0.16, 0.15, 0.14, 0.12, 0.1, 0.08, 0.075, 0.06, 0.05, 0.04, 0.025, 0.02]\n",
    "        for cov_cutoff in coverage_cutoffs:\n",
    "            # category='Any' set by default for ContactScorer, not needed for SinglePositionScorer\n",
    "            _, _, top_res = prediction_scorer.select_and_color_residues(out_dir=residue_viz_dir, n=None, k=None, residue_coverage=cov_cutoff,\n",
    "                                                                        fn=f'{protein}_{method}_residues_Chain_{prediction_scorer.query_pdb_mapper.best_chain}_threshold_{cov_cutoff}')\n",
    "            if method == 'rvET':\n",
    "                top_rvET_residues[cov_cutoff] = top_res\n",
    "            else:\n",
    "                rvET_hyper_geom_test = prediction_scorer.score_pdb_residue_identification(pdb_residues=top_rvET_residues[cov_cutoff], coverage_cutoff=cov_cutoff)\n",
    "                rvET_overlap_data['rvET Residues'].append('select resi ' + '+'.join([str(x) for x in top_rvET_residues[cov_cutoff]]))\n",
    "                rvET_overlap_data['Method'].append(method)\n",
    "                rvET_overlap_data['Covariation Residues'].append('select resi ' + '+'.join([str(x) for x in top_res]))\n",
    "                rvET_overlap_data['Coverage Cutoff'].append(cov_cutoff)\n",
    "                rvET_overlap_data['X (Sample Successes)'].append(rvET_hyper_geom_test[0])\n",
    "                rvET_overlap_data['M (Population Size)'].append(rvET_hyper_geom_test[1])\n",
    "                rvET_overlap_data['n (Population Successes)'].append(rvET_hyper_geom_test[2])\n",
    "                rvET_overlap_data['N (Sample_size)'].append(rvET_hyper_geom_test[3])\n",
    "                rvET_overlap_data['Hypergeometric P-Value'].append(rvET_hyper_geom_test[4])\n",
    "    rvET_overlap_df = pd.DataFrame(rvET_overlap_data)\n",
    "    rvET_overlap_df.to_csv(os.path.join(residue_viz_dir, f'{protein}_rvET_vs_Covariation_Coverage_Overlap_Significance.tsv'), header=True, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing networks from covariation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create directory for covariation network visualization\n",
    "struct_viz_dir = os.path.join(output_dir, 'Structural_Network_Visualization')\n",
    "os.makedirs(struct_viz_dir, exist_ok=True)\n",
    "\n",
    "for protein in ['1axb']: # allosteric_data_set:\n",
    "    for method in method_order:\n",
    "\n",
    "        if protein in small_data_set:\n",
    "            protein_dir = os.path.join(small_data_out_dir, protein)\n",
    "        elif protein in allosteric_data_set:\n",
    "            protein_dir = os.path.join(allosteric_data_out_dir, protein)\n",
    "        else:\n",
    "            raise ValueError('Bad protein')\n",
    "\n",
    "        protein_settings = {'query': all_data[protein]['query'], 'aln_file': all_data[protein]['aln_path']}\n",
    "        # Then perform experiments for each method\n",
    "        # Set the result directory for this method\n",
    "        if method in ['ET-MCM-', 'ET-M-MC', 'ET-MCMCR', 'ET-MCMCA', 'ET-MEM-', 'ET-M-ME', 'ET-MEMER', 'ET-MEMEA',\n",
    "                      'ET-MDM-', 'ET-M-MD', 'ET-MDMDR', 'ET-MDMDA', 'ET-MDMER', 'ET-MDMEA']:\n",
    "            method_dir = os.path.join(protein_dir, 'ET-MEMER')\n",
    "        elif method in ['ET-MIp', 'cET-MIp']:\n",
    "            method_dir = os.path.join(protein_dir, 'ET-MIp')\n",
    "        else:\n",
    "            method_dir = os.path.join(protein_dir, method)\n",
    "        assert os.path.isdir(method_dir)\n",
    "        print(f'Attempting to load {method} covariance for: {protein}')\n",
    "        # Otherwise perform the experiment, beginning with compiling the compelte settings for this predictor\n",
    "        curr_settings = {'out_dir': method_dir}\n",
    "        curr_settings.update(protein_settings)\n",
    "        curr_settings.update(method_dict[method]['Settings'])\n",
    "        predictor = method_dict[method]['Predictor'](**curr_settings)\n",
    "        total_time = predictor.calculate_scores(**method_dict[method]['Scoring Params'])\n",
    "        print(f'Successfully loaded {method} covariance for: {protein}')\n",
    "\n",
    "        any_contact_scorer = ContactScorer(query=all_data[protein]['query'], seq_alignment=os.path.join(method_dir, 'Non-Gapped_Alignment.fa'), pdb_reference=all_data[protein]['pdb_path'], cutoff=8.0,\n",
    "                                           chain=all_data[protein]['chain'])\n",
    "        any_contact_scorer.fit()\n",
    "        any_contact_scorer.measure_distance(method='Any')\n",
    "        any_contact_scorer.map_predictions_to_pdb(ranks=predictor.rankings, predictions=predictor.scores, coverages=predictor.coverages, threshold=0.5)\n",
    "\n",
    "        coverage_cutoffs = [0.3, 0.2, 0.15, 0.1]\n",
    "        if protein == '2ddr':\n",
    "            coverage_cutoffs = [0.3, 0.28, 0.26, 0.24, 0.22, 0.2, 0.18, 0.16, 0.15, 0.14, 0.12, 0.1, 0.08, 0.075, 0.06, 0.05, 0.04, 0.025, 0.02]\n",
    "        for cov_cutoff in coverage_cutoffs:\n",
    "            print(f'Coverage Cutoff: {cov_cutoff}')\n",
    "            any_contact_scorer.select_and_display_pairs(out_dir=struct_viz_dir, category='Any', n=None, k=None, residue_coverage=cov_cutoff,\n",
    "                                                        fn=f'{protein}_{method}_pairs_Chain_{any_contact_scorer.query_pdb_mapper.best_chain}_threshold_{cov_cutoff}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure the overlap of predictions with known key sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key motifs, functional, and structural residues\n",
    "key_residues = {'2ddr': {'water_channel': [52, 76, 80, 418, 422, 423],\n",
    "                         'tm2-7_link': [80, 422],\n",
    "                         'ligand_binding': [41, 83, 117, 118, 193, 199, 205, 379, 414, 419],\n",
    "                         'stabilize_inactive': [122, 201, 382, 418],\n",
    "                         'beta_ionone_binding': [122, 201, 386],\n",
    "                         'dry': [131, 132, 133],\n",
    "                         'hhm': [125, 382, 378, 379],\n",
    "                         'ionic_lock': [132, 368],\n",
    "                         'tm3-5_link': [132, 209],\n",
    "                         'tm5-6_link': [198, 386],\n",
    "                         'broken_ionic_lock': [209, 426],\n",
    "                         'ms_tm6': [382],\n",
    "                         'cwxp': [385, 386, 388],\n",
    "                         'npxxyx_f': [422, 423, 426, 433],\n",
    "                         'tm7_cterm_link': [426, 433],\n",
    "                         'all_key_res': [41, 52, 76, 80, 83, 117, 118, 122, 125, 131, 132, 133, 193,198, 199, 201, 205, 209, 368, 378, 379, 382, 385, 386, 388, 414, 418, 419, 422, 423, 426, 433]},\n",
    "                '2rrm': {'rnp1': [138, 139, 140, 141, 142, 143, 144, 145],\n",
    "                         'rnp2': [101, 102, 103, 104, 105, 106],\n",
    "                         'all_key_res': [101, 102, 103, 104, 105, 106, 138, 139, 140, 141, 142, 143, 144, 145]},\n",
    "                '1yap': {'ww': [177, 199],\n",
    "                         'binding': [188, 190, 192, 196, 197, 199],\n",
    "                         'hydrophobic_cluster_1': [174, 177, 189, 191, 198,202],\n",
    "                         'hydrogen_bonds': [177, 193, 194, 196],\n",
    "                         'hydropobic_patch': [173, 174, 189, 202],\n",
    "                         'hydrophobic_cluster_2': [178, 180, 188, 190, 192, 197, 199],\n",
    "                         'hydrophobic_pocket': [190, 192, 195],\n",
    "                         'all_key_res': [173, 174, 177, 178, 180, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 202],\n",
    "                         'insensitive_n_term': [164, 165, 166, 167, 168, 169, 170, 171, 172],\n",
    "                         'insensitive_turns': [175, 183, 184, 193, 200],\n",
    "                         'insensitive_c_term': [204, 205, 206, 207],\n",
    "                         'all_insensitive_res': [164, 165, 166, 167, 168, 169, 170, 171, 172, 175, 183, 184, 193, 200, 204, 205, 206, 207]},\n",
    "                '1axb': {'binding_cat': [70, 130, 132, 166, 170, 234, 235, 236, 237],\n",
    "                         '5A_binding_cat': [68, 69, 71, 72, 73, 74, 103, 104, 105, 106, 125, 126, 127, 128, 129, 131, 133, 134, 135, 136, 164, 165, 167, 168, 169, 171, 172, 211, 214, 216, 217,\n",
    "                                            220, 232, 233, 238, 240, 243, 244, 245, 246, 247, 272, 276],\n",
    "                         'co-varying core': [72, 76, 80, 138, 142, 148],\n",
    "                         'disulfide bridge': [77, 123],\n",
    "                         'disulfide bridge in Sme-1': [69, 238],\n",
    "                         'folding determinate': [229, 259, 290],\n",
    "                         'all_key_res': [68, 69, 70, 71, 72, 73, 74, 76, 77, 80, 103, 104, 105, 106, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 142, 148, 164, 165, 166, 167, 168, 169,\n",
    "                                         170, 171, 172, 211, 214, 216, 217, 220, 229, 232, 233, 234, 235, 236, 237, 238, 240, 243, 244, 245, 246, 247, 259, 272, 276, 290]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create directory for covariation network visualization\n",
    "overlap_dir = os.path.join(output_dir, 'Key_Site_Overlap')\n",
    "os.makedirs(overlap_dir, exist_ok=True)\n",
    "\n",
    "for protein in key_residues: # ['1axb']: #  allosteric_data_set:\n",
    "    for method in et_method_order:\n",
    "\n",
    "        if protein in small_data_set:\n",
    "            protein_dir = os.path.join(small_data_out_dir, protein)\n",
    "        elif protein in allosteric_data_set:\n",
    "            protein_dir = os.path.join(allosteric_data_out_dir, protein)\n",
    "        else:\n",
    "            raise ValueError('Bad protein')\n",
    "\n",
    "        protein_settings = {'query': all_data[protein]['query'], 'aln_file': all_data[protein]['aln_path']}\n",
    "        # Then perform experiments for each method\n",
    "        # Set the result directory for this method\n",
    "        if method in ['ET-MCM-', 'ET-M-MC', 'ET-MCMCR', 'ET-MCMCA', 'ET-MEM-', 'ET-M-ME', 'ET-MEMER', 'ET-MEMEA',\n",
    "                      'ET-MDM-', 'ET-M-MD', 'ET-MDMDR', 'ET-MDMDA', 'ET-MDMER', 'ET-MDMEA']:\n",
    "            method_dir = os.path.join(protein_dir, 'ET-MEMER')\n",
    "        elif method in ['ET-MIp', 'cET-MIp']:\n",
    "            method_dir = os.path.join(protein_dir, 'ET-MIp')\n",
    "        else:\n",
    "            method_dir = os.path.join(protein_dir, method)\n",
    "        assert os.path.isdir(method_dir)\n",
    "        print(f'Attempting to load {method} covariance for: {protein}')\n",
    "        # Otherwise perform the experiment, beginning with compiling the compelte settings for this predictor\n",
    "        curr_settings = {'out_dir': method_dir}\n",
    "        curr_settings.update(protein_settings)\n",
    "        curr_settings.update(method_dict[method]['Settings'])\n",
    "        predictor = method_dict[method]['Predictor'](**curr_settings)\n",
    "        total_time = predictor.calculate_scores(**method_dict[method]['Scoring Params'])\n",
    "        print(f'Successfully loaded {method} covariance for: {protein}')\n",
    "\n",
    "        if method == 'rvET':\n",
    "            pred_scorer = SinglePositionScorer(query=all_data[protein]['query'], seq_alignment=os.path.join(method_dir, 'Non-Gapped_Alignment.fa'), pdb_reference=all_data[protein]['pdb_path'],\n",
    "                                               chain=all_data[protein]['chain'])\n",
    "        else:\n",
    "            pred_scorer = ContactScorer(query=all_data[protein]['query'], seq_alignment=os.path.join(method_dir, 'Non-Gapped_Alignment.fa'), pdb_reference=all_data[protein]['pdb_path'], cutoff=8.0,\n",
    "                                               chain=all_data[protein]['chain'])\n",
    "        pred_scorer.fit()\n",
    "        pred_scorer.measure_distance(method='Any')\n",
    "        pred_scorer.map_predictions_to_pdb(ranks=predictor.rankings, predictions=predictor.scores, coverages=predictor.coverages, threshold=0.5)\n",
    "\n",
    "        \n",
    "        \n",
    "        coverage_cutoffs = [0.3, 0.2, 0.15, 0.1]\n",
    "        if protein == '2ddr':\n",
    "            coverage_cutoffs = [0.3, 0.28, 0.26, 0.24, 0.22, 0.2, 0.18, 0.16, 0.15, 0.14, 0.12, 0.1, 0.08, 0.075, 0.06, 0.05, 0.04, 0.025, 0.02]\n",
    "        \n",
    "        for cov_cutoff in coverage_cutoffs:\n",
    "            print(f'Coverage cutoff: {cov_cutoff}')\n",
    "            overlap_data = {'Selection': [], 'X (Sample Successes)': [], 'M (Population Size)': [], 'n (Population Successes)': [], 'N (Sample_size)': [], 'Hypergeometric P-Value': []}\n",
    "            for sel in key_residues[protein]:\n",
    "                print(f'\\tSelection: {sel}')\n",
    "                hyper_geom_test = pred_scorer.score_pdb_residue_identification(pdb_residues=key_residues[protein][sel], coverage_cutoff=cov_cutoff)\n",
    "                overlap_data['Selection'].append(sel)\n",
    "                overlap_data['X (Sample Successes)'].append(hyper_geom_test[0])\n",
    "                overlap_data['M (Population Size)'].append(hyper_geom_test[1])\n",
    "                overlap_data['n (Population Successes)'].append(hyper_geom_test[2])\n",
    "                overlap_data['N (Sample_size)'].append(hyper_geom_test[3])\n",
    "                overlap_data['Hypergeometric P-Value'].append(hyper_geom_test[4])\n",
    "            overlap_df = pd.DataFrame(overlap_data)\n",
    "            overlap_df.to_csv(os.path.join(overlap_dir, f'{method}_overlap_key_{protein}_residues_hypergemetric_test_{cov_cutoff}_coverage.tsv'), header=True, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load rvET covariance for: 2ddr\n",
      "Removing gaps took 0.0006339351336161295 min\n",
      "Evolutionary Trace analysis with the same parameters already saved to this location.\n",
      "0.046736955642700195\n",
      "Successfully loaded rvET covariance for: 2ddr\n",
      "Importing the PDB file took 0.0007770140965779622 min\n",
      "MDPLNLSWYDDDLERQNWSRPFNGSDGKADRPHYNYYATLLTLLIAVIVFGNVLVCMAVSREKALQTTTNYLIVSLAVADLLVATLVMPWVVYLEVVGEWKFSRIHCDIFVTLDVMMCTASILNLCAISIDRYTAVAMPMLYNTRYSSKRRVTVMISIVWVLSFTISCPLLFGLNNADQNECIIANPAFVVYSSIVSFYVPFIVTLLVYIKIYIVLRRRRKRVNTKRSSRAFRAHLRAPLKGNCTHPEDMKLCTVIMKSNGSFPVNRRRVEAARRAQELEMEMLSSTSPPERTRYSPIPPSHHQLTLPDPSHHGLHSTPDSPAKPEKNGHAKDHPKIAKIFEIQTMPNGKTRTSLKTMSRRKLSQQKEKKATQMLAIVLGVFIICWLPFFITHILNIHCDCNIPPVLYSAFTWLGYVNSAVNPIIYTTFNIEFRKAFLKILHC\n",
      "                                  |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||.|||||||||||||||||    |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||                                                                                                                                             |||||||||||.|||.||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
      "----------------------------------NYYATLLTLLIAVIVFGNVLVCMAVSREKALQTTTNYLIVSLAVADLLVATLVMPWVVYLEVVGEWKFSRIHCDIFVTLDVMMCTASALNLCAISIDRYTAVAMP----TRYSSKRRVTVMISIVWVLSFTISCPLLFGLNNADQNECIIANPAFVVYSSIVSFYVPFIVTLLVYIKIYIVLRRRRKR---------------------------------------------------------------------------------------------------------------------------------------------SQQKEKKATQMAAIVAGVFIICWLPFFITHILNIHCDCNIPPVLYSAFTWLGYVNSAVNPIIYTTFNIEFRKAFLKILH-\n",
      "  Score=1207\n",
      "\n",
      "Mapping query sequence and pdb took 0.0017172813415527344 min\n",
      "Mapping query sequence and pdb took 0.0017178614934285482 min\n",
      "Constructing internal representation took 2.6686986287434897e-05 min\n",
      "Computing the distance matrix based on the PDB file took 0.012111906210581462 min\n",
      "\tSelection: water_channel\n",
      "\tSelection: tm2-7_link\n",
      "\tSelection: ligand_binding\n",
      "\tSelection: stabilize_inactive\n",
      "\tSelection: beta_ionone_binding\n",
      "\tSelection: dry\n",
      "\tSelection: hhm\n",
      "\tSelection: ionic_lock\n",
      "\tSelection: tm3-5_link\n",
      "\tSelection: tm5-6_link\n",
      "\tSelection: broken_ionic_lock\n",
      "\tSelection: ms_tm6\n",
      "\tSelection: cwxp\n",
      "\tSelection: npxxyx_f\n",
      "\tSelection: tm7_cterm_link\n",
      "\tSelection: all_key_res\n",
      "Attempting to load DCA covariance for: 2ddr\n",
      "Removing gaps took 0.00039161046346028645 min\n",
      "30.106966972351074\n",
      "Successfully loaded DCA covariance for: 2ddr\n",
      "Importing the PDB file took 0.0007488489151000977 min\n",
      "MDPLNLSWYDDDLERQNWSRPFNGSDGKADRPHYNYYATLLTLLIAVIVFGNVLVCMAVSREKALQTTTNYLIVSLAVADLLVATLVMPWVVYLEVVGEWKFSRIHCDIFVTLDVMMCTASILNLCAISIDRYTAVAMPMLYNTRYSSKRRVTVMISIVWVLSFTISCPLLFGLNNADQNECIIANPAFVVYSSIVSFYVPFIVTLLVYIKIYIVLRRRRKRVNTKRSSRAFRAHLRAPLKGNCTHPEDMKLCTVIMKSNGSFPVNRRRVEAARRAQELEMEMLSSTSPPERTRYSPIPPSHHQLTLPDPSHHGLHSTPDSPAKPEKNGHAKDHPKIAKIFEIQTMPNGKTRTSLKTMSRRKLSQQKEKKATQMLAIVLGVFIICWLPFFITHILNIHCDCNIPPVLYSAFTWLGYVNSAVNPIIYTTFNIEFRKAFLKILHC\n",
      "                                  |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||.|||||||||||||||||    |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||                                                                                                                                             |||||||||||.|||.||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
      "----------------------------------NYYATLLTLLIAVIVFGNVLVCMAVSREKALQTTTNYLIVSLAVADLLVATLVMPWVVYLEVVGEWKFSRIHCDIFVTLDVMMCTASALNLCAISIDRYTAVAMP----TRYSSKRRVTVMISIVWVLSFTISCPLLFGLNNADQNECIIANPAFVVYSSIVSFYVPFIVTLLVYIKIYIVLRRRRKR---------------------------------------------------------------------------------------------------------------------------------------------SQQKEKKATQMAAIVAGVFIICWLPFFITHILNIHCDCNIPPVLYSAFTWLGYVNSAVNPIIYTTFNIEFRKAFLKILH-\n",
      "  Score=1207\n",
      "\n",
      "Mapping query sequence and pdb took 0.0020702203114827474 min\n",
      "Mapping query sequence and pdb took 0.002070629596710205 min\n",
      "Constructing internal representation took 0.0026799321174621584 min\n",
      "Computing the distance matrix based on the PDB file took 0.012286631266276042 min\n",
      "\tSelection: water_channel\n",
      "\tSelection: tm2-7_link\n",
      "\tSelection: ligand_binding\n",
      "\tSelection: stabilize_inactive\n",
      "\tSelection: beta_ionone_binding\n",
      "\tSelection: dry\n",
      "\tSelection: hhm\n",
      "\tSelection: ionic_lock\n",
      "\tSelection: tm3-5_link\n",
      "\tSelection: tm5-6_link\n",
      "\tSelection: broken_ionic_lock\n",
      "\tSelection: ms_tm6\n",
      "\tSelection: cwxp\n",
      "\tSelection: npxxyx_f\n",
      "\tSelection: tm7_cterm_link\n",
      "\tSelection: all_key_res\n",
      "Attempting to load EVC Standard covariance for: 2ddr\n",
      "Removing gaps took 0.0003866871198018392 min\n",
      "602.0900826454163\n",
      "Successfully loaded EVC Standard covariance for: 2ddr\n",
      "Importing the PDB file took 0.0007317821184794108 min\n",
      "MDPLNLSWYDDDLERQNWSRPFNGSDGKADRPHYNYYATLLTLLIAVIVFGNVLVCMAVSREKALQTTTNYLIVSLAVADLLVATLVMPWVVYLEVVGEWKFSRIHCDIFVTLDVMMCTASILNLCAISIDRYTAVAMPMLYNTRYSSKRRVTVMISIVWVLSFTISCPLLFGLNNADQNECIIANPAFVVYSSIVSFYVPFIVTLLVYIKIYIVLRRRRKRVNTKRSSRAFRAHLRAPLKGNCTHPEDMKLCTVIMKSNGSFPVNRRRVEAARRAQELEMEMLSSTSPPERTRYSPIPPSHHQLTLPDPSHHGLHSTPDSPAKPEKNGHAKDHPKIAKIFEIQTMPNGKTRTSLKTMSRRKLSQQKEKKATQMLAIVLGVFIICWLPFFITHILNIHCDCNIPPVLYSAFTWLGYVNSAVNPIIYTTFNIEFRKAFLKILHC\n",
      "                                  |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||.|||||||||||||||||    |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||                                                                                                                                             |||||||||||.|||.||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
      "----------------------------------NYYATLLTLLIAVIVFGNVLVCMAVSREKALQTTTNYLIVSLAVADLLVATLVMPWVVYLEVVGEWKFSRIHCDIFVTLDVMMCTASALNLCAISIDRYTAVAMP----TRYSSKRRVTVMISIVWVLSFTISCPLLFGLNNADQNECIIANPAFVVYSSIVSFYVPFIVTLLVYIKIYIVLRRRRKR---------------------------------------------------------------------------------------------------------------------------------------------SQQKEKKATQMAAIVAGVFIICWLPFFITHILNIHCDCNIPPVLYSAFTWLGYVNSAVNPIIYTTFNIEFRKAFLKILH-\n",
      "  Score=1207\n",
      "\n",
      "Mapping query sequence and pdb took 0.001976633071899414 min\n",
      "Mapping query sequence and pdb took 0.0019770065943400064 min\n",
      "Constructing internal representation took 0.0025410970052083333 min\n",
      "Computing the distance matrix based on the PDB file took 0.011947854359944662 min\n",
      "\tSelection: water_channel\n",
      "\tSelection: tm2-7_link\n",
      "\tSelection: ligand_binding\n",
      "\tSelection: stabilize_inactive\n",
      "\tSelection: beta_ionone_binding\n",
      "\tSelection: dry\n",
      "\tSelection: hhm\n",
      "\tSelection: ionic_lock\n",
      "\tSelection: tm3-5_link\n",
      "\tSelection: tm5-6_link\n",
      "\tSelection: broken_ionic_lock\n",
      "\tSelection: ms_tm6\n",
      "\tSelection: cwxp\n",
      "\tSelection: npxxyx_f\n",
      "\tSelection: tm7_cterm_link\n",
      "\tSelection: all_key_res\n",
      "Attempting to load ET-MIp covariance for: 2ddr\n",
      "Removing gaps took 0.0003927946090698242 min\n",
      "Evolutionary Trace analysis with the same parameters already saved to this location.\n",
      "13.508091688156128\n",
      "Successfully loaded ET-MIp covariance for: 2ddr\n",
      "Importing the PDB file took 0.0007433215777079264 min\n",
      "MDPLNLSWYDDDLERQNWSRPFNGSDGKADRPHYNYYATLLTLLIAVIVFGNVLVCMAVSREKALQTTTNYLIVSLAVADLLVATLVMPWVVYLEVVGEWKFSRIHCDIFVTLDVMMCTASILNLCAISIDRYTAVAMPMLYNTRYSSKRRVTVMISIVWVLSFTISCPLLFGLNNADQNECIIANPAFVVYSSIVSFYVPFIVTLLVYIKIYIVLRRRRKRVNTKRSSRAFRAHLRAPLKGNCTHPEDMKLCTVIMKSNGSFPVNRRRVEAARRAQELEMEMLSSTSPPERTRYSPIPPSHHQLTLPDPSHHGLHSTPDSPAKPEKNGHAKDHPKIAKIFEIQTMPNGKTRTSLKTMSRRKLSQQKEKKATQMLAIVLGVFIICWLPFFITHILNIHCDCNIPPVLYSAFTWLGYVNSAVNPIIYTTFNIEFRKAFLKILHC\n",
      "                                  |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||.|||||||||||||||||    |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||                                                                                                                                             |||||||||||.|||.||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
      "----------------------------------NYYATLLTLLIAVIVFGNVLVCMAVSREKALQTTTNYLIVSLAVADLLVATLVMPWVVYLEVVGEWKFSRIHCDIFVTLDVMMCTASALNLCAISIDRYTAVAMP----TRYSSKRRVTVMISIVWVLSFTISCPLLFGLNNADQNECIIANPAFVVYSSIVSFYVPFIVTLLVYIKIYIVLRRRRKR---------------------------------------------------------------------------------------------------------------------------------------------SQQKEKKATQMAAIVAGVFIICWLPFFITHILNIHCDCNIPPVLYSAFTWLGYVNSAVNPIIYTTFNIEFRKAFLKILH-\n",
      "  Score=1207\n",
      "\n",
      "Mapping query sequence and pdb took 0.001972333590189616 min\n",
      "Mapping query sequence and pdb took 0.001972933610280355 min\n",
      "Constructing internal representation took 0.002402079105377197 min\n",
      "Computing the distance matrix based on the PDB file took 0.01192784309387207 min\n",
      "\tSelection: water_channel\n",
      "\tSelection: tm2-7_link\n",
      "\tSelection: ligand_binding\n",
      "\tSelection: stabilize_inactive\n",
      "\tSelection: beta_ionone_binding\n",
      "\tSelection: dry\n",
      "\tSelection: hhm\n",
      "\tSelection: ionic_lock\n",
      "\tSelection: tm3-5_link\n",
      "\tSelection: tm5-6_link\n",
      "\tSelection: broken_ionic_lock\n",
      "\tSelection: ms_tm6\n",
      "\tSelection: cwxp\n",
      "\tSelection: npxxyx_f\n",
      "\tSelection: tm7_cterm_link\n",
      "\tSelection: all_key_res\n",
      "Attempting to load ET-M-MD covariance for: 2ddr\n",
      "Removing gaps took 0.00037172635396321617 min\n",
      "Evolutionary Trace analysis with the same parameters already saved to this location.\n",
      "12.192923069000244\n",
      "Successfully loaded ET-M-MD covariance for: 2ddr\n",
      "Importing the PDB file took 0.0010802865028381348 min\n",
      "MDPLNLSWYDDDLERQNWSRPFNGSDGKADRPHYNYYATLLTLLIAVIVFGNVLVCMAVSREKALQTTTNYLIVSLAVADLLVATLVMPWVVYLEVVGEWKFSRIHCDIFVTLDVMMCTASILNLCAISIDRYTAVAMPMLYNTRYSSKRRVTVMISIVWVLSFTISCPLLFGLNNADQNECIIANPAFVVYSSIVSFYVPFIVTLLVYIKIYIVLRRRRKRVNTKRSSRAFRAHLRAPLKGNCTHPEDMKLCTVIMKSNGSFPVNRRRVEAARRAQELEMEMLSSTSPPERTRYSPIPPSHHQLTLPDPSHHGLHSTPDSPAKPEKNGHAKDHPKIAKIFEIQTMPNGKTRTSLKTMSRRKLSQQKEKKATQMLAIVLGVFIICWLPFFITHILNIHCDCNIPPVLYSAFTWLGYVNSAVNPIIYTTFNIEFRKAFLKILHC\n",
      "                                  |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||.|||||||||||||||||    |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||                                                                                                                                             |||||||||||.|||.||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| \n",
      "----------------------------------NYYATLLTLLIAVIVFGNVLVCMAVSREKALQTTTNYLIVSLAVADLLVATLVMPWVVYLEVVGEWKFSRIHCDIFVTLDVMMCTASALNLCAISIDRYTAVAMP----TRYSSKRRVTVMISIVWVLSFTISCPLLFGLNNADQNECIIANPAFVVYSSIVSFYVPFIVTLLVYIKIYIVLRRRRKR---------------------------------------------------------------------------------------------------------------------------------------------SQQKEKKATQMAAIVAGVFIICWLPFFITHILNIHCDCNIPPVLYSAFTWLGYVNSAVNPIIYTTFNIEFRKAFLKILH-\n",
      "  Score=1207\n",
      "\n",
      "Mapping query sequence and pdb took 0.0028293530146280923 min\n",
      "Mapping query sequence and pdb took 0.0028297464052836102 min\n",
      "Constructing internal representation took 0.002657608191172282 min\n",
      "Computing the distance matrix based on the PDB file took 0.013099964459737141 min\n",
      "\tSelection: water_channel\n",
      "\tSelection: tm2-7_link\n",
      "\tSelection: ligand_binding\n",
      "\tSelection: stabilize_inactive\n",
      "\tSelection: beta_ionone_binding\n",
      "\tSelection: dry\n",
      "\tSelection: hhm\n",
      "\tSelection: ionic_lock\n",
      "\tSelection: tm3-5_link\n",
      "\tSelection: tm5-6_link\n",
      "\tSelection: broken_ionic_lock\n",
      "\tSelection: ms_tm6\n",
      "\tSelection: cwxp\n",
      "\tSelection: npxxyx_f\n",
      "\tSelection: tm7_cterm_link\n",
      "\tSelection: all_key_res\n",
      "Attempting to load rvET covariance for: 2rrm\n",
      "Removing gaps took 0.00020204782485961915 min\n",
      "Evolutionary Trace analysis with the same parameters already saved to this location.\n",
      "30.581856727600098\n",
      "Successfully loaded rvET covariance for: 2rrm\n",
      "Importing the PDB file took 0.0013526717821756998 min\n",
      "-----------------------------------------------------------------------------------------GNIFIKNLHPDIDNKALYDTFSVFGDILSSKIATDENGKSKGFGFVHFEEEGAAKEAIDALNGMLLNGQEIYVA---------PHLS\n",
      "                                                                                         ||||||||...|||||||||||.||.|||.|...|||| |||.||||||...||..||...||||||.....|.         ..|.\n",
      "MASLYVGDLHPDVTEAMLYEKFSPAGPILSIRVCRDMITRRSLGYAYVNFQQPADAERALDTMNFDVIKGKPVRIMWSQRDPSLRKSGVGNIFIKNLDKSIDNKALYDTFSAFGNILSCKVVCDENG-SKGYGFVHFETQEAAERAIEKMNGMLLNDRKVFVGRFKSRKEREAELG\n",
      "  Score=189\n",
      "\n",
      "Mapping query sequence and pdb took 0.0019004225730895996 min\n",
      "Mapping query sequence and pdb took 0.0019007523854573567 min\n",
      "Constructing internal representation took 1.5342235565185546e-05 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 7814.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 7902.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 7922.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 7924.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain E is discontinuous at line 7997.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.006886466344197591 min\n",
      "\tSelection: rnp1\n",
      "\tSelection: rnp2\n",
      "\tSelection: all_key_res\n",
      "Attempting to load DCA covariance for: 2rrm\n",
      "Removing gaps took 0.0002004861831665039 min\n",
      "7.448775291442871\n",
      "Successfully loaded DCA covariance for: 2rrm\n",
      "Importing the PDB file took 0.0013613382975260417 min\n",
      "-----------------------------------------------------------------------------------------GNIFIKNLHPDIDNKALYDTFSVFGDILSSKIATDENGKSKGFGFVHFEEEGAAKEAIDALNGMLLNGQEIYVA---------PHLS\n",
      "                                                                                         ||||||||...|||||||||||.||.|||.|...|||| |||.||||||...||..||...||||||.....|.         ..|.\n",
      "MASLYVGDLHPDVTEAMLYEKFSPAGPILSIRVCRDMITRRSLGYAYVNFQQPADAERALDTMNFDVIKGKPVRIMWSQRDPSLRKSGVGNIFIKNLDKSIDNKALYDTFSAFGNILSCKVVCDENG-SKGYGFVHFETQEAAERAIEKMNGMLLNDRKVFVGRFKSRKEREAELG\n",
      "  Score=189\n",
      "\n",
      "Mapping query sequence and pdb took 0.0019469022750854491 min\n",
      "Mapping query sequence and pdb took 0.0019472440083821614 min\n",
      "Constructing internal representation took 0.0001415133476257324 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 7814.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 7902.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 7922.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 7924.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain E is discontinuous at line 7997.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.00689005454381307 min\n",
      "\tSelection: rnp1\n",
      "\tSelection: rnp2\n",
      "\tSelection: all_key_res\n",
      "Attempting to load EVC Standard covariance for: 2rrm\n",
      "Removing gaps took 0.0002058704694112142 min\n",
      "22.07924485206604\n",
      "Successfully loaded EVC Standard covariance for: 2rrm\n",
      "Importing the PDB file took 0.001338215668996175 min\n",
      "-----------------------------------------------------------------------------------------GNIFIKNLHPDIDNKALYDTFSVFGDILSSKIATDENGKSKGFGFVHFEEEGAAKEAIDALNGMLLNGQEIYVA---------PHLS\n",
      "                                                                                         ||||||||...|||||||||||.||.|||.|...|||| |||.||||||...||..||...||||||.....|.         ..|.\n",
      "MASLYVGDLHPDVTEAMLYEKFSPAGPILSIRVCRDMITRRSLGYAYVNFQQPADAERALDTMNFDVIKGKPVRIMWSQRDPSLRKSGVGNIFIKNLDKSIDNKALYDTFSAFGNILSCKVVCDENG-SKGYGFVHFETQEAAERAIEKMNGMLLNDRKVFVGRFKSRKEREAELG\n",
      "  Score=189\n",
      "\n",
      "Mapping query sequence and pdb took 0.0018725951512654623 min\n",
      "Mapping query sequence and pdb took 0.0018729368845621746 min\n",
      "Constructing internal representation took 0.00013942321141560872 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 7814.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 7902.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 7922.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 7924.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain E is discontinuous at line 7997.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.006988743940989177 min\n",
      "\tSelection: rnp1\n",
      "\tSelection: rnp2\n",
      "\tSelection: all_key_res\n",
      "Attempting to load ET-MIp covariance for: 2rrm\n",
      "Removing gaps took 0.00020953814188639323 min\n",
      "Evolutionary Trace analysis with the same parameters already saved to this location.\n",
      "26.911238431930542\n",
      "Successfully loaded ET-MIp covariance for: 2rrm\n",
      "Importing the PDB file took 0.001346715291341146 min\n",
      "-----------------------------------------------------------------------------------------GNIFIKNLHPDIDNKALYDTFSVFGDILSSKIATDENGKSKGFGFVHFEEEGAAKEAIDALNGMLLNGQEIYVA---------PHLS\n",
      "                                                                                         ||||||||...|||||||||||.||.|||.|...|||| |||.||||||...||..||...||||||.....|.         ..|.\n",
      "MASLYVGDLHPDVTEAMLYEKFSPAGPILSIRVCRDMITRRSLGYAYVNFQQPADAERALDTMNFDVIKGKPVRIMWSQRDPSLRKSGVGNIFIKNLDKSIDNKALYDTFSAFGNILSCKVVCDENG-SKGYGFVHFETQEAAERAIEKMNGMLLNDRKVFVGRFKSRKEREAELG\n",
      "  Score=189\n",
      "\n",
      "Mapping query sequence and pdb took 0.001877435048421224 min\n",
      "Mapping query sequence and pdb took 0.001877752939860026 min\n",
      "Constructing internal representation took 0.00012938976287841798 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 7814.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 7902.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 7922.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 7924.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain E is discontinuous at line 7997.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.006738130251566569 min\n",
      "\tSelection: rnp1\n",
      "\tSelection: rnp2\n",
      "\tSelection: all_key_res\n",
      "Attempting to load ET-M-MD covariance for: 2rrm\n",
      "Removing gaps took 0.00020546515782674153 min\n",
      "Evolutionary Trace analysis with the same parameters already saved to this location.\n",
      "31.297022581100464\n",
      "Successfully loaded ET-M-MD covariance for: 2rrm\n",
      "Importing the PDB file took 0.0013657768567403158 min\n",
      "-----------------------------------------------------------------------------------------GNIFIKNLHPDIDNKALYDTFSVFGDILSSKIATDENGKSKGFGFVHFEEEGAAKEAIDALNGMLLNGQEIYVA---------PHLS\n",
      "                                                                                         ||||||||...|||||||||||.||.|||.|...|||| |||.||||||...||..||...||||||.....|.         ..|.\n",
      "MASLYVGDLHPDVTEAMLYEKFSPAGPILSIRVCRDMITRRSLGYAYVNFQQPADAERALDTMNFDVIKGKPVRIMWSQRDPSLRKSGVGNIFIKNLDKSIDNKALYDTFSAFGNILSCKVVCDENG-SKGYGFVHFETQEAAERAIEKMNGMLLNDRKVFVGRFKSRKEREAELG\n",
      "  Score=189\n",
      "\n",
      "Mapping query sequence and pdb took 0.0018966873486836752 min\n",
      "Mapping query sequence and pdb took 0.0018970370292663574 min\n",
      "Constructing internal representation took 0.00013617277145385742 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 7814.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 7902.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 7922.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 7924.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain E is discontinuous at line 7997.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the distance matrix based on the PDB file took 0.006735551357269287 min\n",
      "\tSelection: rnp1\n",
      "\tSelection: rnp2\n",
      "\tSelection: all_key_res\n",
      "Attempting to load rvET covariance for: 1yap\n",
      "Removing gaps took 5.121231079101563e-05 min\n",
      "Evolutionary Trace analysis with the same parameters already saved to this location.\n",
      "2.2046566009521484\n",
      "Successfully loaded rvET covariance for: 1yap\n",
      "Importing the PDB file took 0.00026706059773763023 min\n",
      "---------DVPLPAGWEMAKTSSGQRYFLNHIDQTTTWQDPRK----\n",
      "         |||||||||||||||||||||||||||||||||||    \n",
      "GAMGFEIPDDVPLPAGWEMAKTSSGQRYFLNHIDQTTTWQDPRKAMLS\n",
      "  Score=171.5\n",
      "\n",
      "Mapping query sequence and pdb took 0.0004572312037150065 min\n",
      "Mapping query sequence and pdb took 0.00045773983001708987 min\n",
      "Constructing internal representation took 1.3963381449381511e-05 min\n",
      "Computing the distance matrix based on the PDB file took 0.0008368333180745443 min\n",
      "\tSelection: ww\n",
      "\tSelection: binding\n",
      "\tSelection: hydrophobic_cluster_1\n",
      "\tSelection: hydrogen_bonds\n",
      "\tSelection: hydropobic_patch\n",
      "\tSelection: hydrophobic_cluster_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSelection: hydrophobic_pocket\n",
      "\tSelection: all_key_res\n",
      "\tSelection: insensitive_n_term\n",
      "\tSelection: insensitive_turns\n",
      "\tSelection: insensitive_c_term\n",
      "\tSelection: all_insensitive_res\n",
      "Attempting to load DCA covariance for: 1yap\n",
      "Removing gaps took 5.261898040771484e-05 min\n",
      "6.000110864639282\n",
      "Successfully loaded DCA covariance for: 1yap\n",
      "Importing the PDB file took 0.000278162956237793 min\n",
      "---------DVPLPAGWEMAKTSSGQRYFLNHIDQTTTWQDPRK----\n",
      "         |||||||||||||||||||||||||||||||||||    \n",
      "GAMGFEIPDDVPLPAGWEMAKTSSGQRYFLNHIDQTTTWQDPRKAMLS\n",
      "  Score=171.5\n",
      "\n",
      "Mapping query sequence and pdb took 0.00047824382781982424 min\n",
      "Mapping query sequence and pdb took 0.00048265854517618817 min\n",
      "Constructing internal representation took 6.502072016398111e-05 min\n",
      "Computing the distance matrix based on the PDB file took 0.0008151769638061523 min\n",
      "\tSelection: ww\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSelection: binding\n",
      "\tSelection: hydrophobic_cluster_1\n",
      "\tSelection: hydrogen_bonds\n",
      "\tSelection: hydropobic_patch\n",
      "\tSelection: hydrophobic_cluster_2\n",
      "\tSelection: hydrophobic_pocket\n",
      "\tSelection: all_key_res\n",
      "\tSelection: insensitive_n_term\n",
      "\tSelection: insensitive_turns\n",
      "\tSelection: insensitive_c_term\n",
      "\tSelection: all_insensitive_res\n",
      "Attempting to load EVC Standard covariance for: 1yap\n",
      "Removing gaps took 5.352099736531575e-05 min\n",
      "3.787893533706665\n",
      "Successfully loaded EVC Standard covariance for: 1yap\n",
      "Importing the PDB file took 0.00026946067810058595 min\n",
      "---------DVPLPAGWEMAKTSSGQRYFLNHIDQTTTWQDPRK----\n",
      "         |||||||||||||||||||||||||||||||||||    \n",
      "GAMGFEIPDDVPLPAGWEMAKTSSGQRYFLNHIDQTTTWQDPRKAMLS\n",
      "  Score=171.5\n",
      "\n",
      "Mapping query sequence and pdb took 0.0004707654317220052 min\n",
      "Mapping query sequence and pdb took 0.00047108332316080727 min\n",
      "Constructing internal representation took 6.738503774007161e-05 min\n",
      "Computing the distance matrix based on the PDB file took 0.0008122364679972331 min\n",
      "\tSelection: ww\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSelection: binding\n",
      "\tSelection: hydrophobic_cluster_1\n",
      "\tSelection: hydrogen_bonds\n",
      "\tSelection: hydropobic_patch\n",
      "\tSelection: hydrophobic_cluster_2\n",
      "\tSelection: hydrophobic_pocket\n",
      "\tSelection: all_key_res\n",
      "\tSelection: insensitive_n_term\n",
      "\tSelection: insensitive_turns\n",
      "\tSelection: insensitive_c_term\n",
      "\tSelection: all_insensitive_res\n",
      "Attempting to load ET-MIp covariance for: 1yap\n",
      "Removing gaps took 5.296866099039713e-05 min\n",
      "Evolutionary Trace analysis with the same parameters already saved to this location.\n",
      "3.661250591278076\n",
      "Successfully loaded ET-MIp covariance for: 1yap\n",
      "Importing the PDB file took 0.00026466051737467446 min\n",
      "---------DVPLPAGWEMAKTSSGQRYFLNHIDQTTTWQDPRK----\n",
      "         |||||||||||||||||||||||||||||||||||    \n",
      "GAMGFEIPDDVPLPAGWEMAKTSSGQRYFLNHIDQTTTWQDPRKAMLS\n",
      "  Score=171.5\n",
      "\n",
      "Mapping query sequence and pdb took 0.00046503543853759766 min\n",
      "Mapping query sequence and pdb took 0.00046536922454833987 min\n",
      "Constructing internal representation took 6.277163823445639e-05 min\n",
      "Computing the distance matrix based on the PDB file took 0.0007990082105000814 min\n",
      "\tSelection: ww\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSelection: binding\n",
      "\tSelection: hydrophobic_cluster_1\n",
      "\tSelection: hydrogen_bonds\n",
      "\tSelection: hydropobic_patch\n",
      "\tSelection: hydrophobic_cluster_2\n",
      "\tSelection: hydrophobic_pocket\n",
      "\tSelection: all_key_res\n",
      "\tSelection: insensitive_n_term\n",
      "\tSelection: insensitive_turns\n",
      "\tSelection: insensitive_c_term\n",
      "\tSelection: all_insensitive_res\n",
      "Attempting to load ET-M-MD covariance for: 1yap\n",
      "Removing gaps took 5.441506703694661e-05 min\n",
      "Evolutionary Trace analysis with the same parameters already saved to this location.\n",
      "5.340250492095947\n",
      "Successfully loaded ET-M-MD covariance for: 1yap\n",
      "Importing the PDB file took 0.0002672155698140462 min\n",
      "---------DVPLPAGWEMAKTSSGQRYFLNHIDQTTTWQDPRK----\n",
      "         |||||||||||||||||||||||||||||||||||    \n",
      "GAMGFEIPDDVPLPAGWEMAKTSSGQRYFLNHIDQTTTWQDPRKAMLS\n",
      "  Score=171.5\n",
      "\n",
      "Mapping query sequence and pdb took 0.00045729875564575194 min\n",
      "Mapping query sequence and pdb took 0.0004578669865926107 min\n",
      "Constructing internal representation took 6.303787231445312e-05 min\n",
      "Computing the distance matrix based on the PDB file took 0.0007714033126831055 min\n",
      "\tSelection: ww\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSelection: binding\n",
      "\tSelection: hydrophobic_cluster_1\n",
      "\tSelection: hydrogen_bonds\n",
      "\tSelection: hydropobic_patch\n",
      "\tSelection: hydrophobic_cluster_2\n",
      "\tSelection: hydrophobic_pocket\n",
      "\tSelection: all_key_res\n",
      "\tSelection: insensitive_n_term\n",
      "\tSelection: insensitive_turns\n",
      "\tSelection: insensitive_c_term\n",
      "\tSelection: all_insensitive_res\n",
      "Attempting to load rvET covariance for: 1axb\n",
      "Removing gaps took 0.034744449456532794 min\n",
      "Evolutionary Trace analysis with the same parameters already saved to this location.\n",
      "8.709298610687256\n",
      "Successfully loaded rvET covariance for: 1axb\n",
      "Importing the PDB file took 0.0004657745361328125 min\n",
      "HPETLVKVKDAEDQLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRIDAGQEQLGRRIHYSQNDLVEYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDRWEPELNEAIPNDERDTTMPVAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "HPETLVKVKDAEDQLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRIDAGQEQLGRRIHYSQNDLVEYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDRWEPELNEAIPNDERDTTMPVAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW\n",
      "  Score=1348\n",
      "\n",
      "Mapping query sequence and pdb took 0.0012475212415059408 min\n",
      "Mapping query sequence and pdb took 0.001247870922088623 min\n",
      "Constructing internal representation took 1.9892056783040365e-05 min\n",
      "Computing the distance matrix based on the PDB file took 0.011918572584788005 min\n",
      "\tSelection: binding_cat\n",
      "\tSelection: 5A_binding_cat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSelection: co-varying core\n",
      "\tSelection: disulfide bridge\n",
      "\tSelection: disulfide bridge in Sme-1\n",
      "\tSelection: folding determinate\n",
      "\tSelection: all_key_res\n",
      "Attempting to load DCA covariance for: 1axb\n",
      "Removing gaps took 0.04411388635635376 min\n",
      "12.136721134185791\n",
      "Successfully loaded DCA covariance for: 1axb\n",
      "Importing the PDB file took 0.00048357248306274414 min\n",
      "HPETLVKVKDAEDQLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRIDAGQEQLGRRIHYSQNDLVEYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDRWEPELNEAIPNDERDTTMPVAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "HPETLVKVKDAEDQLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRIDAGQEQLGRRIHYSQNDLVEYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDRWEPELNEAIPNDERDTTMPVAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW\n",
      "  Score=1348\n",
      "\n",
      "Mapping query sequence and pdb took 0.0013024568557739257 min\n",
      "Mapping query sequence and pdb took 0.001302806536356608 min\n",
      "Constructing internal representation took 0.0011199633280436197 min\n",
      "Computing the distance matrix based on the PDB file took 0.011838889122009278 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSelection: binding_cat\n",
      "\tSelection: 5A_binding_cat\n",
      "\tSelection: co-varying core\n",
      "\tSelection: disulfide bridge\n",
      "\tSelection: disulfide bridge in Sme-1\n",
      "\tSelection: folding determinate\n",
      "\tSelection: all_key_res\n",
      "Attempting to load EVC Standard covariance for: 1axb\n",
      "Removing gaps took 0.021958700815836587 min\n",
      "165.5119504928589\n",
      "Successfully loaded EVC Standard covariance for: 1axb\n",
      "Importing the PDB file took 0.00047312180201212567 min\n",
      "HPETLVKVKDAEDQLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRIDAGQEQLGRRIHYSQNDLVEYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDRWEPELNEAIPNDERDTTMPVAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "HPETLVKVKDAEDQLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRIDAGQEQLGRRIHYSQNDLVEYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDRWEPELNEAIPNDERDTTMPVAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW\n",
      "  Score=1348\n",
      "\n",
      "Mapping query sequence and pdb took 0.0012777169545491536 min\n",
      "Mapping query sequence and pdb took 0.001278078556060791 min\n",
      "Constructing internal representation took 0.0011222124099731444 min\n",
      "Computing the distance matrix based on the PDB file took 0.012175293763478597 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSelection: binding_cat\n",
      "\tSelection: 5A_binding_cat\n",
      "\tSelection: co-varying core\n",
      "\tSelection: disulfide bridge\n",
      "\tSelection: disulfide bridge in Sme-1\n",
      "\tSelection: folding determinate\n",
      "\tSelection: all_key_res\n",
      "Attempting to load ET-MIp covariance for: 1axb\n",
      "Removing gaps took 0.03677264849344889 min\n",
      "Evolutionary Trace analysis with the same parameters already saved to this location.\n",
      "9.642625331878662\n",
      "Successfully loaded ET-MIp covariance for: 1axb\n",
      "Importing the PDB file took 0.00047542651494344074 min\n",
      "HPETLVKVKDAEDQLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRIDAGQEQLGRRIHYSQNDLVEYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDRWEPELNEAIPNDERDTTMPVAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "HPETLVKVKDAEDQLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRIDAGQEQLGRRIHYSQNDLVEYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDRWEPELNEAIPNDERDTTMPVAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW\n",
      "  Score=1348\n",
      "\n",
      "Mapping query sequence and pdb took 0.0012498259544372558 min\n",
      "Mapping query sequence and pdb took 0.0012503584225972493 min\n",
      "Constructing internal representation took 0.0010993440945943197 min\n",
      "Computing the distance matrix based on the PDB file took 0.012139010429382324 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSelection: binding_cat\n",
      "\tSelection: 5A_binding_cat\n",
      "\tSelection: co-varying core\n",
      "\tSelection: disulfide bridge\n",
      "\tSelection: disulfide bridge in Sme-1\n",
      "\tSelection: folding determinate\n",
      "\tSelection: all_key_res\n",
      "Attempting to load ET-M-MD covariance for: 1axb\n",
      "Removing gaps took 0.044185928503672284 min\n",
      "Evolutionary Trace analysis with the same parameters already saved to this location.\n",
      "8.163577795028687\n",
      "Successfully loaded ET-M-MD covariance for: 1axb\n",
      "Importing the PDB file took 0.0004847923914591471 min\n",
      "HPETLVKVKDAEDQLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRIDAGQEQLGRRIHYSQNDLVEYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDRWEPELNEAIPNDERDTTMPVAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "HPETLVKVKDAEDQLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRIDAGQEQLGRRIHYSQNDLVEYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDRWEPELNEAIPNDERDTTMPVAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW\n",
      "  Score=1348\n",
      "\n",
      "Mapping query sequence and pdb took 0.0012791355450948079 min\n",
      "Mapping query sequence and pdb took 0.0012794971466064454 min\n",
      "Constructing internal representation took 0.0010971983273824057 min\n",
      "Computing the distance matrix based on the PDB file took 0.012308832009633381 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/PyETTest/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSelection: binding_cat\n",
      "\tSelection: 5A_binding_cat\n",
      "\tSelection: co-varying core\n",
      "\tSelection: disulfide bridge\n",
      "\tSelection: disulfide bridge in Sme-1\n",
      "\tSelection: folding determinate\n",
      "\tSelection: all_key_res\n"
     ]
    }
   ],
   "source": [
    "# Create directory for covariation auroc/auprc analyses\n",
    "auc_dir = os.path.join(output_dir, 'Key_Site_AUCs')\n",
    "os.makedirs(auc_dir, exist_ok=True)\n",
    "\n",
    "recovery_data = {'Protein': [], 'Method': [], 'Selection': [], 'AUROC': [], 'AUPRC': []}\n",
    "\n",
    "for protein in  key_residues: # ['1axb']: #  allosteric_data_set:\n",
    "    for method in et_method_order:\n",
    "\n",
    "        if protein in small_data_set:\n",
    "            protein_dir = os.path.join(small_data_out_dir, protein)\n",
    "        elif protein in allosteric_data_set:\n",
    "            protein_dir = os.path.join(allosteric_data_out_dir, protein)\n",
    "        else:\n",
    "            raise ValueError('Bad protein')\n",
    "\n",
    "        protein_settings = {'query': all_data[protein]['query'], 'aln_file': all_data[protein]['aln_path']}\n",
    "        # Then perform experiments for each method\n",
    "        # Set the result directory for this method\n",
    "        if method in ['ET-MCM-', 'ET-M-MC', 'ET-MCMCR', 'ET-MCMCA', 'ET-MEM-', 'ET-M-ME', 'ET-MEMER', 'ET-MEMEA',\n",
    "                      'ET-MDM-', 'ET-M-MD', 'ET-MDMDR', 'ET-MDMDA', 'ET-MDMER', 'ET-MDMEA']:\n",
    "            method_dir = os.path.join(protein_dir, 'ET-MEMER')\n",
    "        elif method in ['ET-MIp', 'cET-MIp']:\n",
    "            method_dir = os.path.join(protein_dir, 'ET-MIp')\n",
    "        else:\n",
    "            method_dir = os.path.join(protein_dir, method)\n",
    "        assert os.path.isdir(method_dir)\n",
    "        print(f'Attempting to load {method} covariance for: {protein}')\n",
    "        # Otherwise perform the experiment, beginning with compiling the compelte settings for this predictor\n",
    "        curr_settings = {'out_dir': method_dir}\n",
    "        curr_settings.update(protein_settings)\n",
    "        curr_settings.update(method_dict[method]['Settings'])\n",
    "        predictor = method_dict[method]['Predictor'](**curr_settings)\n",
    "        total_time = predictor.calculate_scores(**method_dict[method]['Scoring Params'])\n",
    "        print(f'Successfully loaded {method} covariance for: {protein}')\n",
    "\n",
    "        if method == 'rvET':\n",
    "            pred_scorer = SinglePositionScorer(query=all_data[protein]['query'], seq_alignment=os.path.join(method_dir, 'Non-Gapped_Alignment.fa'), pdb_reference=all_data[protein]['pdb_path'],\n",
    "                                               chain=all_data[protein]['chain'])\n",
    "        else:\n",
    "            pred_scorer = ContactScorer(query=all_data[protein]['query'], seq_alignment=os.path.join(method_dir, 'Non-Gapped_Alignment.fa'), pdb_reference=all_data[protein]['pdb_path'], cutoff=8.0,\n",
    "                                               chain=all_data[protein]['chain'])\n",
    "        pred_scorer.fit()\n",
    "        pred_scorer.measure_distance(method='Any')\n",
    "        pred_scorer.map_predictions_to_pdb(ranks=predictor.rankings, predictions=predictor.scores, coverages=predictor.coverages, threshold=0.5)\n",
    "\n",
    "        for sel in key_residues[protein]:\n",
    "            print(f'\\tSelection: {sel}')\n",
    "            tpr, fpr, auroc, precision, recall, auprc = pred_scorer.recovery_of_pdb_residues(key_residues[protein][sel])\n",
    "            pred_scorer.plot_auc(auc_data=(tpr, fpr, auroc), title=f'{protein}_{method}_{sel}_AUROC', file_name=f'{protein}_{method}_{sel}_AUROC.png', output_dir=auc_dir)\n",
    "            pred_scorer.plot_auprc(auprc_data=(precision, recall, auprc), title=f'{protein}_{method}_{sel}_AUPRC', file_name=f'{protein}_{method}_{sel}_AUPRC.png', output_dir=auc_dir)\n",
    "            recovery_data['Protein'].append(protein)\n",
    "            recovery_data['Method'].append(method)\n",
    "            recovery_data['Selection'].append(sel)\n",
    "            recovery_data['AUROC'].append(auroc)\n",
    "            recovery_data['AUPRC'].append(auprc)\n",
    "recovery_df = pd.DataFrame(recovery_data)\n",
    "recovery_df.to_csv(os.path.join(auc_dir, f'Overlap_Key_Residues_auroc_auprc.tsv'), header=True, index=False, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyETTest)",
   "language": "python",
   "name": "pyettest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
