{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method Characteriation #\n",
    "## Goal ##\n",
    "The goal of this test set is to perform proof of concept testing on a small number of proteins with a wide range of sizes and available homologs, orthologs, and paralogs. By doing so it should be possible to test the best parameterization for this tool as well as identifying the strengths and weaknesses of the tool using various measurments as end points.\n",
    "## Warning ##\n",
    "Before attempting to use this notebook make sure that your .env file has been properly setup to reflect the correct locations of command line tools and the location of files and directories needed for execution.\n",
    "### Initial Import###\n",
    "This first cell performs the necessary imports required to begin this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "try:\n",
    "    dotenv_path = find_dotenv(raise_error_if_not_found=True)\n",
    "except IOError:\n",
    "    dotenv_path = find_dotenv(raise_error_if_not_found=True, usecwd=True)\n",
    "load_dotenv(dotenv_path)\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ.get('PROJECT_PATH'), 'src'))\n",
    "input_dir = os.environ.get('INPUT_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set Construction ##\n",
    "The first task required to test the data set is to download the required data and construct any necessary input files for all down stream analyses.\n",
    "In this case that means:\n",
    "* Downloading PDB files for the proteins in our small test set.\n",
    "* Extracting a query sequence from each PDB file.\n",
    "* Searching for paralogs, homologs, and orthologs in a custom BLAST database built by filtering the Uniref90 database.\n",
    "* Filtering the hits from the BLAST search to meet minimum and maximum length requirements, as well as minimum and maximum identity requirements.\n",
    "* Building alignments using CLUSTALW in both the fasta and msf formats since some of the tools which will be used for comparison need different formats.\n",
    "* Filtering the alignment for maximum identity similarity between seqeunces.\n",
    "* Re-aligning the filtered sequences using CLUSTALW.\n",
    "This is all handeled by the DataSetGenerator class found in the src/SupportingClasses folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from Supporting_Classes.DataSetGenerator import DataSetGenerator\n",
    "protein_list_dir = os.path.join(input_dir, 'ProteinLists')\n",
    "if not os.path.isdir(protein_list_dir):\n",
    "    os.makedirs(protein_list_dir)\n",
    "small_list_fn = os.path.join(protein_list_dir, 'SmallDataSet.txt')\n",
    "if not os.path.isfile(small_list_fn):\n",
    "    proteins_of_interest = ['2ysdA', '1c17A', '3tnuA', '7hvpA', '135lA', '206lA', '2b59A', '2werA', '1bolA', '3q05A',\n",
    "                            '1axbA', '2rh1A', '1hckA', '3b6vA', '2z0eA', '1jwlA', '1a26A', '1c0kA', '1h1vA', '4lliA',\n",
    "                            '4ycuA', '2iopA', '2zxeA']\n",
    "    with open(small_list_fn, 'wb') as small_list_handle:\n",
    "        for p_id in proteins_of_interest:\n",
    "            small_list_handle.write('{}\\n'.format(p_id))\n",
    "generator = DataSetGenerator(input_dir)\n",
    "start = time()\n",
    "dataset_df = generator.build_pdb_alignment_dataset(protein_list_fn=os.path.basename(small_list_fn), num_threads=10,\n",
    "                                                   database='customuniref90.fasta', max_target_seqs=2500, remote=False,\n",
    "                                                   verbose=False)\n",
    "dataset_df['Length'] = dataset_df['Protein_ID'].apply(lambda x: int(data_dict[x]['Length']),\n",
    "                                                      args=(generator.protein_data,))\n",
    "dataset_df['Total_Size'] = dataset_df.apply(lambda row: row['Length'] * row['Filtered_Alignment'], axis=1)\n",
    "dataset_df.sort(columns=['Total_Size', 'Length', 'Filtered_Alignment'], ascending=[1, 1, 1], axis='columns', inplace=True)\n",
    "end = time()\n",
    "print('It took {} min to generate the data set.'.format((end - start) / 60.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a location to store the output of this parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.environ.get('OUTPUT_PATH')\n",
    "characterization_out_dir = os.path.join(output_dir, 'Characterization')\n",
    "if not os.path.isdir(characterization_out_dir):\n",
    "    os.makedirs(characterization_out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method Characterization##\n",
    "This section performs the Evoluationary Trace method for covariation ('pair's of residues) with different parameters to help determine which provide the optimal behavior (in this case measured by ability to predict structural contacts: AUROC, Precision, and clustering: Biased SCW Z-Score, Unbiased SCW Z-Score).\n",
    "### Distance Metric Parameters###\n",
    "* identity', False - Uses the identity metric to compute the distance between the sequences in the provided alignment.\n",
    "* 'blosum62', True - Uses the similarity metric (as defined by the off diagonal values from the 'blosum62' distance matrix) to compute the distance between the sequences in the provided alignment.\n",
    "* 'blosum62', False - Uses the 'blosum62' scoring matrix to compute the edit distance between sequences in the provided alignment.\n",
    "### Tree Construction Parameters###\n",
    "* 'et' - A phylogenetic tree related to the UPGMA tree, but where the distance update does not use the average of columns from the current step, but rather the average distance between all contributing terminal nodes. This has been used in previous methods by our group.\n",
    "* 'upgma' - A phylogenetic tree constructed using the standard UPGMA algorithm.\n",
    "* 'agglomerative' (affinity='euclidean', linkage='ward') - A tree constructed based on agglomerative/hierarchical clustering over the distance matrix using the specified affinity and linkage.\n",
    "### Scoring Parameters###\n",
    "* 'identity' - A binary scoring of invariance at each level and node in the tree, which yields an integer score for each pair of positions (lower score means the pair position was fixed higher in the tree and therefore more important, higher score means the pair of positions became fixed lower down in the score and is therefore less important).\n",
    "* 'plain_entropy' - The joint entropy between a pair of positions. This provides a real valued (floating point score) for each pair of positions, which can be interpreted the same way as the 'identity' scoring metric but with greater resolution/ability to separate positions.\n",
    "* 'mutual_information' - The mutual informaiton score for each pair of positions within a node of the phylogenetic tree. This is built up over levels of the tree using the trace methodology, in this case the higher the score the better.\n",
    "* 'normalized_mutual_information' - The normalized mutual informaiton score for each pair of positions within a node of the phylogenetic tree. This is built up over levels of the tree using the trace methodology, in this case the higher the score the better.\n",
    "* 'average_product_corrected_mutual_information' - The average product corrected mutual informaiton (MIp) score for each pair of positions within a node of the phylogenetic tree. This is built up over levels of the tree using the trace methodology, in this case the higher the score the better (some low scores my be negative).\n",
    "* 'filtered_average_product_corrected_mutual_information' - The average product corrected mutual informaiton (MIp) score for each pair of positions within a node of the phylogenetic tree. This is built up over levels of the tree using the trace methodology, in this case the higher the score the better (some low scores my be negative). This score is additionally filtered at the node level so that positions with a mutual information <= 0.0001 are set to 0 (this was done in a previously released paper by our lab on this topic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EvolutionaryTrace import EvolutionaryTrace\n",
    "from SupportingClasses.ContactScorer import ContactScorer\n",
    "characterization_scores = {'Protein': [], 'Distance': [], 'Tree': [], 'Scoring': [], 'Separation': [], 'AUROC': [],\n",
    "                           'Max_Unbiased_SCW_Z-Score': [], 'AUC_Unbiased_SCW_Z-Score': [],\n",
    "                           'Max_Biased_SCW_Z-Score': [], 'AUC_Biased_SCW_Z-Score': []}\n",
    "for p_id in dataset_df['Protein_ID']:\n",
    "    contact_scorer = None\n",
    "    biased_w2_ave = None\n",
    "    unbiased_w2_ave = None\n",
    "    print('Characterizing protein: {}'.format(p_id))\n",
    "    protein_dir = os.path.join(characterization_out_dir, p_id)\n",
    "    if not os.path.isdir(protein_dir):\n",
    "        os.mkdir(protein_dir)\n",
    "    for dist_model, et_dist in [('identity', False), ('blosum62', True), ('blosum62', False)]:\n",
    "        print('Distance model: {}, ET dist: {}'.format(dist_model, et_dist))\n",
    "        for tree_building, tree_options in [('et', {}), ('upgma', {}),\n",
    "                                            ('agglomerative', {'affinity': 'euclidean', 'linkage': 'ward'})]:\n",
    "            dist_tree_dir = os.path.join(\n",
    "                protein_dir, '{}{}{}{}'.format(dist_model, '_ET' if et_dist else ''), tree_building,\n",
    "                ('_'.join(['{}_{}'.format(k, v) for k,v in tree_options.items()]) if tree_options else ''))\n",
    "            if not os.path.isdir(dist_tree_dir):\n",
    "                os.mkdir(dist_tree_dir)\n",
    "            for scoring_metric in ['identity', 'plain_entropy', 'mutual_information', 'normalized_mutual_information',\n",
    "                                   'average_product_corrected_mutual_information',\n",
    "                                   'filtered_average_product_corrected_mutual_information']:\n",
    "                scoring_dir = os.path.join(dist_tree_dir, scoring_metric)\n",
    "                if not os.path.isdir(scoring_dir):\n",
    "                    os.mkdir(scoring_dir)\n",
    "                curr_et = EvolutionaryTrace(query_id=p_id, polymer_type='Protein',\n",
    "                                            aln_fn=generator.protein_data[p_id]['Final_FA_Aln'], et_distance=et_dist,\n",
    "                                            distance_model=dist_model, tree_building_method=tree_building,\n",
    "                                            tree_building_options=tree_options, ranks=None, position_type='pair',\n",
    "                                            scoring_metric=scoring_metric, gap_correction=None, out_dir=protein_dir,\n",
    "                                            output_files={'original_aln', 'non_gap_aln', 'tree', 'scores'},\n",
    "                                            processors=10, low_memory=True)\n",
    "                curr_et.import_and_process_aln()\n",
    "                curr_et.out_dir = dist_tree_dir\n",
    "                curr_et.compute_distance_matrix_tree_and_assignments()\n",
    "                curr_et.out_dir = scoring_dir\n",
    "                curr_et.perform_trace()\n",
    "                if contact_scorer is None:\n",
    "                    pdb_structure = PDBReference(pdb_file=generator.protein_data[p_id]['PDB'])\n",
    "                    pdb_structure.import_pdb()\n",
    "                    contact_scorer = ContactScorer(seq_alignment=curr_et.non_gapped_aln,\n",
    "                                                   pdb_reference=pdb_structure, cutoff=8.0)\n",
    "                    contact_scorer.best_chain = generator.protein_data[p_id]['Chain']\n",
    "                    contact_scorer.fit()\n",
    "                z_score_fn = os.path.join(scoring_dir, '{}_ZScores.tsv')\n",
    "                z_score_biased, b_w2_ave, b_scw_z_auc = self.score_clustering_of_contact_predictions(\n",
    "                    scores, bias=True, file_path=z_score_fn.format('Biased'), w2_ave_sub=biased_w2_ave,\n",
    "                    processes=processes)\n",
    "                max_biased_z_score = np.max(pd.to_numeric(z_score_biased['Z-Score'], errors='coerce'))\n",
    "                if (biased_w2_ave is None) and (b_w2_ave is not None):\n",
    "                    biased_w2_ave = b_w2_ave\n",
    "                z_score_unbiased, u_w2_ave, u_scw_z_auc = self.score_clustering_of_contact_predictions(\n",
    "                    scores, bias=False, file_path=z_score_fn.format('Unbiased'), w2_ave_sub=unbiased_w2_ave,\n",
    "                    processes=processes)\n",
    "                max_unbiased_z_score = np.max(pd.to_numeric(z_score_unbiased['Z-Score'], errors='coerce'))\n",
    "                if (unbiased_w2_ave is None) and (u_w2_ave is not None):\n",
    "                    unbiased_w2_ave = u_w2_ave\n",
    "                for separation in ['Any', 'Neighbors', 'Short', 'Medium', 'Long']:\n",
    "                    _, _, auroc = contact_scorer.score_auc(1.0 - curr_et.coverage, category=separation)\n",
    "                    for k in range(1, 11):\n",
    "                        if k == 1:\n",
    "                            precision_label = 'Precision (L)'\n",
    "                        else:\n",
    "                            precision_label = 'Precision (L/{})'.format(k)\n",
    "                        if precision_label not in characterization_scores:\n",
    "                            stats[precision_label] = []\n",
    "                        precision = contact_scorer.score_precision(predictions=scores, k=k, category=separation)\n",
    "                        characterization_scores['Protein'].append(p_id)\n",
    "                        characterization_scores['Distance'].append('{}{}'.format(dist_model, '_ET' if et_dist else '')))\n",
    "                        characterization_scores['Tree'].append('{}{}'.format(tree_building,\n",
    "                                                                             ('_'.join(['{}_{}'.format(k, v)\n",
    "                                                                                        for k,v in tree_options.items()])\n",
    "                                                                              if tree_options else '')))\n",
    "                        characterization_scores['Scoring'].append(scoring_metric)\n",
    "                        characterization_scores['Separation'].append(separation)\n",
    "                        characterization_scores['AUROC'].append(auroc)\n",
    "                        characterization_scores[precision_label].append(precision)\n",
    "                        characterization_scores['Max_Biased_SCW_Z-Score'].append(max_biased_z_score)\n",
    "                        characterization_scores['AUC_Biased_SCW_Z-Score'].append(b_scw_z_auc)\n",
    "                        characterization_scores['Max_Unbiased_SCW_Z-Score'].append(max_unbiased_z_score)\n",
    "                        characterization_scores['AUC_Unbiased_SCW_Z-Score'].append(u_scw_z_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cET-MIp)",
   "language": "python",
   "name": "cet-mip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
