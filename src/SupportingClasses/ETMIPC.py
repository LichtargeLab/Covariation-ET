"""
Created on Aug 21, 2017

@author: dmkonecki
"""
import os
import Queue
import numpy as np
from time import time
import cPickle as pickle
from multiprocessing import Manager, Pool
from sklearn.metrics import mutual_info_score
from SeqAlignment import SeqAlignment
from ContactScorer import write_out_contact_scoring


class ETMIPC(object):
    """
    This is a class representing the coupling Evolutionary Trace - Mutual Information product (cET-MIp).

    Attributes:
            alignment (str/SeqAlignment): The path to an alignment, later updated to a SeqAlignment object containing
            relevant information for this cET-MIp analysis by the import_alignment_method.
            tree_depth (list): When generating the hierarchical clustering/phylogenetic tree, these are the levels for
            which to perform analysis.
            unique_clusters (dict): This dictionary tracks the first unique occurrence of each cluster (node) in the
            hierarchical clustering/phylogenetic tree. This dictionary is nested such that the first level tree position
            (branch, cluster) maps to a second dictionary which contains the following information:
                'assignments' - Which sequences from the alignment are in this cluster (node) of the tree.
                'tree_positions' - The full list of tree positions which refer to this same cluster (node)/set of
                sequences.
                'time' - The amount of time it took to generate the sub alignment, MIp scores, and evidence (non-gap)
                counts for this cluster (node).
                'sub_alignment' - The sub alignment generated by selecting only the assigned seqeunces from the overall
                sequence allignment analyzed by this class.
                'cluster_scores' - The MIp scores computed for this cluster (node).
                'nongap_counts' - The evidence (non-gap) counts for this cluster (node).
            cluster_mapping (dict): A dictionary mapping a position in the tree (branch and cluster) to the first time
            that cluster appeared in the tree when traversing from root to leaves (i.e. the entry tracked in
            unique_clusters).
            nongap_counts (dict): This dictionary maps branch and cluster to a matrix which has counts for the number
            of sequences which are not gaps in either position used for scoring at that position.
            cluster_scores (dict): This dictionary maps branch and cluster to a matrix which has MIp scores for each
            possible pair of residues in the sequence of interest.
            branch_scores (dict): This dictionary maps a specific branch to a matrix scoring the coupling between all
            residues in the query sequence over all of the clusters created at that branch level.
            scores (dict): This dictionary maps a specific branch to a matrix which combines the scores from all
            branching levels lower than and equal to that branch.
            coverage (dict): This dictionary maps a specific branch to a matrix of normalized coupling scores between 0
            and 100, computed from the data in the scores attribute.
            times (dict): Dictionary mapping a specific branch to the amount of time it took to perform analysis for
            that branch.
            processes (int): The number of processes to spawn for more intense computations performed during this
            analysis. If the number is higher than the number of jobs required to quickly perform this analysis the
            number of jobs is used instead.  If the number of processes is higher than the number of processors
            available to the program, the number of processors available is used instead.
            low_mem (bool): This boolean specifies whether or not to run in low memory mode. If True is specified a
            majority of the class attributes will be filled in with file paths instead of matrices of values, and those
            values will be loaded at run time when needed for downstream analysis. The intermediate files generated in
            this way can be removed using the clear_intermediate_files method. The default value is False, in which case
            all variables are kept in memory.
            output_dir (str): Directory name or path to directory where results from this analysis should be stored.
    """

    def __init__(self, alignment):
        """
        __init__

        Instantiates an instance of the ETMIPC class, storing only the file path to a specified alignment and
        initializing all other values to None.

        Args:
            alignment (str or SeqAlignment): The path to an .fa formatted alignment to be used for analysis, or a
            SeqAlignment object whose file_name attribute will be used instead.
        """
        if isinstance(alignment, SeqAlignment):
            self.alignment = alignment.file_name
        else:
            self.alignment = alignment
        self.tree_depth = None
        self.unique_clusters = None
        self.cluster_mapping = None
        self.nongap_counts = None
        self.cluster_scores = None
        self.branch_scores = None
        self.scores = None
        self.coverage = None
        self.times = None
        self.processes = None
        self.low_mem = None
        self.output_dir = None

    def get_sub_alignment(self, branch, cluster):
        """
        Get Sub Alignment

        This method retrieves the relevant sub_alignment for a specified branch and cluster using the cluster_mapping
        and unique_clusters attributes.

        Args:
            branch (int): The hierarchical clustering/phylogenetic tree branching level to return a sub alignment for.
            cluster (int): The cluster within a given branching level to return a sub alignment for.
        Returns:
            SeqAlignment: The sub alignment object for the specified branch and cluster.
        """
        return self.unique_clusters[self.cluster_mapping[(branch, cluster)]]['sub_alignment']

    def __get_c_level_matrices(self, item, branch=None, cluster=None, three_dim=False):
        """
        Get C Level Matrices

        A general class method to retrieve data from a dictionary 2D arrays or a dictionary of dictionaries of 2D
        arrays. The entire dictionary can be returned, or just the matrices for a specific cluster and/or branch.
        As long as only three dimensions worth of data is returned a 3D matrix can be generated if specified.

        Args:
            item (str): The class attribute to work with.
            branch (int): The hierarchical clustering/phylogenetic tree branching level to return data for.
            cluster (int): The cluster within a given branching level to return data for.
            three_dim (bool): Whether or not to return the data in a three dimensional matrix.
        Returns:
            np.array or dict. The specified data requested from the dictionary of dictionaries of 2D arrays.
        """
        attr = self.__getattribute__(item)
        if branch is not None:
            if cluster is not None:
                curr_matrices = attr[branch][cluster]
            else:
                curr_matrices = attr[branch]
        else:
            curr_matrices = attr
        if self.low_mem:
            if isinstance(curr_matrices, str):
                curr_matrices = np.load(curr_matrices)['mat']
            elif isinstance(curr_matrices, dict):
                if isinstance(curr_matrices.values()[0], str):
                    curr_matrices = {i: np.load(curr_matrices[i])['mat'] for i in curr_matrices}
                else:
                    curr_matrices = {i: {j: np.load(curr_matrices[i][j])['mat'] for j in curr_matrices[i]}
                                     for i in curr_matrices}
            else:
                raise ValueError('Incorrect value encountered at self.{}'.format(item))
        if three_dim:
            if isinstance(curr_matrices, np.ndarray):
                curr_matrices = curr_matrices[np.newaxis, :, :]
            elif isinstance(curr_matrices, dict):
                if isinstance(curr_matrices.values()[0], np.ndarray):
                    curr_matrices = np.vstack(tuple([curr_matrices[cluster][np.newaxis, :, :]
                                                     for cluster in sorted(curr_matrices.keys())]))
                else:
                    raise ValueError('This method is not intended to return 4D matrices which would be required for a'
                                     'dictionary of dictionaries of matrices.')
            else:
                raise ValueError('Incorrect value encountered at self.{}'.format(item))
        return curr_matrices

    def get_nongap_counts(self, branch=None, cluster=None, three_dim=False):
        """
        Get Nongap Counts

        Retrieve the nongap count data. The entire dictionary of dictionaries of 2D matrices can be returned, or just
        the dictionary of matrices for a specific branch, or a single matrix if both cluster and branch are specified.
        If branch or cluster are specified a three dimensional matrix can be returned if specified. This method relies
        on the __get_c_level_matrices method.

        Args:
            branch (int): The hierarchical clustering/phylogenetic tree branching level to return cluster score data
            for.
            cluster (int): The cluster within a given branching level to return cluster score data for.
            three_dim (bool): Whether or not to return the data in a three dimensional matrix.
        Returns:
            np.array or dict. The specified data requested from the dictionary of cluster scores.
        """
        return self.__get_c_level_matrices(item='nongap_counts', branch=branch, cluster=cluster, three_dim=three_dim)

    def get_cluster_scores(self, branch=None, cluster=None, three_dim=False):
        """
        Get Cluster Scores

        Retrieve the cluster score data. The entire dictionary of dictionaries of 2D matrices can be returned, or just
        the dictionary of matrices for a specific branch, or a single matrix if both cluster and branch are specified.
        If branch or cluster are specified a three dimensional matrix can be returned if specified. This method relies
        on the __get_c_level_matrices method.

        Args:
            branch (int): The hierarchical clustering/phylogenetic tree branching level to return cluster score data
            for.
            cluster (int): The cluster within a given branching level to return cluster score data for.
            three_dim (bool): Whether or not to return the data in a three dimensional matrix.
        Returns:
            np.array or dict. The specified data requested from the dictionary of cluster scores.
        """
        return self.__get_c_level_matrices(item='cluster_scores', branch=branch, cluster=cluster, three_dim=three_dim)

    def get_branch_scores(self, branch=None, three_dim=False):
        """
        Get Branch Scores

        Retrieve the branch score data. The entire dictionary of of 2D matrices can be returned or a single matrix if
        branch is specified. In either case a three dimensional matrix can be returned if specified. This method relies
        on the __get_c_level_matrices method.

        Args:
            branch (int): The hierarchical clustering/phylogenetic tree branching level to return branch score data for.
            three_dim (bool): Whether or not to return the data in a three dimensional matrix.
        Returns:
            np.array or dict. The specified data requested from the dictionary of branch scores.
        """
        return self.__get_c_level_matrices(item='branch_scores', branch=branch, three_dim=three_dim)

    def get_scores(self, branch=None, three_dim=False):
        """
        Get Scores

        Retrieve the scores data. The entire dictionary of of 2D matrices can be returned or a single matrix if branch
        is specified. In either case a three dimensional matrix can be returned if specified. This method relies on the
        __get_c_level_matrices method.

        Args:
            branch (int): The hierarchical clustering/phylogenetic tree branching level to return scores data for.
            three_dim (bool): Whether or not to return the data in a three dimensional matrix.
        Returns:
            np.array or dict. The specified data requested from the dictionary of scores data.
        """
        return self.__get_c_level_matrices(item='scores', branch=branch, three_dim=three_dim)

    def get_coverage(self, branch=None, three_dim=False):
        """
        Get Coverage

        Retrieve the coverage data for a specified branch or all branches. The entire dictionary of of 2D matrices can
        be returned or a single matrix if branch is specified. In either case a three dimensional matrix can be returned
        if specified. This method relies on the __get_c_level_matrices method.

        Args:
            branch (int): The hierarchical clustering/phylogenetic tree branching level to return coverage data for.
            three_dim (bool): Whether or not to return the data in a three dimensional matrix.
        Returns:
            np.array or dict. The specified data requested from the dictionary of coverage data.
        """
        return self.__get_c_level_matrices(item='coverage', branch=branch, three_dim=three_dim)
    ####################################################################################################################

    def import_alignment(self, query, ignore_alignment_size=False, clustering='agglomerative',
                         clustering_args={'affinity': 'euclidean', 'linkage': 'ward'}):
        """
        Import Alignment

        This method imports an alignment for analysis. The gaps are removed from the alignment such that the sequence
        specified by query has no gaps in its sequence. This ungapped alignment is written to file. The alignment
        variable of this class instance is also updated to the imported SeqAlignment as opposed to the path
        provided upon initialization. Using the import alignment the distances (sequence identity) between all pairs of
        sequences are computed. These distances are then used to build a hierarchical clustering/

        Args:
            query (str): A string specifying the name of the target query in the alignment, '>query_' will be prepended
            to the provided string to find it in the alignment.
            ignore_alignment_size (bool): Whether or not to ignore the alignment size. If False and the alignment
            provided has fewer than 125 sequences a ValueError will be raised.
            clustering (str): Which method to use for generating a hierachical clustering/phylogenetic tree. Current
            options are described in SeqAlignment set_tree_ordering and include 'agglomerative' and 'random'.
            clustering_args (dict): Additional arguments for the clustering method used. This function initializes the
            unique_clusters, cluster_mapping, and tree_depth attributes and updates the alignment attribute.
        """
        print 'Importing alignment'
        # Create SeqAlignment object to represent the alignment for this analysis.
        print(self.alignment)
        query_alignment = SeqAlignment(file_name=self.alignment, query_id=query)
        # Import alignment information from file.
        query_alignment.import_alignment(save_file=os.path.join(self.output_dir, 'alignment.pkl'))
        # Check if alignment meets analysis criteria:
        if (not ignore_alignment_size) and (query_alignment.size < 125):
            raise ValueError('The multiple sequence alignment is smaller than recommended for performing this analysis '
                             '({} < 125, see PMID:16159918), if you wish to proceed with the analysis anyway please '
                             'call the code again using the --ignore_alignment_size option.'.format(query_alignment.size))
        # Remove gaps from aligned query sequences
        query_alignment.remove_gaps(save_file=os.path.join(self.output_dir, 'ungapped_alignment.pkl'))
        # Compute distance between all sequences in the alignment
        query_alignment.compute_distance_matrix(save_file=os.path.join(self.output_dir, 'X'))
        # Write the ungapped alignment to file.
        query_alignment.write_out_alignment(file_name=os.path.join(self.output_dir, 'UngappedAlignment.fa'))
        # Determine the full clustering tree for the alignment and the ordering of its sequences.
        tree_depth = query_alignment.set_tree_ordering(tree_depth=self.tree_depth, cache_dir=self.output_dir,
                                                       clustering=clustering, clustering_args=clustering_args)
        unique_assignments = {}
        first_occurrence = {}
        cluster_mapping = {}
        for branch in query_alignment.sequence_assignments:
            for cluster in query_alignment.sequence_assignments[branch]:
                # assignments = '_'.join(sorted(query_alignment.sequence_assignments[branch][cluster]))
                assignments = frozenset(query_alignment.sequence_assignments[branch][cluster])
                tree_position = (branch, cluster)
                # if assignments not in unique_assignments:
                if assignments not in first_occurrence:
                    first_occurrence[assignments] = tree_position
                    unique_assignments[tree_position] = {'assignments': assignments, 'tree_positions': set(), 'time': 0,
                                                         'sub_alignment': None, 'cluster_scores': None,
                                                         'nongap_counts': None}
                unique_assignments[first_occurrence[assignments]]['tree_positions'].add(tree_position)
                cluster_mapping[tree_position] = first_occurrence[assignments]
        print('Query Sequence: {}'.format(query_alignment.query_sequence))
        self.alignment = query_alignment
        self.unique_clusters = unique_assignments
        self.cluster_mapping = cluster_mapping
        self.tree_depth = tree_depth

    def _generate_sub_alignments(self):
        """
        Generate Sub Alignments

        This method generates the sub alignments for all unique clusters identified from the
        hierarchical clustering/phylogenetic tree. The method depends on the pool_init_sub_aln and
        generate_sub_alignment functions and updates the unique_cluters attribute.
        """
        tree_positions = list(self.unique_clusters.keys())
        pool = Pool(processes=self.processes, initializer= pool_init_sub_aln, initargs=(self.alignment,
                                                                                               self.unique_clusters))
        pool_res = pool.map_async(generate_sub_alignment, tree_positions)
        for res in pool_res.get():
            self.unique_clusters[res[0]]['sub_alignment'] = res[1]
            self.unique_clusters[res[0]]['time'] = res[2]

    def _score_clusters(self, evidence, aa_mapping):
        """
        Score Clusters

        This method calculates the MIp scores and evidence (non_gap) counts for the unique sub alignments present in
        the unique_clusters attribute. This method depends on the pool_init_score and mip_score functions and updates
        the unique_clusters attribute.

        Args:
            evidence (bool): Whether or not to generate the evidence (non-gap) counts for each pair of residues scored
            while computing the MIp score.
            aa_mapping (dict): A dictionary mapping amino acids (including gaps) to numbers.
        """
        tree_positions = list(self.unique_clusters.keys())
        pool = Pool(processes=self.processes, initializer=pool_init_score,
                    initargs=(evidence, self.unique_clusters, aa_mapping, self.output_dir, self.low_mem))
        pool_res = pool.map_async(mip_score, tree_positions)
        for res in pool_res.get():
            self.unique_clusters[res[0]]['cluster_scores'] = res[1]
            self.unique_clusters[res[0]]['nongap_counts'] = res[2]
            self.unique_clusters[res[0]]['time'] = res[3]

    def calculate_cluster_scores(self, evidence, aa_mapping):
        """
        Calculate Cluster Scores

        This method uses the cluster_mapping defined by the hierarchical clustering/phylogenetic tree to generate sub
        alignments and score all unique sub alignments generated during the analysis and if specified the evidence
        (non-gap) counts for each pair of residues scored this way. This function depends on the
        _generate_sub_alignments, pool_init_sub_aln, generate_sub_alignment, _score_clusters, pool_init_score, and
        score_mip methods and functions and it initializes the nongap_counts, cluster_scores, and times attributes and
        updates the unique_clusters attribute.

        Args:
            evidence (bool): Whether or not to generate the evidence (non-gap) counts for each pair of residues scored
            while computing the MIp score.
            aa_mapping (dict): A dictionary mapping amino acids (including gaps) to numbers.
        """
        self._generate_sub_alignments()
        self._score_clusters(evidence=evidence, aa_mapping=aa_mapping)
        self.nongap_counts = {}
        self.cluster_scores = {}
        self.times = {}
        for c in self.cluster_mapping:
            if c[0] not in self.nongap_counts:
                self.nongap_counts[c[0]] = {}
                self.cluster_scores[c[0]] = {}
                self.times[c[0]] = 0
            self.nongap_counts[c[0]][c[1]] = self.unique_clusters[self.cluster_mapping[c]]['nongap_counts']
            self.cluster_scores[c[0]][c[1]] = self.unique_clusters[self.cluster_mapping[c]]['cluster_scores']
            self.times[c[0]] += self.unique_clusters[self.cluster_mapping[c]]['time']

    def calculate_branch_scores(self, combine_clusters):
        """
        Calculate Branch Scores

        This method uses cluster_scores to calculate branch scores for each branch as specified by combine_clusters.
        This function depends on the pool_init_calculate_branch_score and calculate_branch_score methods. This function
        sets the branch_scores attribute and updates the times attribute.

        Args:

        """
        pool = Pool(processes=self.processes, initializer=pool_init_calculate_branch_score,
                    initargs=(self, combine_clusters))
        pool_res = pool.map_async(calculate_branch_score, self.tree_depth)
        self.branch_scores = {}
        for res in pool_res.get():
            self.branch_scores[res[0]] = res[1]
            self.times[res[0]] += res[2]

    def calculate_final_scores(self, combine_branches):
        """
        Calculate Final Scores

        This method uses branch_scores to calculate final scores and coverage for each branch as specified by
        combine_branches. This function depends on the pool_init_calculate_score_and_coverage and
        calculate_score_and_coverage methods. This function sets the scores and coverage attributes and updates the
        times attribute.

        Args:
            combine_branches (str): The options currently available are 'sum' and 'average', which compute the
            respective function on all branches up to and including the specified branch.
        """
        pool = Pool(processes=self.processes, initializer=pool_init_calculate_score_and_coverage,
                    initargs=(self, combine_branches))
        pool_res = pool.map_async(calculate_score_and_coverage, self.tree_depth)
        self.scores = {}
        self.coverage = {}
        for res in pool_res.get():
            self.scores[res[0]] = res[1]
            self.coverage[res[0]] = res[2]
            self.times[res[0]] += res[3]

    def write_out_scores(self, curr_date):
        """
        Write Out Scores

        This method writes out clustering scores. This method updates the time class variable.

        Args:
            curr_date (str): The current date which will be used for identifying the proper directory to store files in
            and as part of the file name.
        """
        pool = Pool(processes=self.processes, initializer=pool_init_write_score, initargs=(self, curr_date))
        pool_res = pool.map_async(write_score, self.tree_depth)
        for res in pool_res.get():
            self.times[res[0]] += res[1]

    def clear_intermediate_files(self):
        """
        Clear Intermediate Files

        This method is intended to be used only if the ETMIPC low_mem attribute is set to True. If this is the case all
        serialized files for analyses that have been completed will be removed.
        """
        if self.low_mem:
            for branch in self.tree_depth:
                if self.branch_scores and os.path.isfile(self.branch_scores[branch]):
                    os.remove(self.branch_scores[branch])
                if self.scores and os.path.isfile(self.scores[branch]):
                    os.remove(self.scores[branch])
                if self.coverage and os.path.isfile(self.coverage[branch]):
                    os.remove(self.coverage[branch])
            for tree_pos in self.unique_clusters:
                if self.unique_clusters[tree_pos]['cluster_scores'] and \
                        os.path.isfile(self.unique_clusters[tree_pos]['cluster_scores']):
                    os.remove(self.unique_clusters[tree_pos]['cluster_scores'])
                if self.unique_clusters[tree_pos]['nongap_counts'] and \
                        os.path.isfile(self.unique_clusters[tree_pos]['nongap_counts']):
                    os.remove(self.unique_clusters[tree_pos]['nongap_counts'])

    def calculate_scores(self, curr_date, query, tree_depth, out_dir, ignore_alignment_size, clustering,
                         clustering_args, aa_mapping, combine_clusters, combine_branches, processes=1, low_mem=False,
                         del_intermediate=False):
        """
        Calculate Scores

        This method generates all raw, intermediate, and final scores for the ETMIPC class by calling on other methods.
        This method is meant to be the main interface for generating these scores, while other methods are meant as
        support. At the ended of the calculation the state of this object is serialized in pickle and npz files which
        can be loaded if the same analysis is performed again.

        Args:
            curr_date (str): The date on which this run is being performed (used for file naming).
            query (str): The query in the alignment to center this analysis on.
            tree_depth (None, tuple, list): If None then the full tree will be computed for this analysis, if a tuple is
            passed then the tree will be computed from the first element in the tuple to the second (non-inclusive, see
            range behavior), and if a list each branch specified in that list will be analyzed.
            out_dir (str): The top level directory in which results for this analysis should be saved.
            ignore_alignment_size (bool): Whether or not to ignore the size of the alignment specified for this
            ETMIPC instance, the recomended length is 125 sequences.
            clustering (str): Which method to use when clustering to create the tree analyzed here. Current options are
            detailed in the SeqAlignment set_tree_ordering method.
            clustering_args (dict): Additional arguments for the SeqAlignment set_tree_ordering method.
            aa_mapping (dict): A dictionary mapping amino acids (including gaps) to numbers.
            combine_clusters (str): A method for combining clusters to get branch scores. Described in more detail in
            calculate_branch_scores.
            combine_branches (str): A method for combinging branch scores to get final scores. Described in more detail
            in calculate_final_scores.
            processes (int): The number of processes available to perform this analysis.
            low_mem (bool): Whether to perform this analysis in low memory mode, where score matrices are serialized
            instead of being kept in memory.
            del_intermediate (bool): Whether to remove the serialized files if low_mem is True or not. Note if low_mem
            is True and del_intermediate is also True then the serialized version of this instance (.pkl and .npz) files
            will no longer be able to load its data if re-run.
        Returns:
            float: The time in seconds that it took to perform this method.
        """
        start = time()
        self.output_dir = out_dir
        self.processes = processes
        serialized_path = os.path.join(self.output_dir, '{}_cET-MIp.npz'.format(query))
        save_file = os.path.join(self.output_dir, '{}_cET-MIp.pkl'.format(query))
        if os.path.isfile(serialized_path) and os.path.isfile(save_file):
            self.import_alignment(query=query, ignore_alignment_size=ignore_alignment_size, clustering=clustering,
                                  clustering_args=clustering_args)
            loaded_vars = pickle.load(open(save_file, 'rb'))
            self.tree_depth = loaded_vars[0]
            self.low_mem = loaded_vars[1]
            self.unique_clusters = loaded_vars[2]
            self.cluster_mapping = loaded_vars[3]
            self.times = loaded_vars[4]
            loaded_data = np.load(serialized_path)
            self.scores = loaded_data['scores'][()]
            self.coverage = loaded_data['coverage'][()]
            self.branch_scores = loaded_data['branches'][()]
            self.cluster_scores = loaded_data['clusters'][()]
            self.nongap_counts = loaded_data['nongap_counts'][()]
        else:
            self.low_mem = low_mem
            self.tree_depth = tree_depth
            self.import_alignment(query=query, ignore_alignment_size=ignore_alignment_size, clustering=clustering,
                                  clustering_args=clustering_args)
            self.calculate_cluster_scores(evidence=('evidence' in combine_clusters), aa_mapping=aa_mapping)
            self.calculate_branch_scores(combine_clusters=combine_clusters)
            self.calculate_final_scores(combine_branches=combine_branches)
            self.write_out_scores(curr_date=curr_date)
            end = time()
            self.times['Total'] = end - start
            pickle.dump((self.tree_depth, self.low_mem, self.unique_clusters, self.cluster_mapping, self.times),
                        open(save_file, 'wb'), protocol=pickle.HIGHEST_PROTOCOL)
            np.savez(serialized_path, scores=self.scores, coverage=self.coverage, branches=self.branch_scores,
                     clusters=self.cluster_scores, nongap_counts=self.nongap_counts)
            if self.low_mem and del_intermediate:
                self.clear_intermediate_files()
        print('Completing cET-MIp analysis took {} min'.format(self.times['Total'] / 60.0))
        return self.times['Total']

    # def explore_positions(self, i, j, aa_dict):
    #     """
    #     Title
    #
    #     Desc.
    #
    #     Args:
    #     Returns:
    #     """
    #     out_dir = '/home/daniel/Desktop/Test/'
    #     from Bio import AlignIO
    #     if j < i:
    #         i, j = j, i
    #         print('Positions reversed to maintain ordering.')
    #     positional_alns = {c: {k: {} for k in range(c)} for c in [1] + self.clusters}
    #     scoring = {'Branch': [], 'Cluster': [], 'Cluster Score': [], 'Branch Score': [], 'Combined Score': []}
    #     positional_alns[1][0]['aln'] = self.alignment.generate_positional_sub_alignment(i, j)
    #     AlignIO.write([self.alignment.alignment], os.path.join(out_dir, 'C{}_K{}.aln'.format(1, 0)),
    #                   'clustal')
    #     positional_alns[1][0]['plot'] = positional_alns[1][0]['aln'].heatmap_plot('C={} K={}'.format(1, 0),
    #                                                                               aa_dict=aa_dict, save=True,
    #                                                                               out_dir=out_dir)
    #     scoring['Branch'].append(1)
    #     scoring['Cluster'].append(0)
    #     scoring['Cluster Score'].append(self.whole_mip_matrix[i, j])
    #     scoring['Branch Score'].append(self.whole_mip_matrix[i, j])
    #     scoring['Combined Score'].append(self.whole_mip_matrix[i, j])
    #     for c in self.clusters:
    #         for sub in range(c):
    #             positional_alns[c][sub]['aln'] = self.sub_alignments[c][sub].generate_positional_sub_alignment(i, j)
    #             AlignIO.write([self.sub_alignments[c][sub].alignment],
    #                           os.path.join(out_dir, 'C{}_K{}.aln'.format(c, sub)), 'clustal')
    #             positional_alns[c][sub]['plot'] = positional_alns[c][sub]['aln'].heatmap_plot(
    #                 'C={} K={}'.format(c, sub), aa_dict=aa_dict, save=True, out_dir=out_dir)
    #             scoring['Branch'].append(c)
    #             scoring['Cluster'].append(sub)
    #             scoring['Cluster Score'].append(self.get_raw_scores(c=c, k=sub)[i, j])
    #             scoring['Branch Score'].append(self.get_result_matrices(c=c)[i, j])
    #             scoring['Combined Score'].append(self.get_scores(c=c)[i, j])
    #     import pandas as pd
    #     df = pd.DataFrame(scoring)
    #     import seaborn as sns
    #     grid = sns.FacetGrid(df, row='Cluster', col='Branch')
    #     from IPython import embed
    #     embed()


def single_matrix_filename(name, branch, out_dir):
    """
    Single Matrix Filename

    This function can be used to generate a file path and parent directory path for any of the several matrices which
    need to be saved to disk in order to reduce the memory footprint when the ETMIPC attribute low_mem is set to True.

    Args:
        name (str): The name of the matrix to be saved or loaded (expected values: Raw_C{}, Nongap_counts_C{}, Result,
        Scores, Coverage; where {} is replaced by a specific cluster value).
        branch (int): The branch (and therefore directory) for which a value is being saved or loaded.
        out_dir (str): The top level directory to which all ETMIPC instance data is being read and written.
    Returns:
        str: The path to the parent directory of the generated filename.
        str: The full path to the filename generated for the given inputs. The name of the file has the form K{}_{}.npz
        where the first {} is replaced by the specfied branch and the second {} is replaced by the provided filename.
    """
    c_out_dir = os.path.join(out_dir, str(branch))
    fn = os.path.join(c_out_dir, 'K{}_{}.npz'.format(branch, name))
    return c_out_dir, fn


def exists_single_matrix(name, branch, out_dir):
    """
    Exists Single Matrix

    This function can be used to check if any of the several matrices which need to be saved to disk in order to reduce
    the memory footprint when the ETMIPC attribute low_mem is set to True has already been written to file.

    Args:
        name (str): The name of the matrix to be checked (expected values: Raw_C{}, Nongap_counts_C{}, Result, Scores,
        Coverage; where {} is replaced by a specific cluster value).
        branch (int): The branch (and therefore directory) for which a value is being checked.
        out_dir (str): The top level directory to which all ETMIPC instance data is being read and written.
    Returns:
        bool: Whether a file already exists for the specified inputs.
    """
    _, fn = single_matrix_filename(name=name, branch=branch, out_dir=out_dir)
    if os.path.isfile(fn):
        return True
    else:
        return False


def save_single_matrix(name, branch, mat, out_dir):
    """
    Save Single Matrix

    This function can be used to save any of the several matrices which need to be saved to disk in order to reduce the
    memory footprint when the ETMIPC attribute low_mem is set to True.

    Args:
        name (str): The name of the matrix to be saved (expected values: Raw_C{}, Nongap_counts_C{}, Result, Scores,
        Coverage; where {} is replaced by a specific cluster value).
        branch (int): The branch (and therefore directory) for which a value is being saved.
        mat (np.ndarray): The data for the specified branch and variable name to be saved to file.
        out_dir (str): The top level directory to which all ETMIPC instance data is being read and written.
    Returns:
        str: The path to which the provided data were saved.
    """
    parent_dir, fn = single_matrix_filename(name=name, branch=branch, out_dir=out_dir)
    if not os.path.isdir(parent_dir):
        os.mkdir(parent_dir)
    np.savez(fn, mat=mat)
    return fn


def load_single_matrix(name, branch, out_dir):
    """
    Load Single Matrix

    This function can be used to load any of the several matrices which are saved to disk in order to reduce the memory
    footprint when the ETMIPC attribute low_mem is set to True.

    Args:
        name (str): The name of the matrix to be loaded (expected values: Raw_C{}, Nongap_counts_C{}, Result, Scores,
        Coverage; where {} is replaced by a specific cluster value).
        branch (int): The branch (and therefore directory) for which a value is being loaded.
        out_dir (str): The top level directory to which all ETMIPC instance data is being read and written.
    Returns:
        np.array. The array for the given type of data loaded for the specified cluster and/or branch.
    """
    data = None
    _, fn = single_matrix_filename(name=name, branch=branch, out_dir=out_dir)
    if exists_single_matrix(name=name, branch=branch, out_dir=out_dir):
        data = np.load(fn)['mat']
    return data


def pool_init_sub_aln(aln, cluster_dict):
    """
    Pool Init Sub Aln

    This function supports the generate_sub_alignment function, by making the specified alignment and unique_clusters
    dictionary for an ETMIPC instance available to all workers in a multiprocessing pool.

    Args:
        aln (SeqAlignment): The full sequence alignment for an ETMIPC instance (alignment attribute).
        cluster_dict (dict): The unique_clusters dictionary fro an ETMIPC instance which contains the sequence
        assignments for each cluster (required for sub alignment generation).
    """
    global full_aln
    full_aln = aln
    global assignment_dict
    assignment_dict = cluster_dict


def generate_sub_alignment(tree_position):
    """
    Generate Sub Alignment

    This function generates the sub alignment for a specified branch and cluster of a hierarchical
    clustering/phylogenetic tree.

    Args:
        tree_position (tuple):
    Returns:
        tuple: The tree position passed in, returned for mapping results to the proper branch and cluster.
        SeqAlignment: The alignment which is a subset of the ETMIPC alignment attribute.
        float: The time in seconds it took to generate the sub alignment.
    """
    start = time()
    sequence_ids = assignment_dict[tree_position]['assignments']
    sub_aln = full_aln.generate_sub_alignment(sequence_ids)
    end = time()
    return tree_position, sub_aln, (end - start)


def pool_init_score(evidence, cluster_dict, amino_acid_mapping, out_dir, low_mem):
    """
    Pool Init Score

    This function supports the mip_score function, by making the specified ETMIPC instance and method for combining
    clusters available to all workers in a multiprocessing pool.

    Args:
        evidence (bool): Whether or not evidence (non-gap) counts should be generated while calculating MIp scores.
        cluster_dict (dict): The dictionary of unique clusters for the ETMIPC instance.
        amino_acid_mapping (dict): The mapping of amino acids to numbers to use when calculating MIp scores.
        out_dir (str): The directory at which data for this ETMIPC instance is being written.
        low_mem (bool): Whether or not to serialize data so that less RAM is used during execution.
    """
    global measure_evidence
    measure_evidence = evidence
    global sub_alignments
    sub_alignments = cluster_dict
    global aa_dict
    aa_dict = amino_acid_mapping
    global serialization_dir
    serialization_dir = out_dir
    global low_memory_mode
    low_memory_mode = low_mem


def mip_score(tree_position):
    """
    MIp Score

    This function computes MIp scores for all pairs of residues in an alignment for a specified branch and cluster of a
    hierarchical clustering/phylogenetic tree. It also produces a matrix of evidence (non-gap) counts for each pair of
    residues scored this way.

    Args:
        tree_position (tuple): Specifies the branch and cluster for which to compute MIp scores and if specified
        evidence counts.
    Returns:
        tuple: The tree position passed in, returned for mapping results to the proper branch and cluster.
        np.array or str:. Matrix of MIP scores which has dimensions seq_length by seq_length for the ETMIPC instance's
        alignment. The path to a save file for this matrix may be returned instead if low_mem is True for the ETMIPC
        instance.
        np.array or str: Matrix containing the number of sequences which are not gaps in either position used for
        generating MIp scores. The path to a save file for this matrix may be returned instead if low_mem is True for
        the ETMIPC instance.
        float: The time it took to generate MIp scores and evidence founts for a specified branch and cluster of an
        ETMIPC instance.
    """
    start = time()
    mip_fn_bool = exists_single_matrix(name='Raw_C{}'.format(tree_position[1]), branch=tree_position[0],
                                       out_dir=serialization_dir)
    evidence_fn_bool = exists_single_matrix(name='Nongap_counts_C{}'.format(tree_position[1]),
                                            branch=tree_position[0], out_dir=serialization_dir)
    if low_memory_mode and mip_fn_bool and evidence_fn_bool:
        mip_matrix = single_matrix_filename(name='Raw_C{}'.format(tree_position[1]), branch=tree_position[0],
                                            out_dir=serialization_dir)[1]
        evidence_matrix = single_matrix_filename('Nongap_counts_C{}'.format(tree_position[1]), branch=tree_position[0],
                                                 out_dir=serialization_dir)[1]
    else:
        alignment = sub_alignments[tree_position]['sub_alignment']
        overall_mmi = 0.0
        # generate an MI matrix for each cluster
        mi_matrix = np.zeros((alignment.seq_length, alignment.seq_length))
        evidence_matrix = np.zeros((alignment.seq_length, alignment.seq_length))
        # Vector of 1 column
        mmi = np.zeros(alignment.seq_length)
        apc_matrix = np.zeros((alignment.seq_length, alignment.seq_length))
        mip_matrix = np.zeros((alignment.seq_length, alignment.seq_length))
        # Generate MI matrix from alignment2Num matrix, the mmi matrix,
        # and overall_mmi
        alignment_matrix = alignment._alignment_to_num(aa_dict=aa_dict)
        for i in range(alignment.seq_length):
            for j in range(i + 1, alignment.seq_length):
                if measure_evidence:
                    _I, _J, _pos, ev = alignment.identify_comparable_sequences(i, j)
                    evidence_matrix[i, j] = evidence_matrix[j, i] = ev
                col_i = alignment_matrix[:, i]
                col_j = alignment_matrix[:, j]
                curr_mis = mutual_info_score(col_i, col_j, contingency=None)
                # AW: divides by individual entropies to normalize.
                mi_matrix[i, j] = mi_matrix[j, i] = curr_mis
                overall_mmi += curr_mis
        mmi += np.sum(mi_matrix, axis=1)
        mmi -= mi_matrix[np.arange(alignment.seq_length), np.arange(alignment.seq_length)]
        mmi /= (alignment.seq_length - 1)
        overall_mmi = 2.0 * (overall_mmi / (alignment.seq_length - 1)) / alignment.seq_length
        # Calculating APC
        apc_matrix += np.outer(mmi, mmi)
        apc_matrix[np.arange(alignment.seq_length), np.arange(alignment.seq_length)] = 0
        apc_matrix /= overall_mmi
        # Defining MIP matrix
        mip_matrix += mi_matrix - apc_matrix
        mip_matrix[np.arange(alignment.seq_length), np.arange(alignment.seq_length)] = 0
        if low_memory_mode:
            mip_matrix = save_single_matrix(name='Raw_C{}'.format(tree_position[1]), branch=tree_position[0],
                                                                  mat=mip_matrix, out_dir=serialization_dir)
            evidence_matrix = save_single_matrix(name='Nongap_counts_C{}'.format(tree_position[1]),branch=tree_position[0],
                                                 mat=evidence_matrix, out_dir=serialization_dir)
    end = time()
    print('MIp scoring took {} min'.format((end - start) / 60.0))
    return tree_position, mip_matrix, evidence_matrix, (end - start)


def pool_init_calculate_branch_score(curr_instance, combine_clusters):
    """
    Pool Init Calculate Branch Score

    This function supports the calculate_branch_score function, by making the specified ETMIPC instance and method for
    combining clusters available to all workers in a multiprocessing pool.

    Args:
    Returns:
    """
    global instance
    instance = curr_instance
    global combination_method
    combination_method = combine_clusters


def calculate_branch_score(branch):
    """
    Calculate Branch Score

    This function uses variables made available by the pool_init_calculate_branch_score method and the specified branch
    to combine scores from individual clusters to produce a branch score.

    Args:
        branch (int): The branch for which to calculate the combined score.
    Returns:
        int: The branch passed in, returned for mapping results to the proper branch.
        np.ndarray or str: The score produced by combining cluster scores within a branch in the specified way.
        float: The time it took to calculate combined scores for a specific branch of an ETMIPC instance.
    """
    start = time()
    branch_score_fn_bool = exists_single_matrix(name='Result', branch=branch, out_dir=instance.output_dir)
    if instance.low_mem and branch_score_fn_bool:
        branch_score = single_matrix_filename(name='Result', branch=branch, out_dir=instance.output_dir)[1]
    else:
        curr_raw_scores = instance.get_cluster_scores(branch=branch, three_dim=True)
        # Additive clusters
        if combination_method == 'sum':
            branch_score = np.sum(curr_raw_scores, axis=0)
        # Normal average over clusters
        elif combination_method == 'average':
            branch_score = np.mean(curr_raw_scores, axis=0)
        # Weighted average over clusters based on cluster sizes
        elif combination_method == 'size_weighted':
            weighting = np.array([instance.get_sub_alignment(branch=branch, cluster=sub).size for sub in range(branch)])
            branch_score = weighting[:, None, None] * curr_raw_scores
            branch_score = np.sum(branch_score, axis=0) / instance.alignment.size
        elif 'evidence' in combination_method:
            curr_evidence = instance.get_nongap_counts(branch=branch, three_dim=True)
            # Weighted average over clusters based on evidence counts at each
            # pair vs. the number of sequences with evidence for that pairing.
            if combination_method == 'evidence_weighted':
                branch_score = (np.sum(curr_raw_scores * curr_evidence, axis=0) / np.sum(curr_evidence, axis=0))
            # Weighted average over clusters based on evidence counts at each pair vs. the entire size of the alignment.
            elif combination_method == 'evidence_vs_size':
                branch_score = (np.sum(curr_raw_scores * curr_evidence, axis=0) / float(instance.alignment.size))
            else:
                print 'Combination method not yet implemented'
                raise NotImplementedError()
        else:
            print 'Combination method not yet implemented'
            raise NotImplementedError()
        branch_score[np.isnan(branch_score)] = 0.0
        if instance.low_mem:
            branch_score = save_single_matrix('Result', branch, branch_score, instance.output_dir)
    end = time()
    print('Branch scoring took {} min'.format((end - start) / 60.0))
    return branch, branch_score, (end - start)


def pool_init_calculate_score_and_coverage(curr_instance, combine_branches):
    """
    Pool Init Calculate Score And Coverage

    This function supports the calculate_score_and_coverage function, by making the specified ETMIPC instance and
    method for combining branches available to all workers in a multiprocessing pool.

    Args:
        curr_instance (ETMIPC): The ETMIPC object to make accessible to all pool worker processes.
        combine_branches (str): The method for combining branch scores to generate the final score to pass to all pool
        workers.
    """
    global instance
    instance = curr_instance
    global combination_method
    combination_method = combine_branches


def calculate_score_and_coverage(branch):
    """
    Calculate Score And Coverage

    This function calculates final scores for a specified branch of the ETMIPC instance as well as the associated
    coverage scores.

    Args:
        branch (int): The branch for which to compute final scores and coverage scores.
    Returns:
        int: The branch passed in, returned for mapping results to the proper branch.
        np.array and str: A matrix of final scores (or path to the saved matrix) for the specified branch of an ETMIPC
        instance.
        np.array and str: A matrix of coverage scores (or path to the saved matrix) for the specified branch of an
        ETMIPC instance.
        float: The time it took to calculate final scores and coverage for a specific branch of an ETMIPC instance.
    """
    start = time()
    branch_scores = instance.get_branch_scores(three_dim=True)
    branch_index = instance.tree_depth.index(branch) + 1
    scores = np.sum(branch_scores[:branch_index, :, :], axis=0)
    if combination_method == 'average':
        scores /= float(branch_index + 1)
    coverage = np.zeros(scores.shape)
    test_mat = np.triu(scores)
    mask = np.triu(np.ones(scores.shape), k=1)
    normalization = ((scores.shape[0]**2 - scores.shape[0]) / 2.0)
    for i in range(scores.shape[0]):
        for j in range(i + 1, scores.shape[0]):
            bool_mat = (test_mat[i, j] >= test_mat) * 1.0
            corrected_mat = bool_mat * mask
            compute_coverage2 = (((np.sum(corrected_mat) - 1) * 100) / normalization)
            coverage[i, j] = coverage[j, i] = compute_coverage2
    if instance.low_mem:
        scores = save_single_matrix(name='Scores', branch=branch, mat=scores, out_dir=instance.output_dir)
        coverage = save_single_matrix(name='Coverage', branch=branch, mat=coverage, out_dir=instance.output_dir)
    end = time()
    print('Final scoring and coverage calculation took {} min'.format((end - start) / 60.0))
    return branch, scores, coverage, (end - start)


def pool_init_write_score(curr_instance, curr_date):
    """
    Pool Init Write Score

    This function is used to make the write_score function easily callable in the multiprocessing map paradigm. It
    creates global variables of the instance of an ETMIPC object and the string of the current date so it will be
    available to all processes performing that function.

    Args:
        curr_instance (ETMIPC): The ETMIPC instance whose scores are to be written to file.
        curr_date (str): A string of the date to use for file writing.
    """
    global instance
    instance = curr_instance
    global today
    today = curr_date


def write_score(branch):
    """
    Write Score

    This method relies on the global variables instance and today (see pool_init_write_score) and the
    write_out_contact_scoring method (see ContactScorer) in order to write the scores from a specific branch to file.
    The produced file is a tab separated file containing the raw scores, intermediate, and final scores for each pair of
    residues.

    Args:
        branch (int): The branch (must be in ETMIPC.tree_depth) for which to write out scores.
    Returns:
        int: The branch value passed in, used to map the time taken to the proper branch.
        float: The amount of time in seconds that it took to write out the scores.
    """
    start = time()
    curr_out_dir = os.path.join(instance.output_dir, str(branch))
    if not os.path.isdir(curr_out_dir):
        os.mkdir(curr_out_dir)
    res_fn = "{}_{}_{}.all_scores.txt".format(today, instance.alignment.query_id.split('_')[1], branch)
    # write_out_contact_scoring(today=today, alignment=instance.alignment,
    #                           c_raw_scores=instance.get_scores(branch=branch),
    #                           c_coverage=instance.get_coverage(branch=branch),
    #                           mip_matrix=instance.get_cluster_scores(branch=1, cluster=0),
    #                           c_raw_sub_scores=instance.get_cluster_scores(branch=branch),
    #                           c_integrated_scores=instance.get_branch_scores(branch=branch), file_name=res_fn,
    #                           output_dir=os.path.join(instance.output_dir, str(branch)))
    write_out_contact_scoring(today=today, alignment=instance.alignment,
                              scores=instance.get_scores(branch=branch),
                              coverages=instance.get_coverage(branch=branch),
                              cluster_scores=instance.get_cluster_scores(branch=branch),
                              branch_scores=instance.get_branch_scores(branch=branch), file_name=res_fn,
                              output_dir=os.path.join(instance.output_dir, str(branch)))
    end = time()
    print('Writing scores took {} min'.format((end - start) / 60.0))
    return branch, (end - start)
